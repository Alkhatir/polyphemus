{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85065f10",
   "metadata": {},
   "source": [
    "Import libs and set seed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d25c9521",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import os\n",
    "import muspy\n",
    "from itertools import product\n",
    "import pypianoroll as pproll\n",
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "seed = 42\n",
    "set_seed(seed)\n",
    "\n",
    "\n",
    "def plot_stats(stats_tr, stats_to_plot, stats_val=None, eval_every=None, \n",
    "               labels=None, save=False, rx=None, ry=None):\n",
    "\n",
    "    for i, stat in enumerate(stats_to_plot):\n",
    "\n",
    "        label = stat if not labels else labels[i]\n",
    "\n",
    "        plt.plot(range(1, len(stats_tr[stat])+1), stats_tr[stat],\n",
    "                 label=label+' (TR)')\n",
    "\n",
    "        if stats_val:\n",
    "            plt.plot(range(eval_every, len(stats_tr[stat])+1, eval_every),\n",
    "                     stats_val[stat], '.', label=label+' (VL)')\n",
    "\n",
    "    plt.grid()\n",
    "\n",
    "    plt.ylim(ry) if ry else plt.ylim(0)\n",
    "    plt.xlim(rx) if rx else plt.xlim(0)\n",
    "\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99881b47",
   "metadata": {},
   "source": [
    "Load model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6333170",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dir = 'models_prova/'\n",
    "model = '6968a042-5f83-11ee-b397-20677ceb0ed0'\n",
    "checkpoint = torch.load(os.path.join(models_dir, model, 'checkpoint'), \n",
    "                        map_location='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7b15e2",
   "metadata": {},
   "source": [
    "Plot losses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc872705",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 248,
       "width": 369
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labeled_stats = [\n",
    "    #('tot', 'ELBO'),\n",
    "    #('acts', 'Structure'),\n",
    "    #('pitches', 'Pitches'),\n",
    "    #('dur', 'Duration'),\n",
    "    #('rec', 'Rec. term'),\n",
    "    #('kld', 'KLD'),\n",
    "    #('beta*kld', 'beta * KLD')\n",
    "]\n",
    "\n",
    "stats = [s[0] for s in labeled_stats]\n",
    "labels = [s[1] for s in labeled_stats]\n",
    "\n",
    "tr_losses = checkpoint['tr_losses']\n",
    "val_losses = checkpoint['val_losses']\n",
    "eval_every = checkpoint['eval_every']\n",
    "\n",
    "plot_stats(tr_losses, stats, stats_val=val_losses,\n",
    "           eval_every=eval_every, labels=labels, rx=(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c37d02c",
   "metadata": {},
   "source": [
    "Plot accuracies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8d73b0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 252,
       "width": 372
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labeled_stats = [\n",
    "    ('s_acc', 'Struct. accuracy'),\n",
    "    #('s_precision', 'Struct. precision'),\n",
    "    #('s_recall', 'Struct. recall'),\n",
    "    #('s_f1', 'Struct. F1'),\n",
    "    #('pitch', 'Pitches'),\n",
    "    #('pitch_drums', 'Drums pitches'),\n",
    "    #('pitch_non_drums', 'Non drums pitches'),\n",
    "    #('dur', 'Duration'),\n",
    "    ('note', 'Notes')\n",
    "]\n",
    "\n",
    "stats = [s[0] for s in labeled_stats]\n",
    "labels = [s[1] for s in labeled_stats]\n",
    "\n",
    "tr_losses = checkpoint['tr_accuracies']\n",
    "val_losses = checkpoint['val_accuracies']\n",
    "eval_every = checkpoint['eval_every']\n",
    "\n",
    "plot_stats(tr_losses, stats, stats_val=val_losses,\n",
    "           eval_every=eval_every, labels=labels, ry=(0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00e9631",
   "metadata": {},
   "source": [
    "Current epoch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c38c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint['tot_batches']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068ba9af",
   "metadata": {},
   "source": [
    "Show the parameters of the current model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9232c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = torch.load(os.path.join(models_dir, model, 'params'), map_location='cpu')\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7f864f",
   "metadata": {},
   "source": [
    "Learning rates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2693607f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs = checkpoint['lrs']\n",
    "plt.plot(range(1, len(lrs)+1), lrs, label='Lr')\n",
    "plt.grid()\n",
    "plt.ylim(0)\n",
    "plt.xlim(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cf8198",
   "metadata": {},
   "source": [
    "Betas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bc5d18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "betas = checkpoint['betas']\n",
    "plt.plot(range(1, len(betas)+1), betas, label='Beta')\n",
    "plt.grid()\n",
    "#plt.ylim(0, 0.001)\n",
    "plt.xlim(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3a24a8",
   "metadata": {},
   "source": [
    "Reconstruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1b3f35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.set_device(3)\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "#device = torch.device(\"cpu\")\n",
    "print(\"Device:\", device)\n",
    "print(\"Current device idx:\", torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710edc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Dataset\n",
    "from torch_geometric.data import Data\n",
    "import itertools\n",
    "from torch_geometric.data.collate import collate\n",
    "\n",
    "\n",
    "class MIDIDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dir, n_bars=2):\n",
    "        self.dir = dir\n",
    "        _, _, files = next(os.walk(self.dir))\n",
    "        self.len = len(files)\n",
    "        self.n_bars = n_bars\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    \n",
    "    def _get_track_edges(self, acts, edge_type_ind=0):\n",
    "\n",
    "        a_t = acts.transpose()\n",
    "        inds = np.stack(np.where(a_t == 1)).transpose()\n",
    "        \n",
    "        # Create node labels\n",
    "        labels = np.zeros(acts.shape)\n",
    "        acts_inds = np.where(acts == 1)\n",
    "        num_nodes = len(acts_inds[0])\n",
    "        labels[acts_inds] = np.arange(num_nodes)\n",
    "        labels = labels.transpose()\n",
    "\n",
    "        track_edges = []\n",
    "\n",
    "        for track in range(a_t.shape[1]):\n",
    "            tr_inds = list(inds[inds[:,1] == track])\n",
    "            e_inds = [(tr_inds[i],\n",
    "                    tr_inds[i+1]) for i in range(len(tr_inds)-1)]\n",
    "            edges = [(labels[tuple(e[0])], labels[tuple(e[1])], edge_type_ind+track, e[1][0]-e[0][0]) for e in e_inds]\n",
    "            inv_edges = [(e[1], e[0], *e[2:]) for e in edges]\n",
    "            track_edges.extend(edges)\n",
    "            track_edges.extend(inv_edges)\n",
    "\n",
    "        return np.array(track_edges, dtype='long')\n",
    "\n",
    "    \n",
    "    def _get_onset_edges(self, acts, edge_type_ind=4):\n",
    "\n",
    "        a_t = acts.transpose()\n",
    "        inds = np.stack(np.where(a_t == 1)).transpose()\n",
    "        ts_acts = np.any(a_t, axis=1)\n",
    "        ts_inds = np.where(ts_acts)[0]\n",
    "\n",
    "        # Create node labels\n",
    "        labels = np.zeros(acts.shape)\n",
    "        acts_inds = np.where(acts == 1)\n",
    "        num_nodes = len(acts_inds[0])\n",
    "        labels[acts_inds] = np.arange(num_nodes)\n",
    "        labels = labels.transpose()\n",
    "\n",
    "        onset_edges = []\n",
    "\n",
    "        for i in ts_inds:\n",
    "            ts_acts_inds = list(inds[inds[:,0] == i])\n",
    "            if len(ts_acts_inds) < 2:\n",
    "                continue\n",
    "            e_inds = list(itertools.combinations(ts_acts_inds, 2))\n",
    "            edges = [(labels[tuple(e[0])], labels[tuple(e[1])], edge_type_ind, 0) for e in e_inds]\n",
    "            inv_edges = [(e[1], e[0], *e[2:]) for e in edges]\n",
    "            onset_edges.extend(edges)\n",
    "            onset_edges.extend(inv_edges)\n",
    "\n",
    "        return np.array(onset_edges, dtype='long')\n",
    "\n",
    "\n",
    "    def _get_next_edges(self, acts, edge_type_ind=5):\n",
    "\n",
    "        a_t = acts.transpose()\n",
    "        inds = np.stack(np.where(a_t == 1)).transpose()\n",
    "        ts_acts = np.any(a_t, axis=1)\n",
    "        ts_inds = np.where(ts_acts)[0]\n",
    "\n",
    "        # Create node labels\n",
    "        labels = np.zeros(acts.shape)\n",
    "        acts_inds = np.where(acts == 1)\n",
    "        num_nodes = len(acts_inds[0])\n",
    "        labels[acts_inds] = np.arange(num_nodes)\n",
    "        labels = labels.transpose()\n",
    "\n",
    "        next_edges = []\n",
    "\n",
    "        for i in range(len(ts_inds)-1):\n",
    "\n",
    "            ind_s = ts_inds[i]\n",
    "            ind_e = ts_inds[i+1]\n",
    "            s = inds[inds[:,0] == ind_s]\n",
    "            e = inds[inds[:,0] == ind_e]\n",
    "\n",
    "            e_inds = [t for t in list(itertools.product(s, e)) if t[0][1] != t[1][1]]\n",
    "            edges = [(labels[tuple(e[0])], labels[tuple(e[1])], edge_type_ind, ind_e-ind_s) for e in e_inds]\n",
    "            inv_edges = [(e[1], e[0], *e[2:]) for e in edges]\n",
    "            \n",
    "            next_edges.extend(edges)\n",
    "            next_edges.extend(inv_edges)\n",
    "            \n",
    "        return np.array(next_edges, dtype='long')\n",
    "    \n",
    "    def _get_super_edges(self, num_nodes, edge_type_ind=6):\n",
    "    \n",
    "        super_edges = [(num_nodes, i, edge_type_ind, 0) for i in range(num_nodes)]\n",
    "        inv_edges = [(e[1], e[0], *e[2:]) for e in edges]\n",
    "        \n",
    "        super_edges.extend(inv_edges)\n",
    "        \n",
    "        return np.array(super_edges, dtype='long')\n",
    "        \n",
    "    \n",
    "    def _get_node_features(self, acts, num_nodes):\n",
    "        \n",
    "        num_tracks = acts.shape[0]\n",
    "        features = torch.zeros((num_nodes, num_tracks), dtype=torch.float)\n",
    "        features[np.arange(num_nodes), np.stack(np.where(acts))[0]] = 1.\n",
    "        \n",
    "        return features\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        # Load tensors\n",
    "        sample_path = os.path.join(self.dir, str(idx) + \".npz\")\n",
    "        data = np.load(sample_path)\n",
    "        seq_tensor = data[\"seq_tensor\"]\n",
    "        seq_acts = data[\"seq_acts\"]\n",
    "        \n",
    "        # From (#tracks x #timesteps x ...) to (#bars x #tracks x #timesteps x ...)\n",
    "        seq_tensor = seq_tensor.reshape(seq_tensor.shape[0], self.n_bars, -1,\n",
    "                                        seq_tensor.shape[2], seq_tensor.shape[3])\n",
    "        seq_tensor = seq_tensor.transpose(1, 0, 2, 3, 4)\n",
    "        seq_acts = seq_acts.reshape(seq_acts.shape[0], self.n_bars, -1)\n",
    "        seq_acts = seq_acts.transpose(1, 0, 2)\n",
    "        \n",
    "        # Construct src_key_padding_mask (PAD = 130)\n",
    "        src_mask = torch.from_numpy((seq_tensor[..., 0] == 130))\n",
    "\n",
    "        # From decimals to one-hot (pitch)\n",
    "        pitches = seq_tensor[..., 0]\n",
    "        onehot_p = np.zeros(\n",
    "            (pitches.shape[0]*pitches.shape[1]*pitches.shape[2]*pitches.shape[3],\n",
    "             131), \n",
    "            dtype=float\n",
    "        )\n",
    "        onehot_p[np.arange(0, onehot_p.shape[0]), pitches.reshape(-1)] = 1.\n",
    "        onehot_p = onehot_p.reshape(pitches.shape[0], pitches.shape[1], \n",
    "                                    pitches.shape[2], pitches.shape[3], 131)\n",
    "        \n",
    "        # From decimals to one-hot (dur)\n",
    "        durs = seq_tensor[..., 1]\n",
    "        onehot_d = np.zeros(\n",
    "            (durs.shape[0]*durs.shape[1]*durs.shape[2]*durs.shape[3],\n",
    "             99),\n",
    "            dtype=float\n",
    "        )\n",
    "        onehot_d[np.arange(0, onehot_d.shape[0]), durs.reshape(-1)] = 1.\n",
    "        onehot_d = onehot_d.reshape(durs.shape[0], durs.shape[1], \n",
    "                                    durs.shape[2], durs.shape[3], 99)\n",
    "        \n",
    "        # Concatenate pitches and durations\n",
    "        new_seq_tensor = np.concatenate((onehot_p, onehot_d),\n",
    "                                        axis=-1)\n",
    "        \n",
    "        graphs = []\n",
    "        \n",
    "        # Iterate over bars and construct a graph for each bar\n",
    "        for i in range(self.n_bars):\n",
    "            \n",
    "            # Number of nodes\n",
    "            n = torch.sum(torch.Tensor(seq_acts[i]), dtype=torch.long)\n",
    "            \n",
    "            # Get edges from boolean activations\n",
    "            # Todo: optimize and refactor\n",
    "            track_edges = self._get_track_edges(seq_acts[i])\n",
    "            onset_edges = self._get_onset_edges(seq_acts[i])\n",
    "            next_edges = self._get_next_edges(seq_acts[i])\n",
    "            #super_edges = self._get_super_edges(n)\n",
    "            edges = [track_edges, onset_edges, next_edges]\n",
    "            \n",
    "            # Concatenate edge tensors (N x 4) (if any)\n",
    "            # First two columns -> source and dest nodes\n",
    "            # Third column -> edge_type, Fourth column -> timestep distance\n",
    "            no_edges = (len(track_edges) == 0 and \n",
    "                        len(onset_edges) == 0 and len(next_edges) == 0)\n",
    "            if not no_edges:\n",
    "                edge_list = np.concatenate([x for x in edges\n",
    "                                              if x.size > 0])\n",
    "                edge_list = torch.from_numpy(edge_list)\n",
    "                \n",
    "            # Adapt tensor to torch_geometric's Data\n",
    "            # No edges: add fictitious self-edge\n",
    "            edge_index = (torch.LongTensor([[0], [0]]) if no_edges else\n",
    "                                   edge_list[:, :2].t().contiguous())\n",
    "            attrs = (torch.Tensor([[0, 0]]) if no_edges else\n",
    "                                           edge_list[:, 2:])\n",
    "\n",
    "            # One hot timestep distance concatenated to edge type\n",
    "            edge_attrs = torch.zeros(attrs.size(0), 1+seq_acts.shape[-1])\n",
    "            edge_attrs[:, 0] = attrs[:, 0]\n",
    "            edge_attrs[np.arange(edge_attrs.size(0)), attrs.long()[:, 1]+1] = 1\n",
    "            #edge_attrs = torch.Tensor(attrs.float())\n",
    "            \n",
    "            node_features = self._get_node_features(seq_acts[i], n)\n",
    "            is_drum = node_features[:, 0].bool()\n",
    "            \n",
    "            graphs.append(Data(edge_index=edge_index, edge_attrs=edge_attrs,\n",
    "                               num_nodes=n, node_features=node_features,\n",
    "                               is_drum=is_drum))\n",
    "            \n",
    "            \n",
    "        # Merge the graphs corresponding to different bars into a single big graph\n",
    "        graphs, _, inc_dict = collate(\n",
    "            Data,\n",
    "            data_list=graphs,\n",
    "            increment=True,\n",
    "            add_batch=True\n",
    "        )\n",
    "        \n",
    "        # Change bars assignment vector name (otherwise, Dataloader's collate\n",
    "        # would overwrite graphs.batch)\n",
    "        graphs.bars = graphs.batch\n",
    "        \n",
    "        # Filter silences in order to get a sparse representation\n",
    "        new_seq_tensor = new_seq_tensor.reshape(-1, new_seq_tensor.shape[-2],\n",
    "                                                new_seq_tensor.shape[-1])\n",
    "        src_mask = src_mask.reshape(-1, src_mask.shape[-1])\n",
    "        new_seq_tensor = new_seq_tensor[seq_acts.reshape(-1).astype(bool)]\n",
    "        src_mask = src_mask[seq_acts.reshape(-1).astype(bool)]\n",
    "        \n",
    "        new_seq_tensor = torch.Tensor(new_seq_tensor)\n",
    "        seq_acts = torch.Tensor(seq_acts)\n",
    "        graphs.x_seq = new_seq_tensor\n",
    "        graphs.x_acts = seq_acts\n",
    "        graphs.src_mask = src_mask\n",
    "        \n",
    "        # Todo: start with torch at mount\n",
    "        #return torch.Tensor(new_seq_tensor), torch.Tensor(seq_acts), graphs, src_mask\n",
    "        return graphs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d35dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Union, Tuple\n",
    "from torch_geometric.typing import OptTensor, Adj\n",
    "from typing import Callable\n",
    "from torch_geometric.nn.inits import reset\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Parameter as Param\n",
    "from torch.nn import Parameter\n",
    "from torch_scatter import scatter\n",
    "from torch_sparse import SparseTensor, matmul, masked_select_nnz\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "\n",
    "from torch_geometric.nn.inits import glorot, zeros\n",
    "\n",
    "\n",
    "@torch.jit._overload\n",
    "def masked_edge_index(edge_index, edge_mask):\n",
    "    # type: (Tensor, Tensor) -> Tensor\n",
    "    pass\n",
    "\n",
    "\n",
    "@torch.jit._overload\n",
    "def masked_edge_index(edge_index, edge_mask):\n",
    "    # type: (SparseTensor, Tensor) -> SparseTensor\n",
    "    pass\n",
    "\n",
    "\n",
    "def masked_edge_index(edge_index, edge_mask):\n",
    "    if isinstance(edge_index, Tensor):\n",
    "        return edge_index[:, edge_mask]\n",
    "    else:\n",
    "        return masked_select_nnz(edge_index, edge_mask, layout='coo')\n",
    "\n",
    "def masked_edge_attrs(edge_attrs, edge_mask):\n",
    "    return edge_attrs[edge_mask, :]\n",
    "\n",
    "\n",
    "class RGCNConv(MessagePassing):\n",
    "    r\"\"\"The relational graph convolutional operator from the `\"Modeling\n",
    "    Relational Data with Graph Convolutional Networks\"\n",
    "    <https://arxiv.org/abs/1703.06103>`_ paper\n",
    "\n",
    "    .. math::\n",
    "        \\mathbf{x}^{\\prime}_i = \\mathbf{\\Theta}_{\\textrm{root}} \\cdot\n",
    "        \\mathbf{x}_i + \\sum_{r \\in \\mathcal{R}} \\sum_{j \\in \\mathcal{N}_r(i)}\n",
    "        \\frac{1}{|\\mathcal{N}_r(i)|} \\mathbf{\\Theta}_r \\cdot \\mathbf{x}_j,\n",
    "\n",
    "    where :math:`\\mathcal{R}` denotes the set of relations, *i.e.* edge types.\n",
    "    Edge type needs to be a one-dimensional :obj:`torch.long` tensor which\n",
    "    stores a relation identifier\n",
    "    :math:`\\in \\{ 0, \\ldots, |\\mathcal{R}| - 1\\}` for each edge.\n",
    "\n",
    "    .. note::\n",
    "        This implementation is as memory-efficient as possible by iterating\n",
    "        over each individual relation type.\n",
    "        Therefore, it may result in low GPU utilization in case the graph has a\n",
    "        large number of relations.\n",
    "        As an alternative approach, :class:`FastRGCNConv` does not iterate over\n",
    "        each individual type, but may consume a large amount of memory to\n",
    "        compensate.\n",
    "        We advise to check out both implementations to see which one fits your\n",
    "        needs.\n",
    "\n",
    "    Args:\n",
    "        in_channels (int or tuple): Size of each input sample. A tuple\n",
    "            corresponds to the sizes of source and target dimensionalities.\n",
    "            In case no input features are given, this argument should\n",
    "            correspond to the number of nodes in your graph.\n",
    "        out_channels (int): Size of each output sample.\n",
    "        num_relations (int): Number of relations.\n",
    "        nn (torch.nn.Module): A neural network :math:`h_{\\mathbf{\\Theta}}` that\n",
    "            maps edge features :obj:`edge_attr` of shape :obj:`[-1,\n",
    "            num_edge_features]` to shape\n",
    "            :obj:`[-1, in_channels * out_channels]`, *e.g.*, defined by\n",
    "            :class:`torch.nn.Sequential`.\n",
    "        num_bases (int, optional): If set to not :obj:`None`, this layer will\n",
    "            use the basis-decomposition regularization scheme where\n",
    "            :obj:`num_bases` denotes the number of bases to use.\n",
    "            (default: :obj:`None`)\n",
    "        num_blocks (int, optional): If set to not :obj:`None`, this layer will\n",
    "            use the block-diagonal-decomposition regularization scheme where\n",
    "            :obj:`num_blocks` denotes the number of blocks to use.\n",
    "            (default: :obj:`None`)\n",
    "        aggr (string, optional): The aggregation scheme to use\n",
    "            (:obj:`\"add\"`, :obj:`\"mean\"`, :obj:`\"max\"`).\n",
    "            (default: :obj:`\"mean\"`)\n",
    "        root_weight (bool, optional): If set to :obj:`False`, the layer will\n",
    "            not add transformed root node features to the output.\n",
    "            (default: :obj:`True`)\n",
    "        bias (bool, optional): If set to :obj:`False`, the layer will not learn\n",
    "            an additive bias. (default: :obj:`True`)\n",
    "        **kwargs (optional): Additional arguments of\n",
    "            :class:`torch_geometric.nn.conv.MessagePassing`.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: Union[int, Tuple[int, int]],\n",
    "        out_channels: int,\n",
    "        num_relations: int,\n",
    "        #num_dists: int,\n",
    "        nn: Callable,\n",
    "        num_bases: Optional[int] = None,\n",
    "        num_blocks: Optional[int] = None,\n",
    "        dropout: Optional[float] = 0.1,\n",
    "        aggr: str = 'mean',\n",
    "        root_weight: bool = True,\n",
    "        bias: bool = True,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(aggr=aggr, node_dim=0, **kwargs)\n",
    "\n",
    "        if num_bases is not None and num_blocks is not None:\n",
    "            raise ValueError('Can not apply both basis-decomposition and '\n",
    "                             'block-diagonal-decomposition at the same time.')\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.nn = nn\n",
    "        #self.num_dists = num_dists\n",
    "        self.dropout = dropout\n",
    "        self.num_relations = num_relations\n",
    "        self.num_bases = num_bases\n",
    "        self.num_blocks = num_blocks\n",
    "\n",
    "        if isinstance(in_channels, int):\n",
    "            in_channels = (in_channels, in_channels)\n",
    "        self.in_channels_l = in_channels[0]\n",
    "\n",
    "        if num_bases is not None:\n",
    "            self.weight = Parameter(\n",
    "                torch.Tensor(num_bases, in_channels[0], out_channels))\n",
    "            self.comp = Parameter(torch.Tensor(num_relations, num_bases))\n",
    "        \n",
    "        elif num_blocks is not None:\n",
    "            assert (in_channels[0] % num_blocks == 0\n",
    "                    and out_channels % num_blocks == 0)\n",
    "            self.weight = Parameter(\n",
    "                torch.Tensor(num_relations, num_blocks,\n",
    "                             in_channels[0] // num_blocks,\n",
    "                             out_channels // num_blocks))\n",
    "            self.register_parameter('comp', None)\n",
    "\n",
    "        else:\n",
    "            self.weight = Parameter(\n",
    "                torch.Tensor(num_relations, in_channels[0], out_channels))\n",
    "            self.register_parameter('comp', None)\n",
    "\n",
    "        if root_weight:\n",
    "            self.root = Param(torch.Tensor(in_channels[1], out_channels))\n",
    "        else:\n",
    "            self.register_parameter('root', None)\n",
    "\n",
    "        if bias:\n",
    "            self.bias = Param(torch.Tensor(out_channels))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        \n",
    "        #self.dist_weights = Parameter(torch.Tensor(self.num_dists))\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        glorot(self.weight)\n",
    "        reset(self.nn)\n",
    "        glorot(self.comp)\n",
    "        glorot(self.root)\n",
    "        #zeros(self.dist_weights)\n",
    "        zeros(self.bias)\n",
    "\n",
    "\n",
    "    def forward(self, x: Union[OptTensor, Tuple[OptTensor, Tensor]],\n",
    "                edge_index: Adj, edge_type: OptTensor = None,\n",
    "                edge_attr: OptTensor = None):\n",
    "        r\"\"\"\n",
    "        Args:\n",
    "            x: The input node features. Can be either a :obj:`[num_nodes,\n",
    "                in_channels]` node feature matrix, or an optional\n",
    "                one-dimensional node index tensor (in which case input features\n",
    "                are treated as trainable node embeddings).\n",
    "                Furthermore, :obj:`x` can be of type :obj:`tuple` denoting\n",
    "                source and destination node features.\n",
    "            edge_type: The one-dimensional relation type/index for each edge in\n",
    "                :obj:`edge_index`.\n",
    "                Should be only :obj:`None` in case :obj:`edge_index` is of type\n",
    "                :class:`torch_sparse.tensor.SparseTensor`.\n",
    "                (default: :obj:`None`)\n",
    "        \"\"\"\n",
    "\n",
    "        # Convert input features to a pair of node features or node indices.\n",
    "        x_l: OptTensor = None\n",
    "        if isinstance(x, tuple):\n",
    "            x_l = x[0]\n",
    "        else:\n",
    "            x_l = x\n",
    "        if x_l is None:\n",
    "            x_l = torch.arange(self.in_channels_l, device=self.weight.device)\n",
    "\n",
    "        x_r: Tensor = x_l\n",
    "        if isinstance(x, tuple):\n",
    "            x_r = x[1]\n",
    "\n",
    "        size = (x_l.size(0), x_r.size(0))\n",
    "\n",
    "        if isinstance(edge_index, SparseTensor):\n",
    "            edge_type = edge_index.storage.value()\n",
    "        assert edge_type is not None\n",
    "\n",
    "        # propagate_type: (x: Tensor)\n",
    "        out = torch.zeros(x_r.size(0), self.out_channels, device=x_r.device)\n",
    "\n",
    "        weight = self.weight\n",
    "        if self.num_bases is not None:  # Basis-decomposition =================\n",
    "            weight = (self.comp @ weight.view(self.num_bases, -1)).view(\n",
    "                self.num_relations, self.in_channels_l, self.out_channels)\n",
    "\n",
    "        if self.num_blocks is not None:  # Block-diagonal-decomposition =====\n",
    "\n",
    "            if x_l.dtype == torch.long and self.num_blocks is not None:\n",
    "                raise ValueError('Block-diagonal decomposition not supported '\n",
    "                                 'for non-continuous input features.')\n",
    "\n",
    "            for i in range(self.num_relations):\n",
    "                tmp = masked_edge_index(edge_index, edge_type == i)\n",
    "                h = self.propagate(tmp, x=x_l, size=size)\n",
    "                h = h.view(-1, weight.size(1), weight.size(2))\n",
    "                h = torch.einsum('abc,bcd->abd', h, weight[i])\n",
    "                out += h.contiguous().view(-1, self.out_channels)\n",
    "\n",
    "        else:  # No regularization/Basis-decomposition ========================\n",
    "            for i in range(self.num_relations):\n",
    "                tmp = masked_edge_index(edge_index, edge_type == i)\n",
    "                attr = masked_edge_attrs(edge_attr, edge_type == i)\n",
    "\n",
    "                if x_l.dtype == torch.long:\n",
    "                    out += self.propagate(tmp, x=weight[i, x_l], size=size)\n",
    "                else:\n",
    "                    h = self.propagate(tmp, x=x_l, size=size,\n",
    "                                       edge_attr=attr)\n",
    "                    out = out + (h @ weight[i])\n",
    "\n",
    "        root = self.root\n",
    "        if root is not None:\n",
    "            out += root[x_r] if x_r.dtype == torch.long else x_r @ root\n",
    "\n",
    "        if self.bias is not None:\n",
    "            out += self.bias\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "    def message(self, x_j: Tensor, edge_attr: Tensor) -> Tensor:\n",
    "        #weights = self.dist_weights[edge_attr.view(-1).long()]\n",
    "        #weights = torch.diag(weights)\n",
    "        #return torch.matmul(weights, x_j)\n",
    "        weights = self.nn(edge_attr)\n",
    "        weights = weights[..., :self.in_channels_l]\n",
    "        weights = weights.view(-1, self.in_channels_l)\n",
    "        ret = x_j * weights\n",
    "        ret = F.relu(ret)\n",
    "        ret = F.dropout(ret, p=self.dropout, training=self.training)\n",
    "        return ret\n",
    "    \n",
    "        \n",
    "        \n",
    "    def message_and_aggregate(self, adj_t: SparseTensor, x: Tensor) -> Tensor:\n",
    "        adj_t = adj_t.set_value(None, layout=None)\n",
    "        return matmul(adj_t, x, reduce=self.aggr)\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return (f'{self.__class__.__name__}({self.in_channels}, '\n",
    "                f'{self.out_channels}, num_relations={self.num_relations})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007f1aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch_geometric.nn.conv import GCNConv#, RGCNConv\n",
    "from torch_geometric.nn.norm import BatchNorm\n",
    "from torch_geometric.nn.glob import GlobalAttention\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import torch.optim as optim\n",
    "from torch_scatter import scatter_mean\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\n",
    "\n",
    "\n",
    "# Todo: check and think about max_len\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 256):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) *                     \\\n",
    "                             (-math.log(10000.0)/d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position*div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position*div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor, shape [seq_len, batch_size, embedding_dim]\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)\n",
    "    \n",
    "\n",
    "class MLP(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim=256, hidden_dim=256, output_dim=256, num_layers=2,\n",
    "                 act=True, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        assert num_layers >= 1\n",
    "        \n",
    "        self.layers = nn.ModuleList()\n",
    "        \n",
    "        if num_layers == 1:\n",
    "            self.layers.append(nn.Linear(input_dim, output_dim))\n",
    "        else:\n",
    "            self.layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "        \n",
    "            for i in range(num_layers-2):\n",
    "                self.layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "\n",
    "            self.layers.append(nn.Linear(hidden_dim, output_dim))\n",
    "        \n",
    "        self.act = act\n",
    "        self.p = dropout\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            x = F.dropout(x, p=self.p, training=self.training)\n",
    "            x = layer(x)\n",
    "            if self.act:\n",
    "                x = F.relu(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    \n",
    "class EncoderRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size=240, hidden_size=256, num_layers=2, \n",
    "                 dropout=0.1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Linear(input_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, batch_first=True,\n",
    "                            num_layers=num_layers, bidirectional=True)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        embedded = self.embedding(x).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.lstm(output, hidden)\n",
    "        return output, hidden\n",
    "    \n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_size=256, output_size=240, num_layers=2, \n",
    "                 dropout=0.1):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Linear(output_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, batch_first=True,\n",
    "                            num_layers=num_layers, bidirectional=True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        output = self.embedding(x).view(1, 1, -1)\n",
    "        output, hidden = self.lstm(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "\n",
    "class GraphEncoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim=256, hidden_dim=256, n_layers=3, \n",
    "                 num_relations=3, num_dists=32, batch_norm=False, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.layers = nn.ModuleList()\n",
    "        self.norm_layers = nn.ModuleList()\n",
    "        edge_nn = nn.Linear(num_dists, input_dim)\n",
    "        self.batch_norm = batch_norm\n",
    "        \n",
    "        self.layers.append(RGCNConv(input_dim, hidden_dim,\n",
    "                                    num_relations, edge_nn))\n",
    "        if self.batch_norm:\n",
    "            self.norm_layers.append(BatchNorm(hidden_dim))\n",
    "        \n",
    "        for i in range(n_layers-1):\n",
    "            #edge_nn = nn.Linear(num_dists, input_dim)\n",
    "            self.layers.append(RGCNConv(hidden_dim, hidden_dim,\n",
    "                                        num_relations, edge_nn))\n",
    "            if self.batch_norm:\n",
    "                self.norm_layers.append(BatchNorm(hidden_dim))\n",
    "            \n",
    "        self.p = dropout\n",
    "        \n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attrs = data.x, data.edge_index, data.edge_attrs\n",
    "        #batch = data.distinct_bars\n",
    "        edge_type = edge_attrs[:, 0]\n",
    "        edge_attr = edge_attrs[:, 1:]\n",
    "        \n",
    "        for i in range(len(self.layers)):\n",
    "            residual = x\n",
    "            x = F.dropout(x, p=self.p, training=self.training)\n",
    "            x = self.layers[i](x, edge_index, edge_type, edge_attr)\n",
    "            if self.batch_norm:\n",
    "                x = self.norm_layers[i](x)\n",
    "            x = F.relu(x)\n",
    "            x = residual + x\n",
    "\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class CNNEncoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, output_dim=256, dense_dim=256, batch_norm=False,\n",
    "                 dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        if batch_norm:\n",
    "            self.conv = nn.Sequential(\n",
    "                # 4*32 --> 8*4*32\n",
    "                nn.Conv2d(1, 8, 3, padding=1),\n",
    "                nn.BatchNorm2d(8),\n",
    "                nn.ReLU(True),\n",
    "                # 8*4*32 --> 8*4*8\n",
    "                nn.MaxPool2d((1, 4), stride=(1, 4)),\n",
    "                # 8*4*8 --> 16*4*8\n",
    "                nn.Conv2d(8, 16, 3, padding=1),\n",
    "                nn.BatchNorm2d(16),\n",
    "                nn.ReLU(True)\n",
    "            )\n",
    "        else:\n",
    "            self.conv = nn.Sequential(\n",
    "                # 4*32 --> 8*4*32\n",
    "                nn.Conv2d(1, 8, 3, padding=1),\n",
    "                nn.ReLU(True),\n",
    "                # 8*4*32 --> 8*4*8\n",
    "                nn.MaxPool2d((1, 4), stride=(1, 4)),\n",
    "                # 8*4*8 --> 16*4*8\n",
    "                nn.Conv2d(8, 16, 3, padding=1),\n",
    "                nn.ReLU(True)\n",
    "            )\n",
    "        \n",
    "        self.flatten = nn.Flatten(start_dim=1)\n",
    "        \n",
    "        self.lin = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(16*4*8, dense_dim),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(dense_dim, output_dim)\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.conv(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.lin(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "\n",
    "class CNNDecoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim=256, dense_dim=256, batch_norm=False,\n",
    "                 dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.lin = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(input_dim, dense_dim),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(dense_dim, 16*4*8),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "        self.unflatten = nn.Unflatten(dim=1, unflattened_size=(16, 4, 8))\n",
    "\n",
    "        if batch_norm:\n",
    "            self.conv = nn.Sequential(\n",
    "                nn.Upsample(scale_factor=(1, 4), mode='nearest'),\n",
    "                nn.Conv2d(16, 8, 3, padding=1),\n",
    "                nn.BatchNorm2d(8),\n",
    "                nn.ReLU(True),\n",
    "                nn.Conv2d(8, 1, 3, padding=1)\n",
    "            )\n",
    "        else:\n",
    "            self.conv = nn.Sequential(\n",
    "                nn.Upsample(scale_factor=(1, 4), mode='nearest'),\n",
    "                nn.Conv2d(16, 8, 3, padding=1),\n",
    "                nn.ReLU(True),\n",
    "                nn.Conv2d(8, 1, 3, padding=1)\n",
    "            )\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.lin(x)\n",
    "        x = self.unflatten(x)\n",
    "        x = self.conv(x)\n",
    "        \n",
    "        return x.unsqueeze(1)\n",
    "        \n",
    "\n",
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.__dict__.update(kwargs)\n",
    "        \n",
    "        self.dropout_layer = nn.Dropout(p=self.dropout)\n",
    "        \n",
    "        \n",
    "        self.notes_pitch_emb = nn.Linear(self.d_token_pitches, \n",
    "                                               self.d//2)\n",
    "        \n",
    "        self.bn_npe = nn.BatchNorm1d(num_features=self.d//2)\n",
    "        \n",
    "        self.drums_pitch_emb = nn.Linear(self.d_token_pitches, \n",
    "                                               self.d//2)\n",
    "        \n",
    "        self.bn_dpe = nn.BatchNorm1d(num_features=self.d//2)\n",
    "        \n",
    "        self.dur_emb = nn.Linear(self.d_token_dur, self.d//2)\n",
    "        \n",
    "        self.bn_de = nn.BatchNorm1d(num_features=self.d//2)\n",
    "        \n",
    "        self.chord_encoder = nn.Linear(self.d * (self.max_simu_notes-1),\n",
    "                                       self.d)\n",
    "\n",
    "        # Graph encoder\n",
    "        self.graph_encoder = GraphEncoder(dropout=self.dropout, \n",
    "                                          input_dim=self.d,\n",
    "                                          hidden_dim=self.d,\n",
    "                                          n_layers=self.gnn_n_layers,\n",
    "                                          num_relations=self.n_relations,\n",
    "                                          batch_norm=self.batch_norm)\n",
    "        \n",
    "        gate_nn = nn.Sequential(\n",
    "            MLP(input_dim=self.d, output_dim=1, num_layers=1, act=False,\n",
    "                      dropout=self.dropout),\n",
    "            nn.BatchNorm1d(1)\n",
    "        )\n",
    "        self.graph_attention = GlobalAttention(gate_nn)\n",
    "        \n",
    "        #self.context_bar_rnn = nn.GRU(input_size=self.d,\n",
    "        #                              hidden_size=self.d//2,\n",
    "        #                              num_layers=1,\n",
    "        #                              bidirectional=True,\n",
    "        #                              batch_first=True, \n",
    "        #                              dropout=self.dropout)\n",
    "        \n",
    "        self.bars_encoder_attr = nn.Linear(self.n_bars*self.d,\n",
    "                                           self.d)\n",
    "        \n",
    "        \n",
    "        self.cnn_encoder = CNNEncoder(dense_dim=self.d,\n",
    "                                      output_dim=self.d,\n",
    "                                      dropout=0,\n",
    "                                      batch_norm=self.batch_norm)\n",
    "        \n",
    "        self.bars_encoder_struct = nn.Linear(self.n_bars*self.d,\n",
    "                                             self.d)\n",
    "        #self.struct_bar_rnn = nn.GRU(input_size=self.d,\n",
    "        #                              hidden_size=self.d//2,\n",
    "        #                              num_layers=1,\n",
    "        #                              batch_first=True, \n",
    "        #                              dropout=self.dropout)\n",
    "        \n",
    "        self.linear_merge = nn.Linear(2*self.d, self.d)\n",
    "        \n",
    "        self.bn_lm = nn.BatchNorm1d(num_features=self.d)\n",
    "        \n",
    "        # Linear layers that compute the final mu and log_var\n",
    "        # Todo: as parameters\n",
    "        self.linear_mu = nn.Linear(self.d, self.d)\n",
    "        self.linear_log_var = nn.Linear(self.d, self.d)\n",
    "\n",
    "        \n",
    "    def forward(self, x_seq, x_acts, x_graph, src_mask):\n",
    "        \n",
    "        # No start of seq token\n",
    "        x_seq = x_seq[:, 1:, :]\n",
    "        \n",
    "        # Get drums and non drums tensors\n",
    "        drums = x_seq[x_graph.is_drum]\n",
    "        src_mask_drums = src_mask[x_graph.is_drum]\n",
    "        non_drums = x_seq[torch.logical_not(x_graph.is_drum)]\n",
    "        src_mask_non_drums = src_mask[torch.logical_not(x_graph.is_drum)]\n",
    "        \n",
    "        # Permute dimensions to batch_first = False\n",
    "        #drums = drums.permute(1, 0, 2)\n",
    "        #non_drums = non_drums.permute(1, 0, 2)\n",
    "        \n",
    "        # Compute note/drums embeddings\n",
    "        s = drums.size()\n",
    "        drums_pitch = self.drums_pitch_emb(drums[..., :self.d_token_pitches])\n",
    "        drums_pitch = self.bn_dpe(drums_pitch.view(-1, self.d//2))\n",
    "        drums_pitch = drums_pitch.view(s[0], s[1], self.d//2)\n",
    "        drums_dur = self.dur_emb(drums[..., self.d_token_pitches:])\n",
    "        drums_dur = self.bn_de(drums_dur.view(-1, self.d//2))\n",
    "        drums_dur = drums_dur.view(s[0], s[1], self.d//2)\n",
    "        drums = torch.cat((drums_pitch, drums_dur), dim=-1)\n",
    "        #drums = self.dropout_layer(drums)\n",
    "        # [n_nodes x max_simu_notes x d]\n",
    "        \n",
    "        s = non_drums.size()\n",
    "        non_drums_pitch = self.notes_pitch_emb(non_drums[..., :self.d_token_pitches])\n",
    "        non_drums_pitch = self.bn_npe(non_drums_pitch.view(-1, self.d//2))\n",
    "        non_drums_pitch = non_drums_pitch.view(s[0], s[1], self.d//2)\n",
    "        non_drums_dur = self.dur_emb(non_drums[..., self.d_token_pitches:])\n",
    "        non_drums_dur = self.bn_de(non_drums_dur.view(-1, self.d//2))\n",
    "        non_drums_dur = non_drums_dur.view(s[0], s[1], self.d//2)\n",
    "        non_drums = torch.cat((non_drums_pitch, non_drums_dur), dim=-1)\n",
    "        #non_drums = self.dropout_layer(non_drums)\n",
    "        # [n_nodes x max_simu_notes x d]\n",
    "        \n",
    "        #len_drums = self.max_simu_notes - torch.sum(src_mask_drums, dim=1)\n",
    "        #len_non_drums = self.max_simu_notes - torch.sum(src_mask_non_drums, dim=1)\n",
    "        \n",
    "        #drums = pack_padded_sequence(drums, len_drums.cpu().view(-1),\n",
    "        #                             enforce_sorted=False)\n",
    "        #non_drums = pack_padded_sequence(non_drums, len_non_drums.cpu().view(-1),\n",
    "        #                                 enforce_sorted=False)\n",
    "\n",
    "        # Compute chord embeddings both for drums and non drums\n",
    "        drums = self.chord_encoder(drums.view(-1, self.d*(self.max_simu_notes-1)))\n",
    "        non_drums = self.chord_encoder(non_drums.view(-1, self.d*(self.max_simu_notes-1)))\n",
    "        drums = F.relu(drums)\n",
    "        non_drums = F.relu(non_drums)\n",
    "        drums = self.dropout_layer(drums)\n",
    "        non_drums = self.dropout_layer(non_drums)\n",
    "        # [n_nodes x d]\n",
    "        \n",
    "        #hidden = torch.zeros(drums.size(1), )\n",
    "        #drums = self.chord_encoder_drums(drums)[-1]\n",
    "        #non_drums = self.chord_encoder(non_drums)[-1]\n",
    "        #drums = torch.mean(drums, dim=0)\n",
    "        #non_drums = torch.mean(non_drums, dim=0)\n",
    "        \n",
    "        #drums = self.dropout_layer(drums)\n",
    "        #non_drums = self.dropout_layer(non_drums)\n",
    "        \n",
    "        # Merge drums and non-drums\n",
    "        #out = torch.zeros((x_seq.size(0), self.d_model), \n",
    "        #                  device=self.device)\n",
    "        out = torch.zeros((x_seq.size(0), self.d), \n",
    "                          device=self.device, dtype=torch.half)\n",
    "        out[x_graph.is_drum] = drums\n",
    "        out[torch.logical_not(x_graph.is_drum)] = non_drums\n",
    "        # [n_nodes x d]\n",
    "        \n",
    "        #x_graph.x = torch.cat((x_graph.node_features, out), 1)\n",
    "        x_graph.x = out\n",
    "        x_graph.distinct_bars = x_graph.bars + self.n_bars*x_graph.batch\n",
    "        out = self.graph_encoder(x_graph)\n",
    "        # [n_nodes x d]\n",
    "        \n",
    "        with torch.cuda.amp.autocast(enabled=False):\n",
    "            out = self.graph_attention(out,\n",
    "                                       batch=x_graph.distinct_bars)\n",
    "            # [bs x n_bars x d]\n",
    "            \n",
    "        out = out.view(-1, self.n_bars * self.d)\n",
    "        # [bs x n_bars * d]\n",
    "        out_attr = self.bars_encoder_attr(out)\n",
    "        # [bs x d]\n",
    "        \n",
    "        # Process structure\n",
    "        out = self.cnn_encoder(x_acts.view(-1, self.n_tracks,\n",
    "                                                self.resolution*4))\n",
    "        # [bs * n_bars x d]\n",
    "        out = out.view(-1, self.n_bars * self.d)\n",
    "        # [bs x n_bars * d]\n",
    "        out_struct = self.bars_encoder_struct(out)\n",
    "        # [bs x d]\n",
    "        \n",
    "        # Merge attr state and struct state\n",
    "        out = torch.cat((out_attr, out_struct), dim=1)\n",
    "        out = self.dropout_layer(out)\n",
    "        out = self.linear_merge(out)\n",
    "        out = self.bn_lm(out)\n",
    "        out = F.relu(out)\n",
    "\n",
    "        # Compute mu and log(std^2)\n",
    "        out = self.dropout_layer(out)\n",
    "        mu = self.linear_mu(out)\n",
    "        log_var = self.linear_log_var(out)\n",
    "        \n",
    "        return mu, log_var\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.__dict__.update(kwargs)\n",
    "        \n",
    "        self.dropout_layer = nn.Dropout(p=self.dropout)\n",
    "\n",
    "        self.lin_divide = nn.Linear(self.d, 2 * self.d)\n",
    "        \n",
    "        self.bn_ld = nn.BatchNorm1d(num_features=2*self.d)\n",
    "        \n",
    "        self.bars_decoder_attr = nn.Linear(self.d, self.d * self.n_bars)\n",
    "        #self.context_bar_rnn = nn.GRU(input_size=self.d,\n",
    "        #                              hidden_size=self.d//2,\n",
    "        #                              num_layers=1,\n",
    "        #                              bidirectional=True,\n",
    "        #                              batch_first=True,\n",
    "        #                              dropout=self.dropout)\n",
    "        \n",
    "        self.bars_decoder_struct = nn.Linear(self.d, self.d * self.n_bars)\n",
    "        #self.struct_bar_rnn = nn.GRU(input_size=self.d//2,\n",
    "        #                              hidden_size=self.d//2,\n",
    "        #                              num_layers=1,\n",
    "        #                              batch_first=True,\n",
    "        #                              dropout=self.dropout)\n",
    "        \n",
    "        self.cnn_decoder = CNNDecoder(input_dim=self.d,\n",
    "                                      dense_dim=self.d,\n",
    "                                      dropout=0,\n",
    "                                      batch_norm=self.batch_norm)\n",
    "        \n",
    "        self.graph_decoder = GraphEncoder(dropout=self.dropout,\n",
    "                                          input_dim=self.d,\n",
    "                                          hidden_dim=self.d,\n",
    "                                          n_layers=self.gnn_n_layers,\n",
    "                                          num_relations=self.n_relations,\n",
    "                                          batch_norm=self.batch_norm)\n",
    "        \n",
    "        #gate_nn = nn.Sequential(\n",
    "        #    MLP(input_dim=self.d, output_dim=1, num_layers=1, act=False,\n",
    "        #              dropout=self.dropout),\n",
    "        #    nn.BatchNorm1d(1)\n",
    "        #)\n",
    "        #feat_nn = nn.Sequential(\n",
    "        #    MLP(input_dim=self.d, output_dim=self.d//2, num_layers=1,\n",
    "        #              dropout=self.dropout),\n",
    "        #    nn.BatchNorm1d(self.d//2)\n",
    "        #)\n",
    "        #self.graph_attention = GlobalAttention(gate_nn, feat_nn)\n",
    "        \n",
    "        self.chord_decoder = nn.Linear(self.d, self.d*(self.max_simu_notes-1))\n",
    "        #self.chord_decoder = nn.GRU(input_size=self.d,\n",
    "        #                            hidden_size=self.d,\n",
    "        #                            num_layers=1,\n",
    "        #                            dropout=self.dropout)\n",
    "        #self.chord_decoder_drums = nn.GRU(input_size=self.d,\n",
    "        #                                  hidden_size=self.d,\n",
    "        #                                  num_layers=1,\n",
    "        #                                  dropout=self.dropout)\n",
    "        \n",
    "        # Pitch and dur linear layers\n",
    "        self.drums_pitch_emb = nn.Linear(self.d//2, self.d_token_pitches)\n",
    "        self.notes_pitch_emb = nn.Linear(self.d//2, self.d_token_pitches)\n",
    "        self.dur_emb = nn.Linear(self.d//2, self.d_token_dur)\n",
    "        \n",
    "        \n",
    "    def forward_struct(self, z):\n",
    "        # z: [bs x d]\n",
    "        \n",
    "        # Obtain z_structure and z_attributes from z\n",
    "        #z = self.dropout_layer(z)\n",
    "        z = self.lin_divide(z)\n",
    "        z = self.bn_ld(z)\n",
    "        z = F.relu(z)\n",
    "        z = self.dropout_layer(z)\n",
    "        # [bs x 2*d]\n",
    "        \n",
    "        out_struct = z[:, :self.d]\n",
    "        # [bs x d] \n",
    "        out_struct = self.bars_decoder_struct(out_struct)\n",
    "        # [bs x n_bars * d]\n",
    "        \n",
    "        out_struct = self.cnn_decoder(out_struct.reshape(-1, self.d))\n",
    "        \n",
    "        return out_struct\n",
    "\n",
    "\n",
    "    def forward(self, z, x_seq, x_acts, x_graph, src_mask, tgt_mask,\n",
    "                inference=False):\n",
    "        # z: [bs x d]\n",
    "        \n",
    "        # Obtain z_structure and z_attributes from z\n",
    "        #z = self.dropout_layer(z)\n",
    "        z = self.lin_divide(z)\n",
    "        z = self.bn_ld(z)\n",
    "        z = F.relu(z)\n",
    "        z = self.dropout_layer(z)\n",
    "        # [bs x 2*d]\n",
    "        \n",
    "        out_struct = z[:, :self.d]\n",
    "        # [bs x d] \n",
    "        out_struct = self.bars_decoder_struct(out_struct)\n",
    "        # [bs x n_bars * d]\n",
    "        \n",
    "        out_struct = self.cnn_decoder(out_struct.reshape(-1, self.d))\n",
    "        out_struct = out_struct.view(x_acts.size())\n",
    "        \n",
    "        # Decode attributes\n",
    "        out = z[:, self.d:]\n",
    "        # [bs x d]\n",
    "        out = self.bars_decoder_attr(out)\n",
    "        # [bs x n_bars * d]\n",
    "        \n",
    "        # Initialize node features with corresponding z_bar\n",
    "        # and propagate with GNN\n",
    "        _, counts = torch.unique(x_graph.distinct_bars, return_counts=True)\n",
    "        out = out.view(-1, self.d)\n",
    "        out = torch.repeat_interleave(out, counts, axis=0)\n",
    "        # [n_nodes x d]\n",
    "        \n",
    "        # Add one-hot encoding of tracks\n",
    "        # Todo: use also edge info\n",
    "        #x_graph.x = torch.cat((x_graph.node_features, out), 1)\n",
    "        x_graph.x = out\n",
    "        out = self.graph_decoder(x_graph)\n",
    "        # [n_nodes x d]\n",
    "        #print(\"Node decodings:\", node_decs.size())\n",
    "        \n",
    "        \n",
    "        #out = torch.matmul(out, self.chord_decoder.weight)\n",
    "        out = self.chord_decoder(out)\n",
    "        # [n_nodes x max_simu_notes * d]\n",
    "        out = out.view(-1, self.max_simu_notes-1, self.d)\n",
    "        \n",
    "        drums = out[x_graph.is_drum]\n",
    "        non_drums = out[torch.logical_not(x_graph.is_drum)]\n",
    "        # [n_nodes(dr/non_dr) x max_simu_notes x d]\n",
    "        \n",
    "        # Obtain final pitch and dur decodings\n",
    "        # (softmax to be applied outside the model)\n",
    "        non_drums = self.dropout_layer(non_drums)\n",
    "        drums = self.dropout_layer(drums)\n",
    "        \n",
    "        drums_pitch = self.drums_pitch_emb(drums[..., :self.d//2])\n",
    "        drums_dur = self.dur_emb(drums[..., self.d//2:])\n",
    "        drums = torch.cat((drums_pitch, drums_dur), dim=-1)\n",
    "        #drums_pitch = torch.matmul(drums[..., :self.d//2], self.drums_pitch_emb.weight)\n",
    "        #drums_dur = torch.matmul(drums[..., self.d//2:], self.dur_emb.weight)\n",
    "        #drums = torch.cat((drums_pitch, drums_dur), dim=-1)\n",
    "        # [n_nodes(dr) x max_simu_notes x d_token]\n",
    "        non_drums_pitch = self.notes_pitch_emb(non_drums[..., :self.d//2])\n",
    "        non_drums_dur = self.dur_emb(non_drums[..., self.d//2:])\n",
    "        non_drums = torch.cat((non_drums_pitch, non_drums_dur), dim=-1)\n",
    "        #non_drums_pitch = torch.matmul(non_drums[..., :self.d//2], self.notes_pitch_emb.weight)\n",
    "        #non_drums_dur = torch.matmul(non_drums[..., self.d//2:], self.dur_emb.weight)\n",
    "        #non_drums = torch.cat((non_drums_pitch, non_drums_dur), dim=-1)\n",
    "        # [n_nodes(non_dr) x max_simu_notes x d_token]\n",
    "        \n",
    "        # Merge drums and non-drums\n",
    "        out = torch.zeros((x_seq.size(0), x_seq.size(1), x_seq.size(2)),\n",
    "                          device=self.device, dtype=torch.half)\n",
    "        out[x_graph.is_drum] = drums\n",
    "        out[torch.logical_not(x_graph.is_drum)] = non_drums\n",
    "        \n",
    "        out = out.view(x_seq.size())\n",
    "\n",
    "        return out, out_struct\n",
    "\n",
    "\n",
    "class VAE(nn.Module):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = Encoder(**kwargs)\n",
    "        self.decoder = Decoder(\n",
    "            **kwargs\n",
    "        )\n",
    "    \n",
    "    \n",
    "    def forward(self, x_seq, x_acts, x_graph, src_mask, tgt_mask,\n",
    "                inference=False):\n",
    "        \n",
    "        #src_mask = src_mask.view(-1, src_mask.size(-1))\n",
    "        \n",
    "        # Encoder pass\n",
    "        mu, log_var = self.encoder(x_seq, x_acts, x_graph, src_mask)\n",
    "        \n",
    "        # Reparameterization trick\n",
    "        z = torch.exp(0.5*log_var)\n",
    "        z = z * torch.randn_like(z)\n",
    "        #print(\"eps:\", eps.size())\n",
    "        z = z + mu\n",
    "        \n",
    "        # Shifting target sequence and mask for transformer decoder\n",
    "        tgt = x_seq[..., :-1, :]\n",
    "        src_mask = src_mask[:, :-1]\n",
    "        \n",
    "        # Decoder pass\n",
    "        out = self.decoder(z, tgt, x_acts, x_graph, src_mask, tgt_mask,\n",
    "                           inference=inference)\n",
    "        \n",
    "        return out, mu, log_var\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e439a46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "\n",
    "def print_params(model):\n",
    "    \n",
    "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
    "    total_params = 0\n",
    "    \n",
    "    for name, parameter in model.named_parameters():\n",
    "        \n",
    "        if not parameter.requires_grad:\n",
    "            continue\n",
    "            \n",
    "        param = parameter.numel()\n",
    "        table.add_row([name, param])\n",
    "        total_params += param\n",
    "        \n",
    "    print(table)\n",
    "    print(f\"Total Trainable Params: {total_params}\")\n",
    "    \n",
    "    return total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4846b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_square_subsequent_mask(sz):\n",
    "    \"\"\"Generates an upper-triangular matrix of -inf, with zeros on diag.\"\"\"\n",
    "    return torch.triu(torch.ones(sz, sz) * float('-inf'), diagonal=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7076bfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'models/2barsGNNDEF/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca9fcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(os.path.join(model, 'checkpoint'), map_location='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e258528",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = checkpoint['model_state_dict']\n",
    "params = torch.load(os.path.join(model, 'params'), map_location='cpu')\n",
    "vae = VAE(**params['model'], device=device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7315f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c2bb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.load_state_dict(state_dict)\n",
    "vae.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9b96c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Subset\n",
    "import numpy as np\n",
    "import os\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "n_bars = 2\n",
    "bs = 256\n",
    "nw = 4\n",
    "\n",
    "ds_dir = \"/data/cosenza/datasets/preprocessed_2bars/\"\n",
    "dataset = MIDIDataset(ds_dir, n_bars=n_bars)\n",
    "print('Dataset len:', len(dataset))\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=bs, shuffle=False, num_workers=nw)\n",
    "#print(len(subset))\n",
    "\n",
    "\n",
    "train_len = int(0.7 * len(dataset)) \n",
    "valid_len = int(0.01 * len(dataset))\n",
    "test_len = len(dataset) - train_len - valid_len\n",
    "#train_dataset, valid_dataset, test_dataset = random_split(model_dataset, (train_count, valid_count, test_count))\n",
    "tr_set, vl_set, ts_set = random_split(dataset, (train_len, valid_len, test_len))\n",
    "\n",
    "trainloader = DataLoader(tr_set, batch_size=bs, shuffle=True, num_workers=nw)\n",
    "validloader = DataLoader(vl_set, batch_size=bs, shuffle=False, num_workers=nw)\n",
    "#testloader = DataLoader(ts_set, batch_size=64, shuffle=False, num_workers=4)\n",
    "\n",
    "tr_len = len(tr_set)\n",
    "vl_len = len(vl_set)\n",
    "ts_len = len(ts_set)\n",
    "\n",
    "print('TR set len:', len(tr_set))\n",
    "print('VL set len:', len(vl_set))\n",
    "print('TS set len:', len(ts_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee356a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for idx, inputs in enumerate(trainloader):\n",
    "\n",
    "        x_graph = inputs.to(device)\n",
    "        x_seq, x_acts, src_mask = x_graph.x_seq, x_graph.x_acts, x_graph.src_mask\n",
    "        tgt_mask = generate_square_subsequent_mask(x_seq.size(-2)-1).to(device)\n",
    "\n",
    "        # Forward pass, get the reconstructions\n",
    "        with torch.cuda.amp.autocast():\n",
    "            outputs, mu, log_var = vae(x_seq, x_acts, x_graph, src_mask, tgt_mask)\n",
    "\n",
    "        break\n",
    "    \n",
    "\n",
    "seq_rec, acts_rec  = outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185ee4d2",
   "metadata": {},
   "source": [
    "Reconstruct activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafe2bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pitches_accuracy(seq_rec, x_seq, is_drum=None, drums=None):\n",
    "        \n",
    "    if drums is not None:\n",
    "        if drums:\n",
    "            seq_rec = seq_rec[is_drum]\n",
    "            x_seq = x_seq[is_drum]\n",
    "        else:\n",
    "            seq_rec = seq_rec[torch.logical_not(is_drum)]\n",
    "            x_seq = x_seq[torch.logical_not(is_drum)]\n",
    "\n",
    "    pitches_rec = F.softmax(seq_rec[..., :131], dim=-1)\n",
    "    pitches_rec = torch.argmax(pitches_rec, dim=-1)\n",
    "    pitches_true = torch.argmax(x_seq[..., :131], dim=-1)\n",
    "\n",
    "    #print(\"All EOS pitches?\", torch.all(pitches_rec == 129))\n",
    "\n",
    "    mask = (pitches_true != 130)\n",
    "    #mask = torch.logical_and(pitches_true != 128,\n",
    "     #                        pitches_true != 129)\n",
    "    #mask = torch.logical_and(mask,\n",
    "     #                        pitches_true != 130)\n",
    "\n",
    "    preds_pitches = (pitches_rec == pitches_true)\n",
    "    preds_pitches = torch.logical_and(preds_pitches, mask)\n",
    "\n",
    "    return torch.sum(preds_pitches) / torch.sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1ee032",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_seq = x_seq[..., 1:, :]\n",
    "_pitches_accuracy(seq_rec, new_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d6ee60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "print(acts_rec.size())\n",
    "print(x_acts.size())\n",
    "print(x_seq.size())\n",
    "print(seq_rec.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39579d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_struct(s):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.pcolormesh(s.detach().cpu().numpy(), edgecolors='k', linewidth=1)\n",
    "    ax = plt.gca()\n",
    "    ax.set_aspect('equal')\n",
    "    plt.xticks(range(0, s.size(1), 8), range(1, 5))\n",
    "    plt.yticks(range(0, 4), range(1, 5))\n",
    "    ax.invert_yaxis()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2dcd9c9",
   "metadata": {},
   "source": [
    "Reconstructed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c225d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = torch.sigmoid(acts_rec[3])\n",
    "s[s > 0.5] = 1\n",
    "s[s <= 0.5] = 0\n",
    "\n",
    "plot_struct(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68c2e43",
   "metadata": {},
   "source": [
    "Real:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02410420",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = x_acts[3]\n",
    "plot_struct(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42d20d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct dense reconstruction from sparse representation\n",
    "\n",
    "def dense_from_sparse(seq, acts, bars):\n",
    "    \n",
    "    dtype = seq.dtype\n",
    "    \n",
    "    acts = acts.view(-1, bars, acts.size(-2), acts.size(-1))\n",
    "    dtype = seq.dtype\n",
    "    seq_dense = torch.zeros((acts.size(0), acts.size(1), acts.size(2),\n",
    "                             acts.size(3), seq.size(-2), seq.size(-1)),\n",
    "                            dtype=dtype).to(device)\n",
    "\n",
    "    size = seq_dense.size()\n",
    "\n",
    "    seq_dense = seq_dense.view(-1, seq_dense.size(-2), seq_dense.size(-1))\n",
    "\n",
    "    silence = torch.zeros((seq_dense.size(-2), seq_dense.size(-1)),\n",
    "                            dtype=dtype).to(device)\n",
    "    silence[:, 129] = 1. # eos token\n",
    "\n",
    "    seq_dense[acts.bool().view(-1)] = seq\n",
    "    seq_dense[torch.logical_not(acts.bool().view(-1))] = silence\n",
    "\n",
    "    seq_dense = seq_dense.view(size)\n",
    "    \n",
    "    return seq_dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c280aeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_rec_dense = dense_from_sparse(seq_rec, x_acts, bars=n_bars)\n",
    "x_seq_dense = dense_from_sparse(x_seq, x_acts, bars=n_bars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ccb213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collapse bars dimension\n",
    "seq_rec_dense = seq_rec_dense.permute(0, 2, 1, 3, 4, 5)\n",
    "x_seq_dense = x_seq_dense.permute(0, 2, 1, 3, 4, 5)\n",
    "\n",
    "print(seq_rec_dense.size())\n",
    "\n",
    "size = [\n",
    "    seq_rec_dense.size(0),\n",
    "    seq_rec_dense.size(1),\n",
    "    -1,\n",
    "    seq_rec_dense.size(4),\n",
    "    seq_rec_dense.size(5)\n",
    "]\n",
    "\n",
    "seq_rec_dense = seq_rec_dense.reshape(size)\n",
    "size[-2] = x_seq_dense.size(-2)\n",
    "x_seq_dense = x_seq_dense.reshape(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47b9002",
   "metadata": {},
   "outputs": [],
   "source": [
    "music_real = x_seq_dense[12]\n",
    "music_rec = seq_rec_dense[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9a645f",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESOLUTION = 8\n",
    "\n",
    "#tracks = [drum_track, bass_track, guitar_track, strings_track]\n",
    "import copy\n",
    "\n",
    "def from_tensor_to_muspy(music_tensor, track_data):\n",
    "    \n",
    "    tracks = []\n",
    "    \n",
    "    for tr in range(music_tensor.size(0)):\n",
    "        \n",
    "        notes = []\n",
    "        \n",
    "        for ts in range(music_tensor.size(1)):\n",
    "            for note in range(music_tensor.size(2)):\n",
    "                \n",
    "                pitch = music_tensor[tr, ts, note, :131]\n",
    "                pitch = torch.argmax(pitch)\n",
    "\n",
    "                if pitch == 129:\n",
    "                    break\n",
    "                \n",
    "                if pitch != 128:\n",
    "                    dur = music_tensor[tr, ts, note, 131:]\n",
    "                    dur = torch.argmax(dur) + 1\n",
    "                    \n",
    "                    if dur == 97 or dur == 98 or dur == 99:\n",
    "                        dur = 4\n",
    "                        continue\n",
    "                    \n",
    "                    notes.append(muspy.Note(ts, pitch.item(), dur.item(), 64))\n",
    "                    #notes.append(muspy.Note(ts, pitch.item(), dur, 64))\n",
    "        \n",
    "        if track_data[tr][0] == 'Drums':\n",
    "            track = muspy.Track(name='Drums', is_drum=True, notes=copy.deepcopy(notes))\n",
    "        else:\n",
    "            track = muspy.Track(name=track_data[tr][0], \n",
    "                                program=track_data[tr][1],\n",
    "                                notes=copy.deepcopy(notes))\n",
    "        tracks.append(track)\n",
    "    \n",
    "    meta = muspy.Metadata(title='prova')\n",
    "    music = muspy.Music(tracks=tracks, metadata=meta, resolution=RESOLUTION)\n",
    "    \n",
    "    return music\n",
    "\n",
    "\n",
    "track_data = [('Drums', -1), ('Bass', 34), ('Guitar', 1), ('Strings', 41)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae906df2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import muspy\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "prefix = \"data/music/\"\n",
    "\n",
    "real = from_tensor_to_muspy(music_real, track_data)\n",
    "\n",
    "fig, axs_ = plt.subplots(4, sharex=True, figsize=(10,10))\n",
    "fig.subplots_adjust(hspace=0)\n",
    "axs = axs_.tolist()\n",
    "muspy.show_pianoroll(music=real, yticklabel='off', grid_axis='off', axs=axs)\n",
    "plt.savefig(prefix + \"real\" + \".png\", dpi=200)\n",
    "muspy.write_midi(prefix + \"real\" + \".mid\", real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f02ceb6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rec = from_tensor_to_muspy(music_rec, track_data)\n",
    "\n",
    "fig, axs_ = plt.subplots(4, sharex=True, figsize=(10,10))\n",
    "fig.subplots_adjust(hspace=0)\n",
    "axs = axs_.tolist()\n",
    "\n",
    "muspy.show_pianoroll(rec, yticklabel='off', grid_axis='off', axs=axs)\n",
    "plt.savefig(prefix + \"rec\" + \".png\", dpi=200)\n",
    "muspy.write_midi(prefix + \"rec\" + \".mid\", rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ee6b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"data/music/file\"\n",
    "\n",
    "for i in range(10):\n",
    "    music_tensor = dataset[20+i][0]\n",
    "    music = from_tensor_to_muspy(music_tensor, track_data)\n",
    "    muspy.show_pianoroll(music, yticklabel='off', grid_axis='off')\n",
    "    plt.savefig(prefix + str(i) + \".png\")\n",
    "    muspy.write_midi(prefix + str(i) + \".mid\", music)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baaf02c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'n_tracks': 4,\n",
    "    'dropout': 0.1,\n",
    "    'd_token': 230,\n",
    "    'd_model': 256,\n",
    "    'n_head_transf': 2,\n",
    "    'n_layers_transf': 2,\n",
    "    'gnn_input_dim': 256 + 4,\n",
    "    'gnn_n_layers': 3,\n",
    "    'd_latent': 256,\n",
    "    'resolution': 8\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030a095f",
   "metadata": {},
   "source": [
    "Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c878bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.normal(torch.zeros((256, 512),\n",
    "                             device=vae.decoder.device),\n",
    "                 torch.ones((256, 512),\n",
    "                            device=vae.decoder.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82d987f",
   "metadata": {},
   "outputs": [],
   "source": [
    "z.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c372d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain z_structure and z_attributes from z\n",
    "#z = self.dropout_layer(z)\n",
    "z = vae.decoder.lin_divide(z)\n",
    "z = vae.decoder.bn_ld(z)\n",
    "z = F.relu(z)\n",
    "z = vae.decoder.dropout_layer(z)\n",
    "# [bs x 2*d]\n",
    "\n",
    "out_struct = z[:, :vae.decoder.d]\n",
    "# [bs x d] \n",
    "out_struct = vae.decoder.bars_decoder_struct(out_struct)\n",
    "# [bs x n_bars * d]\n",
    "\n",
    "out_struct = vae.decoder.cnn_decoder(out_struct.reshape(-1, vae.decoder.d))\n",
    "out_struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1afec1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_struct.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28bcdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "acts_rec = torch.sigmoid(out_struct.view(256, 2, 4, 32))\n",
    "acts_rec[acts_rec < 0.5] = 0\n",
    "acts_rec[acts_rec >= 0.5] = 1\n",
    "acts_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92dfd7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.pcolormesh(acts_rec[1, 0].detach().cpu().numpy(), edgecolors='k', linewidth=1)\n",
    "ax = plt.gca()\n",
    "ax.set_aspect('equal')\n",
    "plt.xticks(range(0, acts_rec[1, 0].size(1), 8), range(1, 5))\n",
    "plt.yticks(range(0, 4), range(1, 5))\n",
    "ax.invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af688cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "acts_rec[0].size()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
