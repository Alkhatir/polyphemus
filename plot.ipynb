{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d25c9521",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import os\n",
    "import muspy\n",
    "from itertools import product\n",
    "import pypianoroll as pproll\n",
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "seed = 42\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a1a132c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "\n",
    "#checkpoint = torch.load('models/just_pitches_no_drums_warmup2')\n",
    "#checkpoint = torch.load('models/multibar/checkpoint', map_location='cpu')\n",
    "model = 'models/2barsGNN/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c24af749",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(os.path.join(model, 'checkpoint'), map_location='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9f31112c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "664599\n",
      "250\n",
      "2658\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f78bb67fc50>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 248,
       "width": 375
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tr_losses = checkpoint['tr_losses']\n",
    "print(checkpoint['tot_batches'])\n",
    "\n",
    "#plt.plot(range(1, len(tr_losses['tot'])+1), tr_losses['tot'], label='TR loss')\n",
    "#plt.plot(range(1, len(tr_losses['acts'])+1), tr_losses['acts'], label='TR acts')\n",
    "plt.plot(range(1, len(tr_losses['pitches'])+1), tr_losses['pitches'], label='TR pitches')\n",
    "#plt.plot(range(1, len(tr_losses['rec'])+1), tr_losses['rec'], label='TR rec')\n",
    "#plt.plot(range(1, len(tr_losses['dur'])+1), tr_losses['dur'], label='TR dur')\n",
    "#plt.plot(range(1, len(tr_losses['kld'])+1), tr_losses['kld'], label='TR kld')\n",
    "#plt.plot(range(1, len(tr_losses['beta*kld'])+1), tr_losses['beta*kld'], label='TR kld')\n",
    "\n",
    "\n",
    "val_losses = checkpoint['val_losses']\n",
    "eval_every = checkpoint['eval_every']\n",
    "print(eval_every)\n",
    "print(len(val_losses['tot']))\n",
    "\n",
    "#plt.plot(range(eval_every, len(tr_losses['tot'])+1, eval_every), val_losses['tot'], '.', label='VL loss')\n",
    "#plt.plot(range(eval_every, len(tr_losses['acts'])+1, eval_every), val_losses['acts'], '.', label='VL acts')\n",
    "plt.plot(range(eval_every, len(tr_losses['pitches'])+1, eval_every), val_losses['pitches'], '.', label='VL pitches')\n",
    "#plt.plot(range(eval_every, len(tr_losses['dur'])+1, eval_every), val_losses['dur'], label='VL dur')\n",
    "#plt.plot(range(eval_every, len(tr_losses['kld'])+1, eval_every), val_losses['kld'], label='VL kld')\n",
    "\n",
    "plt.grid()\n",
    "plt.ylim(0)\n",
    "plt.xlim(0)\n",
    "#plt.ylim(0, 300)\n",
    "plt.xlim(0, 4000)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d0a613a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f789463e990>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 252,
       "width": 372
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tr_accs = checkpoint['tr_accuracies']\n",
    "#plt.plot(range(1, len(tr_accs['acts_acc'])+1), tr_accs['acts_acc'], label='Activations acc. (TR)')\n",
    "#plt.plot(range(1, len(tr_accs['acts_precision'])+1), tr_accs['acts_precision'], label='Activations prec. (TR)')\n",
    "#plt.plot(range(1, len(tr_accs['acts_recall'])+1), tr_accs['acts_recall'], label='Activations rec. (TR)')\n",
    "#plt.plot(range(1, len(tr_accs['acts_f1'])+1), tr_accs['acts_f1'], label='Activations F1 (TR)')\n",
    "#plt.plot(range(1, len(tr_accs['pitches'])+1), tr_accs['pitches'], label='Pitches (TR)')\n",
    "#plt.plot(range(1, len(tr_accs['pitches_drums'])+1), tr_accs['pitches_drums'], label='Pitches drums (TR)')\n",
    "#plt.plot(range(1, len(tr_accs['pitches_non_drums'])+1), tr_accs['pitches_non_drums'], label='Pitches non drums (TR)')\n",
    "#plt.plot(range(1, len(tr_accs['dur'])+1), tr_accs['dur'], label='Durations (TR)')\n",
    "plt.plot(range(1, len(tr_accs['notes'])+1), tr_accs['notes'], label='Notes (TR)')\n",
    "\n",
    "val_accs = checkpoint['val_accuracies']\n",
    "#plt.plot(range(eval_every, len(tr_accs['acts_acc'])+1, eval_every), val_accs['acts_acc'], '.', label='Activations (VL)')\n",
    "#plt.plot(range(eval_every, len(tr_accs['acts_precision'])+1, eval_every), val_accs['acts_precision'], '.', label='Activations prec. (VL)')\n",
    "#plt.plot(range(eval_every, len(tr_accs['acts_recall'])+1, eval_every), val_accs['acts_recall'], '.', label='Activations rec. (VL)')\n",
    "#plt.plot(range(eval_every, len(tr_accs['pitches'])+1, eval_every), val_accs['pitches'], '.', label='Pitches (VL)')\n",
    "#plt.plot(range(eval_every, len(tr_accs['pitches_drums'])+1, eval_every), val_accs['pitches_drums'], '.' ,label='Pitches drums (VL)')\n",
    "#plt.plot(range(eval_every, len(tr_accs['pitches_non_drums'])+1, eval_every), val_accs['pitches_non_drums'], '.' ,label='Pitches non drums (VL)')\n",
    "#plt.plot(range(eval_every, len(tr_accs['dur'])+1, eval_every), val_accs['dur'], '.', label='Durations (VL)')\n",
    "plt.plot(range(eval_every, len(tr_accs['notes'])+1, eval_every), val_accs['notes'], '.', label='Notes (VL)')\n",
    "#print(val_accs['pitches'])\n",
    "#print(val_accs['dur'])\n",
    "\n",
    "\n",
    "plt.grid()\n",
    "plt.xlim(0)\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "#plt.xlim(0, 130000)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9232c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = torch.load(os.path.join(model, 'params'), map_location='cpu')\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa373a5d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_accs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_142519/1669368122.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mval_accs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pitches'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'val_accs' is not defined"
     ]
    }
   ],
   "source": [
    "val_accs['pitches'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2693607f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs = checkpoint['lrs']\n",
    "plt.plot(range(1, len(lrs)+1), lrs, label='Lr')\n",
    "plt.grid()\n",
    "plt.ylim(0)\n",
    "plt.xlim(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bc5d18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "betas = checkpoint['betas']\n",
    "plt.plot(range(1, len(betas)+1), betas, label='Beta')\n",
    "plt.grid()\n",
    "#plt.ylim(0, 0.001)\n",
    "plt.xlim(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5a1902",
   "metadata": {},
   "source": [
    "Checking parameters updates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90215ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def sigmoid(x, m=1, a=1, z=0):\n",
    "    return m / (1 + math.exp(-a*(x-z)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044cc976",
   "metadata": {},
   "outputs": [],
   "source": [
    "betas = []\n",
    "beta_start = 35000\n",
    "beta_rate = 0.999996\n",
    "beta_max = 0.1\n",
    "annealing_steps = 0\n",
    "beta_end = 1e6\n",
    "\n",
    "for i in range(1000000):\n",
    "    #betas.append((1. - beta_rate**(i)) * beta_max)\n",
    "    if i < beta_start:\n",
    "        betas.append(0)\n",
    "    else:\n",
    "        betas.append(sigmoid(i, m=0.1, a=8e-6, z=20*beta_start))\n",
    "        #betas.append((i-beta_start)*beta_max/(beta_end-beta_start))\n",
    "    \n",
    "plt.plot(range(1, len(betas)+1), betas, label='Beta')\n",
    "plt.grid()\n",
    "plt.ylim(0, 0.1)\n",
    "#plt.xlim(34950, 35050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f455546",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92ec60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_accs = checkpoint['val_accuracies']\n",
    "val_accs['notes'][-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a43f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = checkpoint['tr_accuracies']\n",
    "accs['acts_recall'][-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b840bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "betas = []\n",
    "start_after = 30000\n",
    "beta_max = 0.1\n",
    "cycle_steps = 30000\n",
    "ann_to_zero_ratio = 0.6\n",
    "sig_scale_point = 7\n",
    "\n",
    "ann_steps = cycle_steps * ann_to_zero_ratio\n",
    "\n",
    "for i in range(160000):\n",
    "    #betas.append((1. - beta_rate**(i)) * beta_max)\n",
    "    if i < start_after:\n",
    "        betas.append(0)\n",
    "    else:\n",
    "        curr_cycle = (i - start_after) // cycle_steps\n",
    "        steps_in_cycle = i - start_after - curr_cycle*cycle_steps\n",
    "        if steps_in_cycle / cycle_steps < ann_to_zero_ratio:\n",
    "            sig_zero = cycle_steps * ann_to_zero_ratio / 2\n",
    "            scale = 1 / ((ann_steps / 2) / sig_scale_point)\n",
    "            beta = sigmoid(steps_in_cycle, m=beta_max, a=scale, z=sig_zero)\n",
    "            betas.append(beta)\n",
    "        else:\n",
    "            betas.append(0)\n",
    "    \n",
    "plt.plot(range(1, len(betas)+1), betas, label='Beta')\n",
    "plt.grid()\n",
    "plt.ylim(0, beta_max)\n",
    "plt.xlim(0, 160000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6389c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "betas[35000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27f8bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def frange_cycle_sigmoid(start, stop, n_epoch, n_cycle=4, ratio=0.5, max_beta=0.1):\n",
    "    L = np.ones(n_epoch)\n",
    "    L[:] = max_beta\n",
    "    period = n_epoch/n_cycle\n",
    "    step = (stop-start)/(period*ratio) # step is in [0,1]\n",
    "    \n",
    "    # transform into [-6, 6] for plots: v*12.-6.\n",
    "\n",
    "    for c in range(n_cycle):\n",
    "\n",
    "        v , i = start , 0\n",
    "        while v <= stop:\n",
    "            L[int(i+c*period)] = max_beta / (1.0 + np.exp(- (v*120. - 6.)))\n",
    "            v += step\n",
    "            i += 1\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8235fa7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_epoch = 40000\n",
    "beta_np_cyc = frange_cycle_sigmoid(0.0, 0.1, n_epoch, 4, ratio=0.9)\n",
    "#beta_np_inc = frange_cycle_sigmoid(0.0, 1.0, n_epoch, 1, 0.25)\n",
    "beta_np_con = np.ones(n_epoch)\n",
    "\n",
    "fig=plt.figure(figsize=(8,4.0))\n",
    "stride = max( int(n_epoch / 8), 1)\n",
    "\n",
    "plt.plot(range(n_epoch), beta_np_cyc, '-', label='Cyclical', marker= 's', color='k', markevery=stride,lw=2,  mec='k', mew=1 , markersize=10)\n",
    "#plt.plot(range(n_epoch), beta_np_inc, '-', label='Monotonic', marker= 'o', color='r', markevery=stride,lw=2,  mec='k', mew=1 , markersize=10)\n",
    "\n",
    "leg = plt.legend(fontsize=16, shadow=True, loc=(0.65, 0.2))\n",
    "plt.grid(True)\n",
    "\n",
    "plt.xlabel('# Iteration', fontsize=16)\n",
    "plt.ylabel(\"$\\\\beta$\", fontsize=16)\n",
    "\n",
    "ax = plt.gca() \n",
    "\n",
    "# X-axis label\n",
    "plt.xticks( (0, 5*1000, 10*1000, 15*1000, 20*1000, 25*1000, 30*1000, 35*1000, 40*1000), \\\n",
    "           ('0','5K','10K','15K','20K','25K','30K','35K','40K'), color='k', size=14)\n",
    "\n",
    "# Left Y-axis labels\n",
    "plt.yticks((0.0, 0.1, 0.5, 1.0), ('0', '0.1', '0.5','1'), color='k', size=14)\n",
    "\n",
    "#plt.xlim(4000,5100)\n",
    "plt.ylim(-0.1,0.2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1929c18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_np_cyc[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd50f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "lrs = []\n",
    "\n",
    "peak_lr = 1e-6\n",
    "warmup_steps = 8000\n",
    "decay_steps = 500000\n",
    "final_lr_scale = 0.1\n",
    "\n",
    "warmup_rate = peak_lr / warmup_steps\n",
    "gamma = -math.log(final_lr_scale) / decay_steps\n",
    "print(gamma)\n",
    "\n",
    "for i in range(1000000):\n",
    "    if i < warmup_steps:\n",
    "        lrs.append(i*warmup_rate)\n",
    "    else:\n",
    "        lrs.append(peak_lr * math.exp(-gamma * (i-warmup_steps)))\n",
    "    \n",
    "plt.plot(range(1, len(lrs)+1), lrs, label='lrs')\n",
    "plt.grid()\n",
    "#plt.ylim(0, 0.1)\n",
    "print(lrs[400000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3a24a8",
   "metadata": {},
   "source": [
    "Reconstruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1b3f35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.set_device(3)\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "#device = torch.device(\"cpu\")\n",
    "print(\"Device:\", device)\n",
    "print(\"Current device idx:\", torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710edc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Dataset\n",
    "from torch_geometric.data import Data\n",
    "import itertools\n",
    "from torch_geometric.data.collate import collate\n",
    "\n",
    "\n",
    "class MIDIDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dir, n_bars=2):\n",
    "        self.dir = dir\n",
    "        _, _, files = next(os.walk(self.dir))\n",
    "        self.len = len(files)\n",
    "        self.n_bars = n_bars\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    \n",
    "    def _get_track_edges(self, acts, edge_type_ind=0):\n",
    "\n",
    "        a_t = acts.transpose()\n",
    "        inds = np.stack(np.where(a_t == 1)).transpose()\n",
    "        \n",
    "        # Create node labels\n",
    "        labels = np.zeros(acts.shape)\n",
    "        acts_inds = np.where(acts == 1)\n",
    "        num_nodes = len(acts_inds[0])\n",
    "        labels[acts_inds] = np.arange(num_nodes)\n",
    "        labels = labels.transpose()\n",
    "\n",
    "        track_edges = []\n",
    "\n",
    "        for track in range(a_t.shape[1]):\n",
    "            tr_inds = list(inds[inds[:,1] == track])\n",
    "            e_inds = [(tr_inds[i],\n",
    "                    tr_inds[i+1]) for i in range(len(tr_inds)-1)]\n",
    "            edges = [(labels[tuple(e[0])], labels[tuple(e[1])], edge_type_ind+track, e[1][0]-e[0][0]) for e in e_inds]\n",
    "            inv_edges = [(e[1], e[0], *e[2:]) for e in edges]\n",
    "            track_edges.extend(edges)\n",
    "            track_edges.extend(inv_edges)\n",
    "\n",
    "        return np.array(track_edges, dtype='long')\n",
    "\n",
    "    \n",
    "    def _get_onset_edges(self, acts, edge_type_ind=4):\n",
    "\n",
    "        a_t = acts.transpose()\n",
    "        inds = np.stack(np.where(a_t == 1)).transpose()\n",
    "        ts_acts = np.any(a_t, axis=1)\n",
    "        ts_inds = np.where(ts_acts)[0]\n",
    "\n",
    "        # Create node labels\n",
    "        labels = np.zeros(acts.shape)\n",
    "        acts_inds = np.where(acts == 1)\n",
    "        num_nodes = len(acts_inds[0])\n",
    "        labels[acts_inds] = np.arange(num_nodes)\n",
    "        labels = labels.transpose()\n",
    "\n",
    "        onset_edges = []\n",
    "\n",
    "        for i in ts_inds:\n",
    "            ts_acts_inds = list(inds[inds[:,0] == i])\n",
    "            if len(ts_acts_inds) < 2:\n",
    "                continue\n",
    "            e_inds = list(itertools.combinations(ts_acts_inds, 2))\n",
    "            edges = [(labels[tuple(e[0])], labels[tuple(e[1])], edge_type_ind, 0) for e in e_inds]\n",
    "            inv_edges = [(e[1], e[0], *e[2:]) for e in edges]\n",
    "            onset_edges.extend(edges)\n",
    "            onset_edges.extend(inv_edges)\n",
    "\n",
    "        return np.array(onset_edges, dtype='long')\n",
    "\n",
    "\n",
    "    def _get_next_edges(self, acts, edge_type_ind=5):\n",
    "\n",
    "        a_t = acts.transpose()\n",
    "        inds = np.stack(np.where(a_t == 1)).transpose()\n",
    "        ts_acts = np.any(a_t, axis=1)\n",
    "        ts_inds = np.where(ts_acts)[0]\n",
    "\n",
    "        # Create node labels\n",
    "        labels = np.zeros(acts.shape)\n",
    "        acts_inds = np.where(acts == 1)\n",
    "        num_nodes = len(acts_inds[0])\n",
    "        labels[acts_inds] = np.arange(num_nodes)\n",
    "        labels = labels.transpose()\n",
    "\n",
    "        next_edges = []\n",
    "\n",
    "        for i in range(len(ts_inds)-1):\n",
    "\n",
    "            ind_s = ts_inds[i]\n",
    "            ind_e = ts_inds[i+1]\n",
    "            s = inds[inds[:,0] == ind_s]\n",
    "            e = inds[inds[:,0] == ind_e]\n",
    "\n",
    "            e_inds = [t for t in list(itertools.product(s, e)) if t[0][1] != t[1][1]]\n",
    "            edges = [(labels[tuple(e[0])], labels[tuple(e[1])], edge_type_ind, ind_e-ind_s) for e in e_inds]\n",
    "            inv_edges = [(e[1], e[0], *e[2:]) for e in edges]\n",
    "            \n",
    "            next_edges.extend(edges)\n",
    "            next_edges.extend(inv_edges)\n",
    "            \n",
    "        return np.array(next_edges, dtype='long')\n",
    "    \n",
    "    def _get_super_edges(self, num_nodes, edge_type_ind=6):\n",
    "    \n",
    "        super_edges = [(num_nodes, i, edge_type_ind, 0) for i in range(num_nodes)]\n",
    "        inv_edges = [(e[1], e[0], *e[2:]) for e in edges]\n",
    "        \n",
    "        super_edges.extend(inv_edges)\n",
    "        \n",
    "        return np.array(super_edges, dtype='long')\n",
    "        \n",
    "    \n",
    "    def _get_node_features(self, acts, num_nodes):\n",
    "        \n",
    "        num_tracks = acts.shape[0]\n",
    "        features = torch.zeros((num_nodes, num_tracks), dtype=torch.float)\n",
    "        features[np.arange(num_nodes), np.stack(np.where(acts))[0]] = 1.\n",
    "        \n",
    "        return features\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        # Load tensors\n",
    "        sample_path = os.path.join(self.dir, str(idx) + \".npz\")\n",
    "        data = np.load(sample_path)\n",
    "        seq_tensor = data[\"seq_tensor\"]\n",
    "        seq_acts = data[\"seq_acts\"]\n",
    "        \n",
    "        # From (#tracks x #timesteps x ...) to (#bars x #tracks x #timesteps x ...)\n",
    "        seq_tensor = seq_tensor.reshape(seq_tensor.shape[0], self.n_bars, -1,\n",
    "                                        seq_tensor.shape[2], seq_tensor.shape[3])\n",
    "        seq_tensor = seq_tensor.transpose(1, 0, 2, 3, 4)\n",
    "        seq_acts = seq_acts.reshape(seq_acts.shape[0], self.n_bars, -1)\n",
    "        seq_acts = seq_acts.transpose(1, 0, 2)\n",
    "        \n",
    "        # Construct src_key_padding_mask (PAD = 130)\n",
    "        src_mask = torch.from_numpy((seq_tensor[..., 0] == 130))\n",
    "\n",
    "        # From decimals to one-hot (pitch)\n",
    "        pitches = seq_tensor[..., 0]\n",
    "        onehot_p = np.zeros(\n",
    "            (pitches.shape[0]*pitches.shape[1]*pitches.shape[2]*pitches.shape[3],\n",
    "             131), \n",
    "            dtype=float\n",
    "        )\n",
    "        onehot_p[np.arange(0, onehot_p.shape[0]), pitches.reshape(-1)] = 1.\n",
    "        onehot_p = onehot_p.reshape(pitches.shape[0], pitches.shape[1], \n",
    "                                    pitches.shape[2], pitches.shape[3], 131)\n",
    "        \n",
    "        # From decimals to one-hot (dur)\n",
    "        durs = seq_tensor[..., 1]\n",
    "        onehot_d = np.zeros(\n",
    "            (durs.shape[0]*durs.shape[1]*durs.shape[2]*durs.shape[3],\n",
    "             99),\n",
    "            dtype=float\n",
    "        )\n",
    "        onehot_d[np.arange(0, onehot_d.shape[0]), durs.reshape(-1)] = 1.\n",
    "        onehot_d = onehot_d.reshape(durs.shape[0], durs.shape[1], \n",
    "                                    durs.shape[2], durs.shape[3], 99)\n",
    "        \n",
    "        # Concatenate pitches and durations\n",
    "        new_seq_tensor = np.concatenate((onehot_p, onehot_d),\n",
    "                                        axis=-1)\n",
    "        \n",
    "        graphs = []\n",
    "        \n",
    "        # Iterate over bars and construct a graph for each bar\n",
    "        for i in range(self.n_bars):\n",
    "            \n",
    "            # Number of nodes\n",
    "            n = torch.sum(torch.Tensor(seq_acts[i]), dtype=torch.long)\n",
    "            \n",
    "            # Get edges from boolean activations\n",
    "            # Todo: optimize and refactor\n",
    "            track_edges = self._get_track_edges(seq_acts[i])\n",
    "            onset_edges = self._get_onset_edges(seq_acts[i])\n",
    "            next_edges = self._get_next_edges(seq_acts[i])\n",
    "            #super_edges = self._get_super_edges(n)\n",
    "            edges = [track_edges, onset_edges, next_edges]\n",
    "            \n",
    "            # Concatenate edge tensors (N x 4) (if any)\n",
    "            # First two columns -> source and dest nodes\n",
    "            # Third column -> edge_type, Fourth column -> timestep distance\n",
    "            no_edges = (len(track_edges) == 0 and \n",
    "                        len(onset_edges) == 0 and len(next_edges) == 0)\n",
    "            if not no_edges:\n",
    "                edge_list = np.concatenate([x for x in edges\n",
    "                                              if x.size > 0])\n",
    "                edge_list = torch.from_numpy(edge_list)\n",
    "                \n",
    "            # Adapt tensor to torch_geometric's Data\n",
    "            # No edges: add fictitious self-edge\n",
    "            edge_index = (torch.LongTensor([[0], [0]]) if no_edges else\n",
    "                                   edge_list[:, :2].t().contiguous())\n",
    "            attrs = (torch.Tensor([[0, 0]]) if no_edges else\n",
    "                                           edge_list[:, 2:])\n",
    "\n",
    "            # One hot timestep distance concatenated to edge type\n",
    "            edge_attrs = torch.zeros(attrs.size(0), 1+seq_acts.shape[-1])\n",
    "            edge_attrs[:, 0] = attrs[:, 0]\n",
    "            edge_attrs[np.arange(edge_attrs.size(0)), attrs.long()[:, 1]+1] = 1\n",
    "            #edge_attrs = torch.Tensor(attrs.float())\n",
    "            \n",
    "            node_features = self._get_node_features(seq_acts[i], n)\n",
    "            is_drum = node_features[:, 0].bool()\n",
    "            \n",
    "            graphs.append(Data(edge_index=edge_index, edge_attrs=edge_attrs,\n",
    "                               num_nodes=n, node_features=node_features,\n",
    "                               is_drum=is_drum))\n",
    "            \n",
    "            \n",
    "        # Merge the graphs corresponding to different bars into a single big graph\n",
    "        graphs, _, inc_dict = collate(\n",
    "            Data,\n",
    "            data_list=graphs,\n",
    "            increment=True,\n",
    "            add_batch=True\n",
    "        )\n",
    "        \n",
    "        # Change bars assignment vector name (otherwise, Dataloader's collate\n",
    "        # would overwrite graphs.batch)\n",
    "        graphs.bars = graphs.batch\n",
    "        \n",
    "        # Filter silences in order to get a sparse representation\n",
    "        new_seq_tensor = new_seq_tensor.reshape(-1, new_seq_tensor.shape[-2],\n",
    "                                                new_seq_tensor.shape[-1])\n",
    "        src_mask = src_mask.reshape(-1, src_mask.shape[-1])\n",
    "        new_seq_tensor = new_seq_tensor[seq_acts.reshape(-1).astype(bool)]\n",
    "        src_mask = src_mask[seq_acts.reshape(-1).astype(bool)]\n",
    "        \n",
    "        new_seq_tensor = torch.Tensor(new_seq_tensor)\n",
    "        seq_acts = torch.Tensor(seq_acts)\n",
    "        graphs.x_seq = new_seq_tensor\n",
    "        graphs.x_acts = seq_acts\n",
    "        graphs.src_mask = src_mask\n",
    "        \n",
    "        # Todo: start with torch at mount\n",
    "        #return torch.Tensor(new_seq_tensor), torch.Tensor(seq_acts), graphs, src_mask\n",
    "        return graphs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d35dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Union, Tuple\n",
    "from torch_geometric.typing import OptTensor, Adj\n",
    "from typing import Callable\n",
    "from torch_geometric.nn.inits import reset\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Parameter as Param\n",
    "from torch.nn import Parameter\n",
    "from torch_scatter import scatter\n",
    "from torch_sparse import SparseTensor, matmul, masked_select_nnz\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "\n",
    "from torch_geometric.nn.inits import glorot, zeros\n",
    "\n",
    "\n",
    "@torch.jit._overload\n",
    "def masked_edge_index(edge_index, edge_mask):\n",
    "    # type: (Tensor, Tensor) -> Tensor\n",
    "    pass\n",
    "\n",
    "\n",
    "@torch.jit._overload\n",
    "def masked_edge_index(edge_index, edge_mask):\n",
    "    # type: (SparseTensor, Tensor) -> SparseTensor\n",
    "    pass\n",
    "\n",
    "\n",
    "def masked_edge_index(edge_index, edge_mask):\n",
    "    if isinstance(edge_index, Tensor):\n",
    "        return edge_index[:, edge_mask]\n",
    "    else:\n",
    "        return masked_select_nnz(edge_index, edge_mask, layout='coo')\n",
    "\n",
    "def masked_edge_attrs(edge_attrs, edge_mask):\n",
    "    return edge_attrs[edge_mask, :]\n",
    "\n",
    "\n",
    "class RGCNConv(MessagePassing):\n",
    "    r\"\"\"The relational graph convolutional operator from the `\"Modeling\n",
    "    Relational Data with Graph Convolutional Networks\"\n",
    "    <https://arxiv.org/abs/1703.06103>`_ paper\n",
    "\n",
    "    .. math::\n",
    "        \\mathbf{x}^{\\prime}_i = \\mathbf{\\Theta}_{\\textrm{root}} \\cdot\n",
    "        \\mathbf{x}_i + \\sum_{r \\in \\mathcal{R}} \\sum_{j \\in \\mathcal{N}_r(i)}\n",
    "        \\frac{1}{|\\mathcal{N}_r(i)|} \\mathbf{\\Theta}_r \\cdot \\mathbf{x}_j,\n",
    "\n",
    "    where :math:`\\mathcal{R}` denotes the set of relations, *i.e.* edge types.\n",
    "    Edge type needs to be a one-dimensional :obj:`torch.long` tensor which\n",
    "    stores a relation identifier\n",
    "    :math:`\\in \\{ 0, \\ldots, |\\mathcal{R}| - 1\\}` for each edge.\n",
    "\n",
    "    .. note::\n",
    "        This implementation is as memory-efficient as possible by iterating\n",
    "        over each individual relation type.\n",
    "        Therefore, it may result in low GPU utilization in case the graph has a\n",
    "        large number of relations.\n",
    "        As an alternative approach, :class:`FastRGCNConv` does not iterate over\n",
    "        each individual type, but may consume a large amount of memory to\n",
    "        compensate.\n",
    "        We advise to check out both implementations to see which one fits your\n",
    "        needs.\n",
    "\n",
    "    Args:\n",
    "        in_channels (int or tuple): Size of each input sample. A tuple\n",
    "            corresponds to the sizes of source and target dimensionalities.\n",
    "            In case no input features are given, this argument should\n",
    "            correspond to the number of nodes in your graph.\n",
    "        out_channels (int): Size of each output sample.\n",
    "        num_relations (int): Number of relations.\n",
    "        nn (torch.nn.Module): A neural network :math:`h_{\\mathbf{\\Theta}}` that\n",
    "            maps edge features :obj:`edge_attr` of shape :obj:`[-1,\n",
    "            num_edge_features]` to shape\n",
    "            :obj:`[-1, in_channels * out_channels]`, *e.g.*, defined by\n",
    "            :class:`torch.nn.Sequential`.\n",
    "        num_bases (int, optional): If set to not :obj:`None`, this layer will\n",
    "            use the basis-decomposition regularization scheme where\n",
    "            :obj:`num_bases` denotes the number of bases to use.\n",
    "            (default: :obj:`None`)\n",
    "        num_blocks (int, optional): If set to not :obj:`None`, this layer will\n",
    "            use the block-diagonal-decomposition regularization scheme where\n",
    "            :obj:`num_blocks` denotes the number of blocks to use.\n",
    "            (default: :obj:`None`)\n",
    "        aggr (string, optional): The aggregation scheme to use\n",
    "            (:obj:`\"add\"`, :obj:`\"mean\"`, :obj:`\"max\"`).\n",
    "            (default: :obj:`\"mean\"`)\n",
    "        root_weight (bool, optional): If set to :obj:`False`, the layer will\n",
    "            not add transformed root node features to the output.\n",
    "            (default: :obj:`True`)\n",
    "        bias (bool, optional): If set to :obj:`False`, the layer will not learn\n",
    "            an additive bias. (default: :obj:`True`)\n",
    "        **kwargs (optional): Additional arguments of\n",
    "            :class:`torch_geometric.nn.conv.MessagePassing`.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: Union[int, Tuple[int, int]],\n",
    "        out_channels: int,\n",
    "        num_relations: int,\n",
    "        #num_dists: int,\n",
    "        nn: Callable,\n",
    "        num_bases: Optional[int] = None,\n",
    "        num_blocks: Optional[int] = None,\n",
    "        dropout: Optional[float] = 0.1,\n",
    "        aggr: str = 'mean',\n",
    "        root_weight: bool = True,\n",
    "        bias: bool = True,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(aggr=aggr, node_dim=0, **kwargs)\n",
    "\n",
    "        if num_bases is not None and num_blocks is not None:\n",
    "            raise ValueError('Can not apply both basis-decomposition and '\n",
    "                             'block-diagonal-decomposition at the same time.')\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.nn = nn\n",
    "        #self.num_dists = num_dists\n",
    "        self.dropout = dropout\n",
    "        self.num_relations = num_relations\n",
    "        self.num_bases = num_bases\n",
    "        self.num_blocks = num_blocks\n",
    "\n",
    "        if isinstance(in_channels, int):\n",
    "            in_channels = (in_channels, in_channels)\n",
    "        self.in_channels_l = in_channels[0]\n",
    "\n",
    "        if num_bases is not None:\n",
    "            self.weight = Parameter(\n",
    "                torch.Tensor(num_bases, in_channels[0], out_channels))\n",
    "            self.comp = Parameter(torch.Tensor(num_relations, num_bases))\n",
    "        \n",
    "        elif num_blocks is not None:\n",
    "            assert (in_channels[0] % num_blocks == 0\n",
    "                    and out_channels % num_blocks == 0)\n",
    "            self.weight = Parameter(\n",
    "                torch.Tensor(num_relations, num_blocks,\n",
    "                             in_channels[0] // num_blocks,\n",
    "                             out_channels // num_blocks))\n",
    "            self.register_parameter('comp', None)\n",
    "\n",
    "        else:\n",
    "            self.weight = Parameter(\n",
    "                torch.Tensor(num_relations, in_channels[0], out_channels))\n",
    "            self.register_parameter('comp', None)\n",
    "\n",
    "        if root_weight:\n",
    "            self.root = Param(torch.Tensor(in_channels[1], out_channels))\n",
    "        else:\n",
    "            self.register_parameter('root', None)\n",
    "\n",
    "        if bias:\n",
    "            self.bias = Param(torch.Tensor(out_channels))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        \n",
    "        #self.dist_weights = Parameter(torch.Tensor(self.num_dists))\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        glorot(self.weight)\n",
    "        reset(self.nn)\n",
    "        glorot(self.comp)\n",
    "        glorot(self.root)\n",
    "        #zeros(self.dist_weights)\n",
    "        zeros(self.bias)\n",
    "\n",
    "\n",
    "    def forward(self, x: Union[OptTensor, Tuple[OptTensor, Tensor]],\n",
    "                edge_index: Adj, edge_type: OptTensor = None,\n",
    "                edge_attr: OptTensor = None):\n",
    "        r\"\"\"\n",
    "        Args:\n",
    "            x: The input node features. Can be either a :obj:`[num_nodes,\n",
    "                in_channels]` node feature matrix, or an optional\n",
    "                one-dimensional node index tensor (in which case input features\n",
    "                are treated as trainable node embeddings).\n",
    "                Furthermore, :obj:`x` can be of type :obj:`tuple` denoting\n",
    "                source and destination node features.\n",
    "            edge_type: The one-dimensional relation type/index for each edge in\n",
    "                :obj:`edge_index`.\n",
    "                Should be only :obj:`None` in case :obj:`edge_index` is of type\n",
    "                :class:`torch_sparse.tensor.SparseTensor`.\n",
    "                (default: :obj:`None`)\n",
    "        \"\"\"\n",
    "\n",
    "        # Convert input features to a pair of node features or node indices.\n",
    "        x_l: OptTensor = None\n",
    "        if isinstance(x, tuple):\n",
    "            x_l = x[0]\n",
    "        else:\n",
    "            x_l = x\n",
    "        if x_l is None:\n",
    "            x_l = torch.arange(self.in_channels_l, device=self.weight.device)\n",
    "\n",
    "        x_r: Tensor = x_l\n",
    "        if isinstance(x, tuple):\n",
    "            x_r = x[1]\n",
    "\n",
    "        size = (x_l.size(0), x_r.size(0))\n",
    "\n",
    "        if isinstance(edge_index, SparseTensor):\n",
    "            edge_type = edge_index.storage.value()\n",
    "        assert edge_type is not None\n",
    "\n",
    "        # propagate_type: (x: Tensor)\n",
    "        out = torch.zeros(x_r.size(0), self.out_channels, device=x_r.device)\n",
    "\n",
    "        weight = self.weight\n",
    "        if self.num_bases is not None:  # Basis-decomposition =================\n",
    "            weight = (self.comp @ weight.view(self.num_bases, -1)).view(\n",
    "                self.num_relations, self.in_channels_l, self.out_channels)\n",
    "\n",
    "        if self.num_blocks is not None:  # Block-diagonal-decomposition =====\n",
    "\n",
    "            if x_l.dtype == torch.long and self.num_blocks is not None:\n",
    "                raise ValueError('Block-diagonal decomposition not supported '\n",
    "                                 'for non-continuous input features.')\n",
    "\n",
    "            for i in range(self.num_relations):\n",
    "                tmp = masked_edge_index(edge_index, edge_type == i)\n",
    "                h = self.propagate(tmp, x=x_l, size=size)\n",
    "                h = h.view(-1, weight.size(1), weight.size(2))\n",
    "                h = torch.einsum('abc,bcd->abd', h, weight[i])\n",
    "                out += h.contiguous().view(-1, self.out_channels)\n",
    "\n",
    "        else:  # No regularization/Basis-decomposition ========================\n",
    "            for i in range(self.num_relations):\n",
    "                tmp = masked_edge_index(edge_index, edge_type == i)\n",
    "                attr = masked_edge_attrs(edge_attr, edge_type == i)\n",
    "\n",
    "                if x_l.dtype == torch.long:\n",
    "                    out += self.propagate(tmp, x=weight[i, x_l], size=size)\n",
    "                else:\n",
    "                    h = self.propagate(tmp, x=x_l, size=size,\n",
    "                                       edge_attr=attr)\n",
    "                    out = out + (h @ weight[i])\n",
    "\n",
    "        root = self.root\n",
    "        if root is not None:\n",
    "            out += root[x_r] if x_r.dtype == torch.long else x_r @ root\n",
    "\n",
    "        if self.bias is not None:\n",
    "            out += self.bias\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "    def message(self, x_j: Tensor, edge_attr: Tensor) -> Tensor:\n",
    "        #weights = self.dist_weights[edge_attr.view(-1).long()]\n",
    "        #weights = torch.diag(weights)\n",
    "        #return torch.matmul(weights, x_j)\n",
    "        weights = self.nn(edge_attr)\n",
    "        weights = weights[..., :self.in_channels_l]\n",
    "        weights = weights.view(-1, self.in_channels_l)\n",
    "        ret = x_j * weights\n",
    "        ret = F.relu(ret)\n",
    "        ret = F.dropout(ret, p=self.dropout, training=self.training)\n",
    "        return ret\n",
    "    \n",
    "        \n",
    "        \n",
    "    def message_and_aggregate(self, adj_t: SparseTensor, x: Tensor) -> Tensor:\n",
    "        adj_t = adj_t.set_value(None, layout=None)\n",
    "        return matmul(adj_t, x, reduce=self.aggr)\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return (f'{self.__class__.__name__}({self.in_channels}, '\n",
    "                f'{self.out_channels}, num_relations={self.num_relations})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007f1aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch_geometric.nn.conv import GCNConv#, RGCNConv\n",
    "from torch_geometric.nn.norm import BatchNorm\n",
    "from torch_geometric.nn.glob import GlobalAttention\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import torch.optim as optim\n",
    "from torch_scatter import scatter_mean\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\n",
    "\n",
    "\n",
    "# Todo: check and think about max_len\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 256):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) *                     \\\n",
    "                             (-math.log(10000.0)/d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position*div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position*div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor, shape [seq_len, batch_size, embedding_dim]\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)\n",
    "    \n",
    "\n",
    "class MLP(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim=256, hidden_dim=256, output_dim=256, num_layers=2,\n",
    "                 act=True, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        assert num_layers >= 1\n",
    "        \n",
    "        self.layers = nn.ModuleList()\n",
    "        \n",
    "        if num_layers == 1:\n",
    "            self.layers.append(nn.Linear(input_dim, output_dim))\n",
    "        else:\n",
    "            self.layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "        \n",
    "            for i in range(num_layers-2):\n",
    "                self.layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "\n",
    "            self.layers.append(nn.Linear(hidden_dim, output_dim))\n",
    "        \n",
    "        self.act = act\n",
    "        self.p = dropout\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            x = F.dropout(x, p=self.p, training=self.training)\n",
    "            x = layer(x)\n",
    "            if self.act:\n",
    "                x = F.relu(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    \n",
    "class EncoderRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size=240, hidden_size=256, num_layers=2, \n",
    "                 dropout=0.1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Linear(input_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, batch_first=True,\n",
    "                            num_layers=num_layers, bidirectional=True)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        embedded = self.embedding(x).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.lstm(output, hidden)\n",
    "        return output, hidden\n",
    "    \n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_size=256, output_size=240, num_layers=2, \n",
    "                 dropout=0.1):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Linear(output_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, batch_first=True,\n",
    "                            num_layers=num_layers, bidirectional=True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        output = self.embedding(x).view(1, 1, -1)\n",
    "        output, hidden = self.lstm(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "\n",
    "class GraphEncoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim=256, hidden_dim=256, n_layers=3, \n",
    "                 num_relations=3, num_dists=32, batch_norm=False, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.layers = nn.ModuleList()\n",
    "        self.norm_layers = nn.ModuleList()\n",
    "        edge_nn = nn.Linear(num_dists, input_dim)\n",
    "        self.batch_norm = batch_norm\n",
    "        \n",
    "        self.layers.append(RGCNConv(input_dim, hidden_dim,\n",
    "                                    num_relations, edge_nn))\n",
    "        if self.batch_norm:\n",
    "            self.norm_layers.append(BatchNorm(hidden_dim))\n",
    "        \n",
    "        for i in range(n_layers-1):\n",
    "            edge_nn = nn.Linear(num_dists, input_dim)\n",
    "            self.layers.append(RGCNConv(hidden_dim, hidden_dim,\n",
    "                                        num_relations, edge_nn))\n",
    "            if self.batch_norm:\n",
    "                self.norm_layers.append(BatchNorm(hidden_dim))\n",
    "            \n",
    "        self.p = dropout\n",
    "        \n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attrs = data.x, data.edge_index, data.edge_attrs\n",
    "        #batch = data.distinct_bars\n",
    "        edge_type = edge_attrs[:, 0]\n",
    "        edge_attr = edge_attrs[:, 1:]\n",
    "        \n",
    "        for i in range(len(self.layers)):\n",
    "            residual = x\n",
    "            x = F.dropout(x, p=self.p, training=self.training)\n",
    "            x = self.layers[i](x, edge_index, edge_type, edge_attr)\n",
    "            if self.batch_norm:\n",
    "                x = self.norm_layers[i](x)\n",
    "            x = F.relu(x)\n",
    "            x = residual + x\n",
    "\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class CNNEncoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, output_dim=256, dense_dim=256, batch_norm=False,\n",
    "                 dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        if batch_norm:\n",
    "            self.conv = nn.Sequential(\n",
    "                # 4*32 --> 8*4*32\n",
    "                nn.Conv2d(1, 8, 3, padding=1),\n",
    "                nn.BatchNorm2d(8),\n",
    "                nn.ReLU(True),\n",
    "                # 8*4*32 --> 8*4*8\n",
    "                nn.MaxPool2d((1, 4), stride=(1, 4)),\n",
    "                # 8*4*8 --> 16*4*8\n",
    "                nn.Conv2d(8, 16, 3, padding=1),\n",
    "                nn.BatchNorm2d(16),\n",
    "                nn.ReLU(True)\n",
    "            )\n",
    "        else:\n",
    "            self.conv = nn.Sequential(\n",
    "                # 4*32 --> 8*4*32\n",
    "                nn.Conv2d(1, 8, 3, padding=1),\n",
    "                nn.ReLU(True),\n",
    "                # 8*4*32 --> 8*4*8\n",
    "                nn.MaxPool2d((1, 4), stride=(1, 4)),\n",
    "                # 8*4*8 --> 16*4*8\n",
    "                nn.Conv2d(8, 16, 3, padding=1),\n",
    "                nn.ReLU(True)\n",
    "            )\n",
    "        \n",
    "        self.flatten = nn.Flatten(start_dim=1)\n",
    "        \n",
    "        self.lin = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(16*4*8, dense_dim),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(dense_dim, output_dim)\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.conv(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.lin(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "\n",
    "class CNNDecoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim=256, dense_dim=256, batch_norm=False,\n",
    "                 dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.lin = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(input_dim, dense_dim),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(dense_dim, 16*4*8),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "        self.unflatten = nn.Unflatten(dim=1, unflattened_size=(16, 4, 8))\n",
    "\n",
    "        if batch_norm:\n",
    "            self.conv = nn.Sequential(\n",
    "                nn.Upsample(scale_factor=(1, 4), mode='nearest'),\n",
    "                nn.Conv2d(16, 8, 3, padding=1),\n",
    "                nn.BatchNorm2d(8),\n",
    "                nn.ReLU(True),\n",
    "                nn.Conv2d(8, 1, 3, padding=1)\n",
    "            )\n",
    "        else:\n",
    "            self.conv = nn.Sequential(\n",
    "                nn.Upsample(scale_factor=(1, 4), mode='nearest'),\n",
    "                nn.Conv2d(16, 8, 3, padding=1),\n",
    "                nn.ReLU(True),\n",
    "                nn.Conv2d(8, 1, 3, padding=1)\n",
    "            )\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.lin(x)\n",
    "        x = self.unflatten(x)\n",
    "        x = self.conv(x)\n",
    "        \n",
    "        return x.unsqueeze(1)\n",
    "        \n",
    "\n",
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.__dict__.update(kwargs)\n",
    "        \n",
    "        self.dropout_layer = nn.Dropout(p=self.dropout)\n",
    "        \n",
    "        \n",
    "        self.notes_pitch_emb = nn.Linear(self.d_token_pitches, \n",
    "                                               self.d//2)\n",
    "        \n",
    "        self.bn_npe = nn.BatchNorm1d(num_features=self.d//2)\n",
    "        \n",
    "        self.drums_pitch_emb = nn.Linear(self.d_token_pitches, \n",
    "                                               self.d//2)\n",
    "        \n",
    "        self.bn_dpe = nn.BatchNorm1d(num_features=self.d//2)\n",
    "        \n",
    "        self.dur_emb = nn.Linear(self.d_token_dur, self.d//2)\n",
    "        \n",
    "        self.bn_de = nn.BatchNorm1d(num_features=self.d//2)\n",
    "        \n",
    "        self.chord_encoder = nn.Linear(self.d * (self.max_simu_notes-1),\n",
    "                                       self.d)\n",
    "\n",
    "        # Graph encoder\n",
    "        self.graph_encoder = GraphEncoder(dropout=self.dropout, \n",
    "                                          input_dim=self.d,\n",
    "                                          hidden_dim=self.d,\n",
    "                                          n_layers=self.gnn_n_layers,\n",
    "                                          num_relations=self.n_relations,\n",
    "                                          batch_norm=self.batch_norm)\n",
    "        \n",
    "        gate_nn = nn.Sequential(\n",
    "            MLP(input_dim=self.d, output_dim=1, num_layers=1, act=False,\n",
    "                      dropout=self.dropout),\n",
    "            nn.BatchNorm1d(1)\n",
    "        )\n",
    "        self.graph_attention = GlobalAttention(gate_nn)\n",
    "        \n",
    "        #self.context_bar_rnn = nn.GRU(input_size=self.d,\n",
    "        #                              hidden_size=self.d//2,\n",
    "        #                              num_layers=1,\n",
    "        #                              bidirectional=True,\n",
    "        #                              batch_first=True, \n",
    "        #                              dropout=self.dropout)\n",
    "        \n",
    "        self.bars_encoder_attr = nn.Linear(self.n_bars*self.d,\n",
    "                                           self.d)\n",
    "        \n",
    "        \n",
    "        self.cnn_encoder = CNNEncoder(dense_dim=self.d,\n",
    "                                      output_dim=self.d,\n",
    "                                      dropout=0,\n",
    "                                      batch_norm=self.batch_norm)\n",
    "        \n",
    "        self.bars_encoder_struct = nn.Linear(self.n_bars*self.d,\n",
    "                                             self.d)\n",
    "        #self.struct_bar_rnn = nn.GRU(input_size=self.d,\n",
    "        #                              hidden_size=self.d//2,\n",
    "        #                              num_layers=1,\n",
    "        #                              batch_first=True, \n",
    "        #                              dropout=self.dropout)\n",
    "        \n",
    "        self.linear_merge = nn.Linear(2*self.d, self.d)\n",
    "        \n",
    "        self.bn_lm = nn.BatchNorm1d(num_features=self.d)\n",
    "        \n",
    "        # Linear layers that compute the final mu and log_var\n",
    "        # Todo: as parameters\n",
    "        self.linear_mu = nn.Linear(self.d, self.d)\n",
    "        self.linear_log_var = nn.Linear(self.d, self.d)\n",
    "\n",
    "        \n",
    "    def forward(self, x_seq, x_acts, x_graph, src_mask):\n",
    "        \n",
    "        # No start of seq token\n",
    "        x_seq = x_seq[:, 1:, :]\n",
    "        \n",
    "        # Get drums and non drums tensors\n",
    "        drums = x_seq[x_graph.is_drum]\n",
    "        src_mask_drums = src_mask[x_graph.is_drum]\n",
    "        non_drums = x_seq[torch.logical_not(x_graph.is_drum)]\n",
    "        src_mask_non_drums = src_mask[torch.logical_not(x_graph.is_drum)]\n",
    "        \n",
    "        # Permute dimensions to batch_first = False\n",
    "        #drums = drums.permute(1, 0, 2)\n",
    "        #non_drums = non_drums.permute(1, 0, 2)\n",
    "        \n",
    "        # Compute note/drums embeddings\n",
    "        s = drums.size()\n",
    "        drums_pitch = self.drums_pitch_emb(drums[..., :self.d_token_pitches])\n",
    "        drums_pitch = self.bn_dpe(drums_pitch.view(-1, self.d//2))\n",
    "        drums_pitch = drums_pitch.view(s[0], s[1], self.d//2)\n",
    "        drums_dur = self.dur_emb(drums[..., self.d_token_pitches:])\n",
    "        drums_dur = self.bn_de(drums_dur.view(-1, self.d//2))\n",
    "        drums_dur = drums_dur.view(s[0], s[1], self.d//2)\n",
    "        drums = torch.cat((drums_pitch, drums_dur), dim=-1)\n",
    "        #drums = self.dropout_layer(drums)\n",
    "        # [n_nodes x max_simu_notes x d]\n",
    "        \n",
    "        s = non_drums.size()\n",
    "        non_drums_pitch = self.notes_pitch_emb(non_drums[..., :self.d_token_pitches])\n",
    "        non_drums_pitch = self.bn_npe(non_drums_pitch.view(-1, self.d//2))\n",
    "        non_drums_pitch = non_drums_pitch.view(s[0], s[1], self.d//2)\n",
    "        non_drums_dur = self.dur_emb(non_drums[..., self.d_token_pitches:])\n",
    "        non_drums_dur = self.bn_de(non_drums_dur.view(-1, self.d//2))\n",
    "        non_drums_dur = non_drums_dur.view(s[0], s[1], self.d//2)\n",
    "        non_drums = torch.cat((non_drums_pitch, non_drums_dur), dim=-1)\n",
    "        #non_drums = self.dropout_layer(non_drums)\n",
    "        # [n_nodes x max_simu_notes x d]\n",
    "        \n",
    "        #len_drums = self.max_simu_notes - torch.sum(src_mask_drums, dim=1)\n",
    "        #len_non_drums = self.max_simu_notes - torch.sum(src_mask_non_drums, dim=1)\n",
    "        \n",
    "        #drums = pack_padded_sequence(drums, len_drums.cpu().view(-1),\n",
    "        #                             enforce_sorted=False)\n",
    "        #non_drums = pack_padded_sequence(non_drums, len_non_drums.cpu().view(-1),\n",
    "        #                                 enforce_sorted=False)\n",
    "\n",
    "        # Compute chord embeddings both for drums and non drums\n",
    "        drums = self.chord_encoder(drums.view(-1, self.d*(self.max_simu_notes-1)))\n",
    "        non_drums = self.chord_encoder(non_drums.view(-1, self.d*(self.max_simu_notes-1)))\n",
    "        drums = F.relu(drums)\n",
    "        non_drums = F.relu(non_drums)\n",
    "        drums = self.dropout_layer(drums)\n",
    "        non_drums = self.dropout_layer(non_drums)\n",
    "        # [n_nodes x d]\n",
    "        \n",
    "        #hidden = torch.zeros(drums.size(1), )\n",
    "        #drums = self.chord_encoder_drums(drums)[-1]\n",
    "        #non_drums = self.chord_encoder(non_drums)[-1]\n",
    "        #drums = torch.mean(drums, dim=0)\n",
    "        #non_drums = torch.mean(non_drums, dim=0)\n",
    "        \n",
    "        #drums = self.dropout_layer(drums)\n",
    "        #non_drums = self.dropout_layer(non_drums)\n",
    "        \n",
    "        # Merge drums and non-drums\n",
    "        #out = torch.zeros((x_seq.size(0), self.d_model), \n",
    "        #                  device=self.device)\n",
    "        out = torch.zeros((x_seq.size(0), self.d), \n",
    "                          device=self.device, dtype=torch.half)\n",
    "        out[x_graph.is_drum] = drums\n",
    "        out[torch.logical_not(x_graph.is_drum)] = non_drums\n",
    "        # [n_nodes x d]\n",
    "        \n",
    "        #x_graph.x = torch.cat((x_graph.node_features, out), 1)\n",
    "        x_graph.x = out\n",
    "        x_graph.distinct_bars = x_graph.bars + self.n_bars*x_graph.batch\n",
    "        out = self.graph_encoder(x_graph)\n",
    "        # [n_nodes x d]\n",
    "        \n",
    "        with torch.cuda.amp.autocast(enabled=False):\n",
    "            out = self.graph_attention(out,\n",
    "                                       batch=x_graph.distinct_bars)\n",
    "            # [bs x n_bars x d]\n",
    "            \n",
    "        out = out.view(-1, self.n_bars * self.d)\n",
    "        # [bs x n_bars * d]\n",
    "        out_attr = self.bars_encoder_attr(out)\n",
    "        # [bs x d]\n",
    "        \n",
    "        # Process structure\n",
    "        out = self.cnn_encoder(x_acts.view(-1, self.n_tracks,\n",
    "                                                self.resolution*4))\n",
    "        # [bs * n_bars x d]\n",
    "        out = out.view(-1, self.n_bars * self.d)\n",
    "        # [bs x n_bars * d]\n",
    "        out_struct = self.bars_encoder_struct(out)\n",
    "        # [bs x d]\n",
    "        \n",
    "        # Merge attr state and struct state\n",
    "        out = torch.cat((out_attr, out_struct), dim=1)\n",
    "        out = self.dropout_layer(out)\n",
    "        out = self.linear_merge(out)\n",
    "        out = self.bn_lm(out)\n",
    "        out = F.relu(out)\n",
    "\n",
    "        # Compute mu and log(std^2)\n",
    "        out = self.dropout_layer(out)\n",
    "        mu = self.linear_mu(out)\n",
    "        log_var = self.linear_log_var(out)\n",
    "        \n",
    "        return mu, log_var\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.__dict__.update(kwargs)\n",
    "        \n",
    "        self.dropout_layer = nn.Dropout(p=self.dropout)\n",
    "\n",
    "        self.lin_divide = nn.Linear(self.d, 2 * self.d)\n",
    "        \n",
    "        self.bn_ld = nn.BatchNorm1d(num_features=2*self.d)\n",
    "        \n",
    "        self.bars_decoder_attr = nn.Linear(self.d, self.d * self.n_bars)\n",
    "        #self.context_bar_rnn = nn.GRU(input_size=self.d,\n",
    "        #                              hidden_size=self.d//2,\n",
    "        #                              num_layers=1,\n",
    "        #                              bidirectional=True,\n",
    "        #                              batch_first=True,\n",
    "        #                              dropout=self.dropout)\n",
    "        \n",
    "        self.bars_decoder_struct = nn.Linear(self.d, self.d * self.n_bars)\n",
    "        #self.struct_bar_rnn = nn.GRU(input_size=self.d//2,\n",
    "        #                              hidden_size=self.d//2,\n",
    "        #                              num_layers=1,\n",
    "        #                              batch_first=True,\n",
    "        #                              dropout=self.dropout)\n",
    "        \n",
    "        self.cnn_decoder = CNNDecoder(input_dim=self.d,\n",
    "                                      dense_dim=self.d,\n",
    "                                      dropout=0,\n",
    "                                      batch_norm=self.batch_norm)\n",
    "        \n",
    "        self.graph_decoder = GraphEncoder(dropout=self.dropout,\n",
    "                                          input_dim=self.d,\n",
    "                                          hidden_dim=self.d,\n",
    "                                          n_layers=self.gnn_n_layers,\n",
    "                                          num_relations=self.n_relations,\n",
    "                                          batch_norm=self.batch_norm)\n",
    "        \n",
    "        #gate_nn = nn.Sequential(\n",
    "        #    MLP(input_dim=self.d, output_dim=1, num_layers=1, act=False,\n",
    "        #              dropout=self.dropout),\n",
    "        #    nn.BatchNorm1d(1)\n",
    "        #)\n",
    "        #feat_nn = nn.Sequential(\n",
    "        #    MLP(input_dim=self.d, output_dim=self.d//2, num_layers=1,\n",
    "        #              dropout=self.dropout),\n",
    "        #    nn.BatchNorm1d(self.d//2)\n",
    "        #)\n",
    "        #self.graph_attention = GlobalAttention(gate_nn, feat_nn)\n",
    "        \n",
    "        #self.chord_decoder = nn.Linear(self.d, self.d*(self.max_simu_notes-1))\n",
    "        #self.chord_decoder = nn.GRU(input_size=self.d,\n",
    "        #                            hidden_size=self.d,\n",
    "        #                            num_layers=1,\n",
    "        #                            dropout=self.dropout)\n",
    "        #self.chord_decoder_drums = nn.GRU(input_size=self.d,\n",
    "        #                                  hidden_size=self.d,\n",
    "        #                                  num_layers=1,\n",
    "        #                                  dropout=self.dropout)\n",
    "        \n",
    "        # Pitch and dur linear layers\n",
    "        #self.drums_pitch_emb = nn.Linear(self.d//2, self.d_token_pitches)\n",
    "        #self.notes_pitch_emb = nn.Linear(self.d//2, self.d_token_pitches)\n",
    "        #self.dur_emb = nn.Linear(self.d//2, self.d_token_dur)\n",
    "\n",
    "\n",
    "    def forward(self, z, x_seq, x_acts, x_graph, src_mask, tgt_mask,\n",
    "                inference=False):\n",
    "        # z: [bs x d]\n",
    "        \n",
    "        # Obtain z_structure and z_attributes from z\n",
    "        #z = self.dropout_layer(z)\n",
    "        z = self.lin_divide(z)\n",
    "        z = self.bn_ld(z)\n",
    "        z = F.relu(z)\n",
    "        z = self.dropout_layer(z)\n",
    "        # [bs x 2*d]\n",
    "        \n",
    "        out_struct = z[:, :self.d]\n",
    "        # [bs x d] \n",
    "        out_struct = self.bars_decoder_struct(out_struct)\n",
    "        # [bs x n_bars * d]\n",
    "        \n",
    "        out_struct = self.cnn_decoder(out_struct.reshape(-1, self.d))\n",
    "        out_struct = out_struct.view(x_acts.size())\n",
    "        \n",
    "        # Decode attributes\n",
    "        out = z[:, self.d:]\n",
    "        # [bs x d]\n",
    "        out = self.bars_decoder_attr(out)\n",
    "        # [bs x n_bars * d]\n",
    "        \n",
    "        # Initialize node features with corresponding z_bar\n",
    "        # and propagate with GNN\n",
    "        _, counts = torch.unique(x_graph.distinct_bars, return_counts=True)\n",
    "        out = out.view(-1, self.d)\n",
    "        out = torch.repeat_interleave(out, counts, axis=0)\n",
    "        # [n_nodes x d]\n",
    "        \n",
    "        # Add one-hot encoding of tracks\n",
    "        # Todo: use also edge info\n",
    "        #x_graph.x = torch.cat((x_graph.node_features, out), 1)\n",
    "        x_graph.x = out\n",
    "        out = self.graph_decoder(x_graph)\n",
    "        # [n_nodes x d]\n",
    "        #print(\"Node decodings:\", node_decs.size())\n",
    "        \n",
    "        \n",
    "        out = torch.matmul(out, self.chord_decoder.weight)\n",
    "        # [n_nodes x max_simu_notes * d]\n",
    "        out = out.view(-1, self.max_simu_notes-1, self.d)\n",
    "        \n",
    "        drums = out[x_graph.is_drum]\n",
    "        non_drums = out[torch.logical_not(x_graph.is_drum)]\n",
    "        # [n_nodes(dr/non_dr) x max_simu_notes x d]\n",
    "        \n",
    "        # Obtain final pitch and dur decodings\n",
    "        # (softmax to be applied outside the model)\n",
    "        non_drums = self.dropout_layer(non_drums)\n",
    "        drums = self.dropout_layer(drums)\n",
    "        \n",
    "        drums_pitch = torch.matmul(drums[..., :self.d//2], self.drums_pitch_emb.weight)\n",
    "        drums_dur = torch.matmul(drums[..., self.d//2:], self.dur_emb.weight)\n",
    "        drums = torch.cat((drums_pitch, drums_dur), dim=-1)\n",
    "        # [n_nodes(dr) x max_simu_notes x d_token]\n",
    "        non_drums_pitch = torch.matmul(non_drums[..., :self.d//2], self.notes_pitch_emb.weight)\n",
    "        non_drums_dur = torch.matmul(non_drums[..., self.d//2:], self.dur_emb.weight)\n",
    "        non_drums = torch.cat((non_drums_pitch, non_drums_dur), dim=-1)\n",
    "        # [n_nodes(non_dr) x max_simu_notes x d_token]\n",
    "        \n",
    "        # Merge drums and non-drums\n",
    "        out = torch.zeros((x_seq.size(0), x_seq.size(1), x_seq.size(2)),\n",
    "                          device=self.device, dtype=torch.half)\n",
    "        out[x_graph.is_drum] = drums\n",
    "        out[torch.logical_not(x_graph.is_drum)] = non_drums\n",
    "        \n",
    "        out = out.view(x_seq.size())\n",
    "\n",
    "        return out, out_struct\n",
    "\n",
    "\n",
    "class VAE(nn.Module):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = Encoder(**kwargs)\n",
    "        self.decoder = Decoder(\n",
    "            drums_pitch_emb=self.encoder.drums_pitch_emb,\n",
    "            notes_pitch_emb=self.encoder.notes_pitch_emb,\n",
    "            dur_emb=self.encoder.dur_emb,\n",
    "            chord_decoder=self.encoder.chord_encoder,\n",
    "            **kwargs\n",
    "        )\n",
    "    \n",
    "    \n",
    "    def forward(self, x_seq, x_acts, x_graph, src_mask, tgt_mask,\n",
    "                inference=False):\n",
    "        \n",
    "        #src_mask = src_mask.view(-1, src_mask.size(-1))\n",
    "        \n",
    "        # Encoder pass\n",
    "        mu, log_var = self.encoder(x_seq, x_acts, x_graph, src_mask)\n",
    "        \n",
    "        # Reparameterization trick\n",
    "        z = torch.exp(0.5*log_var)\n",
    "        z = z * torch.randn_like(z)\n",
    "        #print(\"eps:\", eps.size())\n",
    "        z = z + mu\n",
    "        \n",
    "        # Shifting target sequence and mask for transformer decoder\n",
    "        tgt = x_seq[..., :-1, :]\n",
    "        src_mask = src_mask[:, :-1]\n",
    "        \n",
    "        # Decoder pass\n",
    "        out = self.decoder(z, tgt, x_acts, x_graph, src_mask, tgt_mask,\n",
    "                           inference=inference)\n",
    "        \n",
    "        return out, mu, log_var\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e439a46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "\n",
    "def print_params(model):\n",
    "    \n",
    "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
    "    total_params = 0\n",
    "    \n",
    "    for name, parameter in model.named_parameters():\n",
    "        \n",
    "        if not parameter.requires_grad:\n",
    "            continue\n",
    "            \n",
    "        param = parameter.numel()\n",
    "        table.add_row([name, param])\n",
    "        total_params += param\n",
    "        \n",
    "    print(table)\n",
    "    print(f\"Total Trainable Params: {total_params}\")\n",
    "    \n",
    "    return total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4846b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_square_subsequent_mask(sz):\n",
    "    \"\"\"Generates an upper-triangular matrix of -inf, with zeros on diag.\"\"\"\n",
    "    return torch.triu(torch.ones(sz, sz) * float('-inf'), diagonal=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7076bfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'models/2barsGNN3/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca9fcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(os.path.join(model, 'checkpoint'), map_location='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e258528",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = checkpoint['model_state_dict']\n",
    "params = torch.load(os.path.join(model, 'params'), map_location='cpu')\n",
    "vae = VAE(**params['model'], device=device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7315f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c2bb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.load_state_dict(state_dict)\n",
    "vae.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9b96c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Subset\n",
    "import numpy as np\n",
    "import os\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "n_bars = 2\n",
    "bs = 256\n",
    "nw = 4\n",
    "\n",
    "ds_dir = \"/data/cosenza/datasets/preprocessed_2bars/\"\n",
    "dataset = MIDIDataset(ds_dir, n_bars=n_bars)\n",
    "print('Dataset len:', len(dataset))\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=bs, shuffle=False, num_workers=nw)\n",
    "#print(len(subset))\n",
    "\n",
    "\n",
    "train_len = int(0.7 * len(dataset)) \n",
    "valid_len = int(0.01 * len(dataset))\n",
    "test_len = len(dataset) - train_len - valid_len\n",
    "#train_dataset, valid_dataset, test_dataset = random_split(model_dataset, (train_count, valid_count, test_count))\n",
    "tr_set, vl_set, ts_set = random_split(dataset, (train_len, valid_len, test_len))\n",
    "\n",
    "trainloader = DataLoader(tr_set, batch_size=bs, shuffle=True, num_workers=nw)\n",
    "validloader = DataLoader(vl_set, batch_size=bs, shuffle=False, num_workers=nw)\n",
    "#testloader = DataLoader(ts_set, batch_size=64, shuffle=False, num_workers=4)\n",
    "\n",
    "tr_len = len(tr_set)\n",
    "vl_len = len(vl_set)\n",
    "ts_len = len(ts_set)\n",
    "\n",
    "print('TR set len:', len(tr_set))\n",
    "print('VL set len:', len(vl_set))\n",
    "print('TS set len:', len(ts_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee356a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with torch.no_grad():\n",
    "    for idx, inputs in enumerate(trainloader):\n",
    "\n",
    "        x_graph = inputs.to(device)\n",
    "        x_seq, x_acts, src_mask = x_graph.x_seq, x_graph.x_acts, x_graph.src_mask\n",
    "        tgt_mask = generate_square_subsequent_mask(x_seq.size(-2)-1).to(device)\n",
    "\n",
    "\n",
    "        # Forward pass, get the reconstructions\n",
    "        with torch.cuda.amp.autocast():\n",
    "            outputs, mu, log_var = vae(x_seq, x_acts, x_graph, src_mask, tgt_mask)\n",
    "\n",
    "        break\n",
    "    \n",
    "\n",
    "seq_rec, acts_rec  = outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185ee4d2",
   "metadata": {},
   "source": [
    "Reconstruct activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafe2bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pitches_accuracy(seq_rec, x_seq, is_drum=None, drums=None):\n",
    "        \n",
    "    if drums is not None:\n",
    "        if drums:\n",
    "            seq_rec = seq_rec[is_drum]\n",
    "            x_seq = x_seq[is_drum]\n",
    "        else:\n",
    "            seq_rec = seq_rec[torch.logical_not(is_drum)]\n",
    "            x_seq = x_seq[torch.logical_not(is_drum)]\n",
    "\n",
    "    pitches_rec = F.softmax(seq_rec[..., :131], dim=-1)\n",
    "    pitches_rec = torch.argmax(pitches_rec, dim=-1)\n",
    "    pitches_true = torch.argmax(x_seq[..., :131], dim=-1)\n",
    "\n",
    "    #print(\"All EOS pitches?\", torch.all(pitches_rec == 129))\n",
    "\n",
    "    mask = (pitches_true != 130)\n",
    "    #mask = torch.logical_and(pitches_true != 128,\n",
    "     #                        pitches_true != 129)\n",
    "    #mask = torch.logical_and(mask,\n",
    "     #                        pitches_true != 130)\n",
    "\n",
    "    preds_pitches = (pitches_rec == pitches_true)\n",
    "    preds_pitches = torch.logical_and(preds_pitches, mask)\n",
    "\n",
    "    return torch.sum(preds_pitches) / torch.sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1ee032",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_seq = x_seq[..., 1:, :]\n",
    "_pitches_accuracy(seq_rec, new_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d6ee60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "print(acts_rec.size())\n",
    "print(x_acts.size())\n",
    "print(x_seq.size())\n",
    "print(seq_rec.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c225d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = torch.sigmoid(acts_rec[3])\n",
    "s[s > 0.5] = 1\n",
    "s[s <= 0.5] = 0\n",
    "#plt.matshow(s.detach().numpy())\n",
    "#plt.xticks(range(0, s.size(1), 8), range(1, 5))\n",
    "#plt.grid()\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.pcolormesh(s.detach().cpu().numpy(), edgecolors='k', linewidth=1)\n",
    "ax = plt.gca()\n",
    "ax.set_aspect('equal')\n",
    "plt.xticks(range(0, s.size(1), 8), range(1, 5))\n",
    "plt.yticks(range(0, 4), range(1, 5))\n",
    "ax.invert_yaxis()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02410420",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = torch.sigmoid(x_acts[3])\n",
    "#plt.matshow(s.detach().numpy())\n",
    "#plt.xticks(range(0, s.size(1), 8), range(1, 5))\n",
    "#plt.grid()\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.pcolormesh(s.detach().cpu().numpy(), edgecolors='k', linewidth=1)\n",
    "ax = plt.gca()\n",
    "ax.set_aspect('equal')\n",
    "plt.xticks(range(0, s.size(1), 8), range(1, 5))\n",
    "plt.yticks(range(0, 4), range(1, 5))\n",
    "ax.invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42d20d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct dense reconstruction from sparse representation\n",
    "\n",
    "def dense_from_sparse(seq, acts, bars):\n",
    "    \n",
    "    dtype = seq.dtype\n",
    "    \n",
    "    acts = acts.view(-1, bars, acts.size(-2), acts.size(-1))\n",
    "    dtype = seq.dtype\n",
    "    seq_dense = torch.zeros((acts.size(0), acts.size(1), acts.size(2),\n",
    "                             acts.size(3), seq.size(-2), seq.size(-1)),\n",
    "                            dtype=dtype).to(device)\n",
    "\n",
    "    size = seq_dense.size()\n",
    "\n",
    "    seq_dense = seq_dense.view(-1, seq_dense.size(-2), seq_dense.size(-1))\n",
    "\n",
    "    silence = torch.zeros((seq_dense.size(-2), seq_dense.size(-1)),\n",
    "                            dtype=dtype).to(device)\n",
    "    silence[:, 129] = 1. # eos token\n",
    "\n",
    "    seq_dense[acts.bool().view(-1)] = seq\n",
    "    seq_dense[torch.logical_not(acts.bool().view(-1))] = silence\n",
    "\n",
    "    seq_dense = seq_dense.view(size)\n",
    "    \n",
    "    return seq_dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c280aeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_rec_dense = dense_from_sparse(seq_rec, x_acts, bars=n_bars)\n",
    "x_seq_dense = dense_from_sparse(x_seq, x_acts, bars=n_bars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ccb213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collapse bars dimension\n",
    "seq_rec_dense = seq_rec_dense.permute(0, 2, 1, 3, 4, 5)\n",
    "x_seq_dense = x_seq_dense.permute(0, 2, 1, 3, 4, 5)\n",
    "\n",
    "print(seq_rec_dense.size())\n",
    "\n",
    "size = [\n",
    "    seq_rec_dense.size(0),\n",
    "    seq_rec_dense.size(1),\n",
    "    -1,\n",
    "    seq_rec_dense.size(4),\n",
    "    seq_rec_dense.size(5)\n",
    "]\n",
    "\n",
    "seq_rec_dense = seq_rec_dense.reshape(size)\n",
    "size[-2] = x_seq_dense.size(-2)\n",
    "x_seq_dense = x_seq_dense.reshape(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47b9002",
   "metadata": {},
   "outputs": [],
   "source": [
    "music_real = x_seq_dense[32]\n",
    "music_rec = seq_rec_dense[32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9a645f",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESOLUTION = 8\n",
    "\n",
    "#tracks = [drum_track, bass_track, guitar_track, strings_track]\n",
    "import copy\n",
    "\n",
    "def from_tensor_to_muspy(music_tensor, track_data):\n",
    "    \n",
    "    tracks = []\n",
    "    \n",
    "    for tr in range(music_tensor.size(0)):\n",
    "        \n",
    "        notes = []\n",
    "        \n",
    "        for ts in range(music_tensor.size(1)):\n",
    "            for note in range(music_tensor.size(2)):\n",
    "                \n",
    "                pitch = music_tensor[tr, ts, note, :131]\n",
    "                pitch = torch.argmax(pitch)\n",
    "\n",
    "                if pitch == 129:\n",
    "                    break\n",
    "                \n",
    "                if pitch != 128:\n",
    "                    dur = music_tensor[tr, ts, note, 131:]\n",
    "                    dur = torch.argmax(dur) + 1\n",
    "                    \n",
    "                    if dur == 97 or dur == 98 or dur == 99:\n",
    "                        dur = 4\n",
    "                        continue\n",
    "                    \n",
    "                    notes.append(muspy.Note(ts, pitch.item(), dur.item(), 64))\n",
    "                    #notes.append(muspy.Note(ts, pitch.item(), dur, 64))\n",
    "        \n",
    "        if track_data[tr][0] == 'Drums':\n",
    "            track = muspy.Track(name='Drums', is_drum=True, notes=copy.deepcopy(notes))\n",
    "        else:\n",
    "            track = muspy.Track(name=track_data[tr][0], \n",
    "                                program=track_data[tr][1],\n",
    "                                notes=copy.deepcopy(notes))\n",
    "        tracks.append(track)\n",
    "    \n",
    "    meta = muspy.Metadata(title='prova')\n",
    "    music = muspy.Music(tracks=tracks, metadata=meta, resolution=RESOLUTION)\n",
    "    \n",
    "    return music\n",
    "\n",
    "\n",
    "track_data = [('Drums', -1), ('Bass', 34), ('Guitar', 1), ('Strings', 41)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae906df2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import muspy\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "prefix = \"data/music/\"\n",
    "\n",
    "real = from_tensor_to_muspy(music_real, track_data)\n",
    "\n",
    "fig, axs_ = plt.subplots(4, sharex=True, figsize=(10,10))\n",
    "fig.subplots_adjust(hspace=0)\n",
    "axs = axs_.tolist()\n",
    "muspy.show_pianoroll(music=real, yticklabel='off', grid_axis='off', axs=axs)\n",
    "plt.savefig(prefix + \"real\" + \".png\", dpi=200)\n",
    "muspy.write_midi(prefix + \"real\" + \".mid\", real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f02ceb6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rec = from_tensor_to_muspy(music_rec, track_data)\n",
    "\n",
    "fig, axs_ = plt.subplots(4, sharex=True, figsize=(10,10))\n",
    "fig.subplots_adjust(hspace=0)\n",
    "axs = axs_.tolist()\n",
    "\n",
    "muspy.show_pianoroll(rec, yticklabel='off', grid_axis='off', axs=axs)\n",
    "plt.savefig(prefix + \"rec\" + \".png\", dpi=200)\n",
    "muspy.write_midi(prefix + \"rec\" + \".mid\", rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ee6b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"data/music/file\"\n",
    "\n",
    "for i in range(10):\n",
    "    music_tensor = dataset[20+i][0]\n",
    "    music = from_tensor_to_muspy(music_tensor, track_data)\n",
    "    muspy.show_pianoroll(music, yticklabel='off', grid_axis='off')\n",
    "    plt.savefig(prefix + str(i) + \".png\")\n",
    "    muspy.write_midi(prefix + str(i) + \".mid\", music)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baaf02c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'n_tracks': 4,\n",
    "    'dropout': 0.1,\n",
    "    'd_token': 230,\n",
    "    'd_model': 256,\n",
    "    'n_head_transf': 2,\n",
    "    'n_layers_transf': 2,\n",
    "    'gnn_input_dim': 256 + 4,\n",
    "    'gnn_n_layers': 3,\n",
    "    'd_latent': 256,\n",
    "    'resolution': 8\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
