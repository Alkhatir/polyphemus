{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "from torch.utils.data import Subset\n",
    "from torch.utils.data import random_split\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Batch\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "from utils import set_seed\n",
    "\n",
    "from data import MIDIDataset, graph_from_tensor, graph_from_tensor_torch\n",
    "from model import VAE\n",
    "from utils import plot_struct, dense_from_sparse, dense_from_sparse_torch, muspy_from_dense, muspy_from_dense_torch\n",
    "from utils import plot_pianoroll, midi_from_muspy\n",
    "from train import VAETrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set global seed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dir = 'models/'\n",
    "model = 'LMD2'\n",
    "gpu = True\n",
    "device_idx = 3\n",
    "\n",
    "checkpoint = torch.load(os.path.join(models_dir, model, 'checkpoint'), map_location='cpu')\n",
    "state_dict = checkpoint['model_state_dict']\n",
    "params = torch.load(os.path.join(models_dir, model, 'params'), map_location='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['epoch', 'batch', 'tot_batches', 'betas', 'min_val_loss', 'print_every', 'save_every', 'eval_every', 'lrs', 'tr_losses', 'tr_accuracies', 'val_losses', 'val_accuracies', 'model_state_dict', 'optimizer_state_dict'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_decoder_keys(state_dict):\n",
    "    i = 0\n",
    "\n",
    "    for k in state_dict.keys():\n",
    "        if 'decoder.' in k:\n",
    "            print(k)\n",
    "            i += 1\n",
    "\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "model_dir = './models/2barsGNNDEFrefactoring'\n",
    "model_name = 'prova'\n",
    "\n",
    "renaming_dict = {\n",
    "    \"decoder.lin_divide.\": \"decoder.lin_decoder.\",\n",
    "    \"decoder.bn_ld.\": \"decoder.batch_norm.\",\n",
    "    \"decoder.bars_decoder_attr.\": \"decoder.c_decoder.bars_decoder.\",\n",
    "    \"decoder.bars_decoder_struct.\": \"decoder.s_decoder.bars_decoder.\",\n",
    "    \"decoder.cnn_decoder.\": \"decoder.s_decoder.cnn_decoder.\",\n",
    "    \"decoder.graph_decoder.\": \"decoder.c_decoder.graph_decoder.\",\n",
    "    \"decoder.chord_decoder.\": \"decoder.c_decoder.chord_decoder.\",\n",
    "    \"decoder.drums_pitch_emb.\": \"decoder.c_decoder.drums_pitch_emb.\",\n",
    "    \"decoder.notes_pitch_emb.\": \"decoder.c_decoder.non_drums_pitch_emb.\",\n",
    "    \"decoder.dur_emb.\": \"decoder.c_decoder.dur_emb.\"\n",
    "}\n",
    "\n",
    "new_state_dict = OrderedDict()\n",
    "\n",
    "for old_key, value in state_dict.items():\n",
    "    new_key = old_key\n",
    "    for old_sub_str, new_sub_str in renaming_dict.items():\n",
    "        new_key = new_key.replace(old_sub_str, new_sub_str)  # Replace the old substrings with the new ones\n",
    "    new_state_dict[new_key] = value\n",
    "\n",
    "print_decoder_keys(new_state_dict)\n",
    "\n",
    " \n",
    "checkpoint['model_state_dict'] = new_state_dict\n",
    "#print_decoder_keys(checkpoint['model_state_dict'])\n",
    "#state_dict = checkpoint['model_state_dict']\n",
    "\n",
    "path = os.path.join(model_dir, model_name)\n",
    "torch.save(checkpoint, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Device idx: 3\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.set_device(device_idx)\n",
    "\n",
    "device = torch.device(\"cuda\") if gpu else torch.device(\"cpu\")\n",
    "print(\"Device:\", device)\n",
    "print(\"Device idx:\", torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'training': {'batch_size': 256,\n",
       "  'num_workers': 4,\n",
       "  'ds_len': 6813946,\n",
       "  'tr_len': 4769762,\n",
       "  'vl_len': 681394,\n",
       "  'ts_len': 1362790},\n",
       " 'model': {'dropout': 0,\n",
       "  'batch_norm': True,\n",
       "  'gnn_n_layers': 8,\n",
       "  'actsnn_n_layers': 2,\n",
       "  'd': 512,\n",
       "  'rnn_n_layers': 1,\n",
       "  'k_isgn': 3,\n",
       "  'd_token': 230,\n",
       "  'd_token_pitches': 131,\n",
       "  'd_token_dur': 99,\n",
       "  'n_bars': 2,\n",
       "  'n_relations': 6,\n",
       "  'n_tracks': 4,\n",
       "  'resolution': 8,\n",
       "  'max_simu_notes': 16},\n",
       " 'scheduler': {'peak_lr': 0.0001,\n",
       "  'final_lr_scale': 0.01,\n",
       "  'warmup_steps': 8000,\n",
       "  'decay_steps': 800000},\n",
       " 'optimizer': {'betas': (0.9, 0.98), 'eps': 1e-09, 'lr': 5e-06},\n",
       " 'beta_annealing': {'beta_update': True,\n",
       "  'anneal_start': 40000,\n",
       "  'beta_max': 0.01,\n",
       "  'step_size': 0.001,\n",
       "  'anneal_end': 500000}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAE(\n",
       "  (encoder): Encoder(\n",
       "    (dropout_layer): Dropout(p=0, inplace=False)\n",
       "    (notes_pitch_emb): Linear(in_features=131, out_features=256, bias=True)\n",
       "    (drums_pitch_emb): Linear(in_features=131, out_features=256, bias=True)\n",
       "    (dur_emb): Linear(in_features=99, out_features=256, bias=True)\n",
       "    (bn_npe): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn_dpe): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn_de): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (chord_encoder): Linear(in_features=7680, out_features=512, bias=True)\n",
       "    (graph_encoder): GCN(\n",
       "      (layers): ModuleList(\n",
       "        (0): RGCNConv(512, 512, num_relations=6)\n",
       "        (1): RGCNConv(512, 512, num_relations=6)\n",
       "        (2): RGCNConv(512, 512, num_relations=6)\n",
       "        (3): RGCNConv(512, 512, num_relations=6)\n",
       "        (4): RGCNConv(512, 512, num_relations=6)\n",
       "        (5): RGCNConv(512, 512, num_relations=6)\n",
       "        (6): RGCNConv(512, 512, num_relations=6)\n",
       "        (7): RGCNConv(512, 512, num_relations=6)\n",
       "      )\n",
       "      (norm_layers): ModuleList(\n",
       "        (0): BatchNorm(512)\n",
       "        (1): BatchNorm(512)\n",
       "        (2): BatchNorm(512)\n",
       "        (3): BatchNorm(512)\n",
       "        (4): BatchNorm(512)\n",
       "        (5): BatchNorm(512)\n",
       "        (6): BatchNorm(512)\n",
       "        (7): BatchNorm(512)\n",
       "      )\n",
       "    )\n",
       "    (graph_attention): GlobalAttention(gate_nn=Sequential(\n",
       "      (0): MLP(\n",
       "        (layers): ModuleList(\n",
       "          (0): Linear(in_features=512, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    ), nn=None)\n",
       "    (bars_encoder_attr): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (cnn_encoder): CNNEncoder(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): MaxPool2d(kernel_size=(1, 4), stride=(1, 4), padding=0, dilation=1, ceil_mode=False)\n",
       "        (4): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): ReLU(inplace=True)\n",
       "      )\n",
       "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "      (lin): Sequential(\n",
       "        (0): Dropout(p=0, inplace=False)\n",
       "        (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Dropout(p=0, inplace=False)\n",
       "        (4): Linear(in_features=512, out_features=512, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (bars_encoder_struct): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (linear_merge): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (bn_lm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (linear_mu): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (linear_log_var): Linear(in_features=512, out_features=512, bias=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (lin_decoder): Linear(in_features=512, out_features=1024, bias=True)\n",
       "    (batch_norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dropout): Dropout(p=0, inplace=False)\n",
       "    (s_decoder): StructureDecoder(\n",
       "      (bars_decoder): Linear(in_features=512, out_features=1024, bias=True)\n",
       "      (cnn_decoder): CNNDecoder(\n",
       "        (lin): Sequential(\n",
       "          (0): Dropout(p=0, inplace=False)\n",
       "          (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Dropout(p=0, inplace=False)\n",
       "          (4): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "        (unflatten): Unflatten(dim=1, unflattened_size=(16, 4, 8))\n",
       "        (conv): Sequential(\n",
       "          (0): Upsample(scale_factor=(1.0, 4.0), mode=nearest)\n",
       "          (1): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): Conv2d(8, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (c_decoder): ContentDecoder(\n",
       "      (bars_decoder): Linear(in_features=512, out_features=1024, bias=True)\n",
       "      (graph_decoder): GCN(\n",
       "        (layers): ModuleList(\n",
       "          (0): RGCNConv(512, 512, num_relations=6)\n",
       "          (1): RGCNConv(512, 512, num_relations=6)\n",
       "          (2): RGCNConv(512, 512, num_relations=6)\n",
       "          (3): RGCNConv(512, 512, num_relations=6)\n",
       "          (4): RGCNConv(512, 512, num_relations=6)\n",
       "          (5): RGCNConv(512, 512, num_relations=6)\n",
       "          (6): RGCNConv(512, 512, num_relations=6)\n",
       "          (7): RGCNConv(512, 512, num_relations=6)\n",
       "        )\n",
       "        (norm_layers): ModuleList(\n",
       "          (0): BatchNorm(512)\n",
       "          (1): BatchNorm(512)\n",
       "          (2): BatchNorm(512)\n",
       "          (3): BatchNorm(512)\n",
       "          (4): BatchNorm(512)\n",
       "          (5): BatchNorm(512)\n",
       "          (6): BatchNorm(512)\n",
       "          (7): BatchNorm(512)\n",
       "        )\n",
       "      )\n",
       "      (chord_decoder): Linear(in_features=512, out_features=7680, bias=True)\n",
       "      (drums_pitch_emb): Linear(in_features=256, out_features=131, bias=True)\n",
       "      (non_drums_pitch_emb): Linear(in_features=256, out_features=131, bias=True)\n",
       "      (dur_emb): Linear(in_features=256, out_features=99, bias=True)\n",
       "      (dropout_layer): Dropout(p=0, inplace=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae = VAE(**params['model'], device=device).to(device)\n",
    "vae.load_state_dict(state_dict)\n",
    "vae.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation\n",
    "1. Sample z from normal.\n",
    "2. Create and sample structure.\n",
    "3. Create graph from sampled structure.\n",
    "4. Generate content.\n",
    "5. Put structure and content together and create muspy music."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_music(vae, z):\n",
    "    \n",
    "    # Get structure and content logits\n",
    "    with torch.cuda.amp.autocast():\n",
    "        _, c_logits, s_tensor = vae.decoder(z)\n",
    "    \n",
    "    # Build (n_batches x n_bars x n_tracks x n_timesteps x Sigma x d_token)\n",
    "    # multitrack pianoroll tensor containing logits for each activation and\n",
    "    # hard silences elsewhere\n",
    "    mtp = dense_from_sparse_torch(c_logits, s_tensor)\n",
    "    \n",
    "    # Collapse bars dimension\n",
    "    mtp = mtp.permute(0, 2, 1, 3, 4, 5)\n",
    "    size = (mtp.shape[0], mtp.shape[1], -1, mtp.shape[4], mtp.shape[5])\n",
    "    mtp = mtp.reshape(*size)\n",
    "    \n",
    "    return mtp, s_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample $\\boldsymbol{z}$ from normal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = params['training']['batch_size']\n",
    "d_model = params['model']['d']\n",
    "shape = (bs, d_model)\n",
    "\n",
    "z_norm = torch.normal(\n",
    "    torch.zeros(shape, device=device),\n",
    "    torch.ones(shape, device=device)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 bars: 24 26 31 200 202 204\n",
    "# 16 bars: 4\n",
    "same = False\n",
    "idx = 26\n",
    "\n",
    "if same:\n",
    "    z = z_norm[idx].repeat(params['training']['batch_size'], 1)\n",
    "else:\n",
    "    z = z_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "start_folder_idx = 0\n",
    "start_z_idx = 0\n",
    "n_songs = 10\n",
    "extend = True\n",
    "root_dir = \"tmpmusic/gen\"\n",
    "track_data = [('Drums', -1), ('Bass', 34), ('Guitar', 1), ('Strings', 83)]\n",
    "\n",
    "n_bars = params['model']['n_bars']\n",
    "root = os.path.join(root_dir, str(n_bars))\n",
    "\n",
    "# Generate music with the model\n",
    "print(\"Generating bars...\")\n",
    "music, s = generate_music(vae, z)\n",
    "\n",
    "# Iterate over the generated n-bar sequences\n",
    "for i in range(start_z_idx, start_z_idx + n_songs):\n",
    "    \n",
    "    # Create the directory if it does not exist\n",
    "    save_dir = os.path.join(root, str(start_folder_idx + i))\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    print(\"Generating midi sequence \" + str(i+1) + \"...\")\n",
    "    \n",
    "    # Generate muspy song from dense representation\n",
    "    muspy_song = muspy_from_dense_torch(music[i], track_data, params['model']['resolution'])\n",
    "\n",
    "    # Generate and save midi data from muspy song\n",
    "    midi_from_muspy(muspy_song, save_dir, name='music')\n",
    "    \n",
    "    # Plot the pianoroll associated to the sequence\n",
    "    preset = 'full'\n",
    "    with mpl.rc_context({'lines.linewidth': 4, 'axes.linewidth': 4, 'font.size': 34}):\n",
    "        plot_pianoroll(muspy_song, save_dir, name='pianoroll',\n",
    "                       figsize=(20, 10), fformat='png',\n",
    "                       preset=preset)\n",
    "        s_curr = s[i]\n",
    "        s_curr = s_curr.permute(1, 0, 2)\n",
    "        s_curr = s_curr.reshape(s_curr.shape[0], -1)\n",
    "        with mpl.rc_context({'lines.linewidth': 1, 'axes.linewidth': 1, 'font.size': 14}):\n",
    "            plot_struct(s_curr.cpu(), name='structure', save_dir=save_dir, figsize=(12, 3))\n",
    "\n",
    "    if extend:\n",
    "        # Generate extended sequence\n",
    "        print(\"Generating extended (looped) midi sequence \" + str(i+1) + \"...\")\n",
    "        extended = music[i].repeat(1, 4, 1, 1)\n",
    "        extended = muspy_from_dense_torch(extended, track_data, params['model']['resolution'])\n",
    "        midi_from_muspy(extended, save_dir, name='extended')\n",
    "\n",
    "print(\"Finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_music(vae, z, S=0.5, T=0.001):\n",
    "    \n",
    "    # Get structure and sample\n",
    "    s = vae.decoder.forward_struct(z)\n",
    "    s = torch.sigmoid(s)\n",
    "    \n",
    "    # Hard threshold instead of sampling gives more pleasant results\n",
    "    s[s >= S] = 1\n",
    "    s[s < S] = 0\n",
    "\n",
    "    s = s.detach().cpu().numpy()\n",
    "    \n",
    "    graphs = [0 for _ in range(params['training']['batch_size'])]\n",
    "\n",
    "    # Create graph structures for each input in the batch\n",
    "    for i in range(s.shape[0]):\n",
    "        graphs[i] = graph_from_tensor(s[i])\n",
    "\n",
    "    # Create batch from graphs\n",
    "    graphs = Batch.from_data_list(graphs, exclude_keys=['batch'])\n",
    "    graphs = graphs.to(device)\n",
    "    \n",
    "    # Get content from z and structure\n",
    "    with torch.cuda.amp.autocast():\n",
    "        c = vae.decoder.forward_content(z, graphs)\n",
    "\n",
    "    c = c.detach().cpu().numpy()\n",
    "    \n",
    "    # Compute dense representation (pianoroll with silences)\n",
    "    dense = dense_from_sparse(c, s)\n",
    "    \n",
    "    # Collapse bars dimension\n",
    "    dense = np.transpose(dense, (0, 2, 1, 3, 4, 5))\n",
    "\n",
    "    size = (\n",
    "        dense.shape[0],\n",
    "        dense.shape[1],\n",
    "        -1,\n",
    "        dense.shape[4],\n",
    "        dense.shape[5]\n",
    "    )\n",
    "\n",
    "    dense = dense.reshape(size)\n",
    "    \n",
    "    return dense, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import muspy\n",
    "\n",
    "def plot_pianoroll(music, save_dir=None, name=None, figsize=(10, 10),\n",
    "                   fformat=\"png\", xticklabel='on', preset='full', **kwargs):\n",
    "\n",
    "    fig, axs_ = plt.subplots(4, sharex=True, figsize=figsize)\n",
    "    fig.subplots_adjust(hspace=0)\n",
    "    axs = axs_.tolist()\n",
    "    muspy.show_pianoroll(music=music, yticklabel='off',\n",
    "                         xticklabel=xticklabel, grid_axis='off',\n",
    "                         axs=axs, preset=preset)\n",
    "    \n",
    "    if save_dir:\n",
    "        plt.savefig(os.path.join(save_dir, name+\".\"+fformat), format=fformat, dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "start_folder_idx = 0\n",
    "start_z_idx = 0\n",
    "n_songs = 10\n",
    "extend = True\n",
    "root_dir = \"tmpmusic/gen\"\n",
    "track_data = [('Drums', -1), ('Bass', 34), ('Guitar', 1), ('Strings', 83)]\n",
    "\n",
    "n_bars = params['model']['n_bars']\n",
    "root = os.path.join(root_dir, str(n_bars))\n",
    "\n",
    "# Generate music with the model\n",
    "print(\"Generating bars...\")\n",
    "music, s = generate_music(vae, z, S=0.5, T=0.001)\n",
    "\n",
    "# Iterate over the generated n-bar sequences\n",
    "for i in range(start_z_idx, start_z_idx + n_songs):\n",
    "    \n",
    "    # Create the directory if it does not exist\n",
    "    save_dir = os.path.join(root, str(start_folder_idx + i))\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    print(\"Generating midi sequence \" + str(i+1) + \"...\")\n",
    "    \n",
    "    # Generate muspy song from dense representation\n",
    "    muspy_song = muspy_from_dense(music[i], track_data, params['model']['resolution'])\n",
    "\n",
    "    # Generate and save midi data from muspy song\n",
    "    midi_from_muspy(muspy_song, save_dir, name='music')\n",
    "    \n",
    "    # Plot the pianoroll associated to the sequence\n",
    "    preset = 'full'\n",
    "    with mpl.rc_context({'lines.linewidth': 4, 'axes.linewidth': 4, 'font.size': 34}):\n",
    "        plot_pianoroll(muspy_song, save_dir, name='pianoroll',\n",
    "                       figsize=(20, 10), fformat='png',\n",
    "                       preset=preset)\n",
    "    \n",
    "    # Plot the structure tensor\n",
    "    if n_bars == 2:\n",
    "        s_curr = s[i]\n",
    "        s_curr = np.transpose(s_curr, (1, 0, 2))\n",
    "        s_curr = s_curr.reshape(s_curr.shape[0], -1)\n",
    "        with mpl.rc_context({'lines.linewidth': 1, 'axes.linewidth': 1, 'font.size': 14}):\n",
    "            plot_struct(s_curr, name='structure', save_dir=save_dir, figsize=(12, 3))\n",
    "\n",
    "    if extend:\n",
    "        # Generate extended sequence\n",
    "        print(\"Generating extended (looped) midi sequence \" + str(i+1) + \"...\")\n",
    "        extended = np.tile(music[i], (1, 4, 1, 1))\n",
    "        extended = muspy_from_dense(extended, track_data, params['model']['resolution'])\n",
    "        midi_from_muspy(extended, save_dir, name='extended')\n",
    "\n",
    "print(\"Finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate():\n",
    "    # make sure struct tensor is not zero! or maybe we can let internal methods fix that\n",
    "    pass\n",
    "\n",
    "def save():\n",
    "    # make sure struct tensor is not zero! or maybe we can let internal methods fix that\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_music(vae, z, s_cond=None, s_tensor_cond=None):\n",
    "    \n",
    "    # Get structure and content logits\n",
    "    with torch.cuda.amp.autocast():\n",
    "        _, c_logits, s_tensor_out = vae.decoder(z, s_cond)\n",
    "    \n",
    "    s_tensor = s_tensor_cond if s_tensor_cond != None else s_tensor_out\n",
    "    \n",
    "    # Build (n_batches x n_bars x n_tracks x n_timesteps x Sigma x d_token)\n",
    "    # multitrack pianoroll tensor containing logits for each activation and\n",
    "    # hard silences elsewhere\n",
    "    mtp = dense_from_sparse_torch(c_logits, s_tensor)\n",
    "    \n",
    "    # Collapse bars dimension\n",
    "    mtp = mtp.permute(0, 2, 1, 3, 4, 5)\n",
    "    size = (mtp.shape[0], mtp.shape[1], -1, mtp.shape[4], mtp.shape[5])\n",
    "    mtp = mtp.reshape(*size)\n",
    "    \n",
    "    return mtp, s_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "\n",
    "def save(mtp, dir, s_tensor=None, track_data=None):\n",
    "\n",
    "    start_folder_idx = 0\n",
    "    start_z_idx = 0\n",
    "    n_songs = 10\n",
    "    extend = True\n",
    "    track_data = ([('Drums', -1), ('Bass', 34), ('Guitar', 1), ('Strings', 83)]\n",
    "                  if track_data == None else track_data)\n",
    "\n",
    "    n_bars = params['model']['n_bars']\n",
    "\n",
    "    # Iterate over the generated n-bar sequences\n",
    "    for i in range(start_z_idx, start_z_idx + n_songs):\n",
    "        \n",
    "        # Create the directory if it does not exist\n",
    "        save_dir = os.path.join(dir, str(start_folder_idx + i))\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "        print(\"Saving midi sequence \" + str(i+1) + \"...\")\n",
    "        \n",
    "        # Generate muspy song from multitrack pianoroll, then midi from muspy\n",
    "        # and save\n",
    "        muspy_song = muspy_from_dense_torch(mtp[i], track_data, \n",
    "                                            params['model']['resolution'])\n",
    "        midi_from_muspy(muspy_song, save_dir, name='music')\n",
    "        \n",
    "        # Plot the pianoroll associated to the sequence\n",
    "        preset = 'full'\n",
    "        with mpl.rc_context({'lines.linewidth': 4, \n",
    "                             'axes.linewidth': 4, 'font.size': 34}):\n",
    "            plot_pianoroll(muspy_song, save_dir, name='pianoroll',\n",
    "                           figsize=(20, 10), fformat='png', preset=preset)\n",
    "        \n",
    "        # Plot structure_tensor if present\n",
    "        if s_tensor != None:\n",
    "            s_curr = s_tensor[i]\n",
    "            s_curr = s_curr.permute(1, 0, 2)\n",
    "            s_curr = s_curr.reshape(s_curr.shape[0], -1)\n",
    "            with mpl.rc_context({'lines.linewidth': 1, \n",
    "                                 'axes.linewidth': 1, 'font.size': 14}):\n",
    "                plot_struct(s_curr.cpu(), name='structure', \n",
    "                            save_dir=save_dir, figsize=(12, 3))\n",
    "\n",
    "        if extend:\n",
    "            # Generate extended sequence\n",
    "            print(\"Saving extended (looped) midi sequence \" + str(i+1) + \"...\")\n",
    "            extended = mtp[i].repeat(1, 4, 1, 1)\n",
    "            extended = muspy_from_dense_torch(extended, track_data, \n",
    "                                              params['model']['resolution'])\n",
    "            midi_from_muspy(extended, save_dir, name='extended')\n",
    "        \n",
    "        print()\n",
    "\n",
    "    print(\"Finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_z(bs, d_model):\n",
    "    bs = params['training']['batch_size']\n",
    "    d_model = params['model']['d']\n",
    "    shape = (bs, d_model)\n",
    "\n",
    "    z_norm = torch.normal(\n",
    "        torch.zeros(shape, device=device),\n",
    "        torch.ones(shape, device=device)\n",
    "    )\n",
    "    \n",
    "    return z_norm\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 64.00 MiB (GPU 3; 15.75 GiB total capacity; 14.32 GiB already allocated; 9.56 MiB free; 14.52 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1283/1083430808.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_z\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_structure_from_binary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mmtp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_music\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvae\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmtp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1283/1934396135.py\u001b[0m in \u001b[0;36mgenerate_music\u001b[0;34m(vae, z, s_cond, s_tensor_cond)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Get structure and content logits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_tensor_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_cond\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0ms_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms_tensor_cond\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0ms_tensor_cond\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0ms_tensor_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/test/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/thesis/Polyphemus/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, z, s)\u001b[0m\n\u001b[1;32m    768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0;31m# Obtain the tensor containing content logits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 770\u001b[0;31m         \u001b[0mc_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_decoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    771\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0ms_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/test/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/thesis/Polyphemus/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, z_c, structure)\u001b[0m\n\u001b[1;32m    664\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat_interleave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# n_nodes x d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m         \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 666\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_decoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# n_nodes x d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchord_decoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# n_nodes x (max_simu_notes*d)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/test/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/thesis/Polyphemus/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    346\u001b[0m             \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_norm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/test/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/thesis/Polyphemus/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_type, edge_attr)\u001b[0m\n\u001b[1;32m    246\u001b[0m                     h = self.propagate(tmp, x=x_l, size=size,\n\u001b[1;32m    247\u001b[0m                                        edge_attr=attr)\n\u001b[0;32m--> 248\u001b[0;31m                     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 64.00 MiB (GPU 3; 15.75 GiB total capacity; 14.32 GiB already allocated; 9.56 MiB free; 14.52 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "bs = params['training']['batch_size']\n",
    "d_model = params['model']['d']\n",
    "n_bars = 2\n",
    "n_tracks = 4\n",
    "n_timesteps = 32\n",
    "n_sequences = 10\n",
    "dir = 'tmpmusic/'\n",
    "\n",
    "track_data = [('Drums', -1), ('Bass', 34), ('Guitar', 1), ('Strings', 83)]\n",
    "\n",
    "# Test structure tensor\n",
    "s_tensor = torch.zeros(n_bars, n_tracks, n_timesteps)\n",
    "s_tensor[:, :, ::2] = 1\n",
    "s_tensor = s_tensor.bool()\n",
    "s_tensor = s_tensor.unsqueeze(0).repeat(bs, 1, 1, 1)\n",
    "s_tensor.to(device)\n",
    "\n",
    "z = generate_z(bs, d_model)\n",
    "s = vae.decoder._structure_from_binary(s_tensor)\n",
    "s.to(device)\n",
    "mtp, s_tensor = generate_music(vae, z, s, s_tensor)\n",
    "save(mtp, dir, s_tensor, track_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
