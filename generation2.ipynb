{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "from torch.utils.data import Subset\n",
    "from torch.utils.data import random_split\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Batch\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "from utils import set_seed\n",
    "\n",
    "from data import MIDIDataset, graph_from_tensor, graph_from_tensor_torch\n",
    "from model import VAE\n",
    "from utils import plot_struct, dense_from_sparse, dense_from_sparse_torch, muspy_from_dense, muspy_from_dense_torch\n",
    "from utils import plot_pianoroll, midi_from_muspy\n",
    "from train import VAETrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set global seed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dir = 'models/'\n",
    "model = 'LMD2'\n",
    "gpu = True\n",
    "device_idx = 3\n",
    "\n",
    "checkpoint = torch.load(os.path.join(models_dir, model, 'checkpoint'), map_location='cpu')\n",
    "state_dict = checkpoint['model_state_dict']\n",
    "params = torch.load(os.path.join(models_dir, model, 'params'), map_location='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(device_idx)\n",
    "\n",
    "device = torch.device(\"cuda\") if gpu else torch.device(\"cpu\")\n",
    "print(\"Device:\", device)\n",
    "print(\"Device idx:\", torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VAE(**params['model'], device=device).to(device)\n",
    "vae.load_state_dict(state_dict)\n",
    "vae.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_music(vae, z, s_cond=None, s_tensor_cond=None):\n",
    "    \n",
    "    # Get structure and content logits\n",
    "    with torch.cuda.amp.autocast():\n",
    "        _, c_logits, s_tensor_out = vae.decoder(z, s_cond)\n",
    "    \n",
    "    s_tensor = s_tensor_cond if s_tensor_cond != None else s_tensor_out\n",
    "    \n",
    "    # Build (n_batches x n_bars x n_tracks x n_timesteps x Sigma x d_token)\n",
    "    # multitrack pianoroll tensor containing logits for each activation and\n",
    "    # hard silences elsewhere\n",
    "    mtp = dense_from_sparse_torch(c_logits, s_tensor)\n",
    "    \n",
    "    # Collapse bars dimension\n",
    "    mtp = mtp.permute(0, 2, 1, 3, 4, 5)\n",
    "    size = (mtp.shape[0], mtp.shape[1], -1, mtp.shape[4], mtp.shape[5])\n",
    "    mtp = mtp.reshape(*size)\n",
    "    \n",
    "    return mtp, s_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "\n",
    "def save(mtp, dir, s_tensor=None, track_data=None, n_loop=1):\n",
    "    \n",
    "    track_data = ([('Drums', -1), ('Bass', 34), ('Guitar', 1), ('Strings', 83)]\n",
    "                  if track_data == None else track_data)\n",
    "    \n",
    "    # Clear matplotlib cache (this avoids formatting problems with first plot)\n",
    "    plt.clf()\n",
    "\n",
    "    # Iterate over the generated n-bar sequences\n",
    "    for i in range(mtp.size(0)):\n",
    "        \n",
    "        # Create the directory if it does not exist\n",
    "        save_dir = os.path.join(dir, str(i))\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "        print(\"Saving midi sequence \" + str(i+1) + \"...\")\n",
    "        \n",
    "        # Generate muspy song from multitrack pianoroll, then midi from muspy\n",
    "        # and save\n",
    "        muspy_song = muspy_from_dense_torch(mtp[i], track_data, \n",
    "                                            params['model']['resolution'])\n",
    "        midi_from_muspy(muspy_song, save_dir, name='music')\n",
    "        \n",
    "        # Plot the pianoroll associated to the sequence\n",
    "        preset = 'full'\n",
    "        with mpl.rc_context({'lines.linewidth': 4, \n",
    "                             'axes.linewidth': 4, 'font.size': 34}):\n",
    "            plot_pianoroll(muspy_song, save_dir, name='pianoroll',\n",
    "                           figsize=(20, 10), fformat='png', preset=preset)\n",
    "        \n",
    "        # Plot structure_tensor if present\n",
    "        if s_tensor != None:\n",
    "            s_curr = s_tensor[i]\n",
    "            s_curr = s_curr.permute(1, 0, 2)\n",
    "            s_curr = s_curr.reshape(s_curr.shape[0], -1)\n",
    "            with mpl.rc_context({'lines.linewidth': 1, \n",
    "                                 'axes.linewidth': 1, 'font.size': 14}):\n",
    "                plot_struct(s_curr.cpu(), name='structure', \n",
    "                            save_dir=save_dir, figsize=(12, 3))\n",
    "\n",
    "        if n_loop > 1:\n",
    "            # Generate extended sequence\n",
    "            print(\"Saving extended (looped) midi sequence \" + str(i+1) + \"...\")\n",
    "            extended = mtp[i].repeat(1, n_loop, 1, 1)\n",
    "            extended = muspy_from_dense_torch(extended, track_data, \n",
    "                                              params['model']['resolution'])\n",
    "            midi_from_muspy(extended, save_dir, name='extended')\n",
    "        \n",
    "        print()\n",
    "\n",
    "    print(\"Finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_z(bs, d_model):\n",
    "    shape = (bs, d_model)\n",
    "\n",
    "    z_norm = torch.normal(\n",
    "        torch.zeros(shape, device=device),\n",
    "        torch.ones(shape, device=device)\n",
    "    )\n",
    "    \n",
    "    return z_norm\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "structure = True\n",
    "structure_file = 'structure2bars.json'\n",
    "\n",
    "n_sequences = 5\n",
    "n_loop = 4\n",
    "d_model = params['model']['d']\n",
    "n_bars = params['model']['n_bars']\n",
    "n_tracks = params['model']['n_tracks']\n",
    "n_timesteps = 4*params['model']['resolution']\n",
    "dir = 'tmpmusic/'\n",
    "\n",
    "bs = n_sequences\n",
    "track_data = [('Drums', -1), ('Bass', 34), ('Guitar', 1), ('Strings', 83)]\n",
    "\n",
    "s, s_tensor = None, None\n",
    "\n",
    "if structure:\n",
    "    \n",
    "    # Load structure tensor from file\n",
    "    with open(structure_file, 'r') as f:\n",
    "        s_tensor = json.load(f)\n",
    "    \n",
    "    s_tensor = torch.tensor(s_tensor)\n",
    "    s_tensor = s_tensor.bool()\n",
    "    s_tensor = s_tensor.unsqueeze(0).repeat(bs, 1, 1, 1)\n",
    "    s = vae.decoder._structure_from_binary(s_tensor)\n",
    "\n",
    "z = generate_z(bs, d_model)\n",
    "mtp, s_tensor = generate_music(vae, z, s, s_tensor)\n",
    "save(mtp, dir, s_tensor, track_data, n_loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "\n",
    "# 1. Create a Tensor\n",
    "tensor = torch.zeros(2, 4, 32)  # Replace with your actual tensor.\n",
    "tensor[:, :, ::8] = 1\n",
    "tensor = tensor.int()\n",
    "# 2. Convert Tensor to List\n",
    "tensor_list = tensor.tolist()\n",
    "\n",
    "# 3. Write to JSON File\n",
    "with open('structure2bars.json', 'w') as f:\n",
    "    json.dump(tensor_list, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import plot_structure\n",
    "\n",
    "s = torch.zeros(2, 4, 32)\n",
    "\n",
    "plot_structure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_track_edges(s_tensor, edge_type_idx=0):\n",
    "\n",
    "    a_t = s_tensor.t()\n",
    "    idxs = torch.stack(torch.where(a_t == 1)).t()\n",
    "\n",
    "    # Create node labels\n",
    "    labels = torch.zeros(s_tensor.size())\n",
    "    s_tensor_idxs = torch.where(s_tensor == 1)\n",
    "    num_nodes = len(s_tensor_idxs[0])\n",
    "    labels[s_tensor_idxs] = torch.arange(num_nodes, dtype=torch.float)\n",
    "    labels = labels.t()\n",
    "\n",
    "    track_edges = []\n",
    "\n",
    "    for track in range(a_t.size(1)):\n",
    "        tr_idxs = list(idxs[idxs[:, 1] == track])\n",
    "        e_idxs = [(tr_idxs[i],\n",
    "                   tr_idxs[i+1]) for i in range(len(tr_idxs)-1)]\n",
    "        edges = [(labels[tuple(e[0])], labels[tuple(e[1])],\n",
    "                  edge_type_idx+track, e[1][0]-e[0][0]) for e in e_idxs]\n",
    "        inv_edges = [(e[1], e[0], *e[2:]) for e in edges]\n",
    "        track_edges.extend(edges)\n",
    "        track_edges.extend(inv_edges)\n",
    "\n",
    "    return torch.tensor(track_edges, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_track_edges(s_tensor, edge_type_idx=0):\n",
    "\n",
    "    a_t = s_tensor.t()\n",
    "    idxs = torch.stack(torch.where(a_t == 1)).t()\n",
    "\n",
    "    # Create node labels\n",
    "    labels = torch.zeros(s_tensor.size())\n",
    "    s_tensor_idxs = torch.where(s_tensor == 1)\n",
    "    num_nodes = len(s_tensor_idxs[0])\n",
    "    labels[s_tensor_idxs] = torch.arange(num_nodes, dtype=torch.float)\n",
    "    labels = labels.t()\n",
    "\n",
    "    track_edges = []\n",
    "\n",
    "    for track in range(a_t.size(1)):\n",
    "        tr_idxs = list(idxs[idxs[:, 1] == track])\n",
    "        e_idxs = [(tr_idxs[i],\n",
    "                   tr_idxs[i+1]) for i in range(len(tr_idxs)-1)]\n",
    "        edges = [(labels[tuple(e[0])], labels[tuple(e[1])],\n",
    "                  edge_type_idx+track, e[1][0]-e[0][0]) for e in e_idxs]\n",
    "        inv_edges = [(e[1], e[0], *e[2:]) for e in edges]\n",
    "        track_edges.extend(edges)\n",
    "        track_edges.extend(inv_edges)\n",
    "\n",
    "    return torch.tensor(track_edges, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a = torch.tensor([[1, 0, 0, 0], [1, 0, 1, 0], [0, 0, 1, 1], [1, 0, 1, 1]])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones_idxs = torch.nonzero(a, as_tuple=True)\n",
    "\n",
    "ones_idxs[1][ones_idxs[0] == 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = ones_idxs[ones_idxs[:, 0] == 3]\n",
    "for i, j in zip(c[:-1], c[1:]):\n",
    "    print(i, j)\n",
    "    print(a[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor([[3, 1], [9, 10]])[torch.tensor([1, 0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "edge_type_idx = 0\n",
    "track_edges = []\n",
    "\n",
    "# Indices where the binary structure tensor is active\n",
    "ones_idxs = torch.nonzero(a, as_tuple=True)\n",
    "\n",
    "# Build a node label tensor which has node labels in place of each activation \n",
    "# in the stucture tensor\n",
    "labels = torch.zeros_like(a)\n",
    "n_nodes = len(ones_idxs[0])\n",
    "labels[ones_idxs] = torch.arange(n_nodes)\n",
    "\n",
    "# For each track, add direct and inverse edges between consecutive nodes\n",
    "for track in range(a.shape[0]):\n",
    "    # List of active timesteps in the current track\n",
    "    ts = list(ones_idxs[1][ones_idxs[0] == track])\n",
    "    edges = [\n",
    "        # Edge tuple: (u, v, type, ts_distance). Zip is used to obtain \n",
    "        # consecutive active timesteps. Edges in different tracks have different\n",
    "        # types.\n",
    "        (labels[track, t1], labels[track, t2], edge_type_idx + track, t2 - t1)\n",
    "        for t1, t2 in zip(ts[:-1], ts[1:])\n",
    "    ]\n",
    "    inverse_edges = [(u, v, t, d) for (v, u, t, d) in edges]\n",
    "    track_edges.extend(edges + inverse_edges)\n",
    "\n",
    "torch.tensor(track_edges, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_tensor = torch.tensor([[0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [1, 0, 0, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "onset_edges = []\n",
    "edge_type = 5\n",
    "\n",
    "# Indices where the binary structure tensor is active\n",
    "ones_idxs = torch.nonzero(s_tensor, as_tuple=True)\n",
    "\n",
    "# Build a node label tensor which has node labels in place of each activation \n",
    "# in the stucture tensor\n",
    "labels = torch.zeros_like(s_tensor)\n",
    "n_nodes = len(ones_idxs[0])\n",
    "labels[ones_idxs] = torch.arange(n_nodes)\n",
    "\n",
    "# Add direct and inverse edges between nodes played in the same timestep\n",
    "for ts in range(s_tensor.shape[1]):\n",
    "    # List of active tracks in the current timestep\n",
    "    tracks = list(ones_idxs[0][ones_idxs[1] == ts])\n",
    "    # Obtain all possible pairwise combinations of active tracks\n",
    "    combinations = list(itertools.combinations(tracks, 2))\n",
    "    edges = [\n",
    "        # Edge tuple: (u, v, type, ts_distance(=0)).\n",
    "        (labels[track1, ts], labels[track2, ts], edge_type, 0)\n",
    "        for track1, track2 in combinations\n",
    "    ]\n",
    "    inverse_edges = [(u, v, t, d) for (v, u, t, d) in edges]\n",
    "    onset_edges.extend(edges + inverse_edges)\n",
    "\n",
    "torch.tensor(onset_edges, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_edges_torch(s_tensor, edge_type_ind=5):\n",
    "\n",
    "    # Indices where the binary structure tensor is active\n",
    "    ones_idxs = torch.nonzero(s_tensor, as_tuple=True)\n",
    "    #print(ones_idxs)\n",
    "    # List of active timesteps\n",
    "    tss = torch.nonzero(torch.any(s_tensor.bool(), dim=0)).squeeze()\n",
    "    print(tss)\n",
    "    #ts_acts = torch.any(a_t, dim=1)\n",
    "    #print(ts_acts)\n",
    "    #ts_inds = torch.where(ts_acts)[0]\n",
    "    #print(ts_inds)\n",
    "    \n",
    "    # Build a node label tensor which has node labels in place of each activation \n",
    "    # in the stucture tensor\n",
    "    labels = torch.zeros_like(s_tensor, dtype=torch.long)\n",
    "    n_nodes = len(ones_idxs[0])\n",
    "    labels[ones_idxs] = torch.arange(n_nodes)\n",
    "\n",
    "    next_edges = []\n",
    "\n",
    "    for i in range(tss.size(0)-1):\n",
    "        # Get consecutive active timesteps\n",
    "        t1, t2 = tss[i], tss[i+1]\n",
    "        # Get all the active tracks in the two timesteps\n",
    "        t1_tracks = ones_idxs[0][ones_idxs[1] == t1]\n",
    "        t2_tracks = ones_idxs[0][ones_idxs[1] == t2]\n",
    "        \n",
    "        # Combine the source and destination tracks, removing combinations with\n",
    "        # the same source and destination track (since these represent track\n",
    "        # edges).\n",
    "        tracks_product = list(itertools.product(t1_tracks, t2_tracks))\n",
    "        tracks_product = [(track1, track2) \n",
    "                          for (track1, track2) in tracks_product \n",
    "                          if track1 != track2]\n",
    "        # Edge tuple: (u, v, type, ts_distance).\n",
    "        edges = [(labels[track1, t1], labels[track2, t2], 7, t2 - t1) \n",
    "                 for track1, track2 in tracks_product]\n",
    "\n",
    "        next_edges.extend(edges)\n",
    "\n",
    "    return torch.tensor(next_edges, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_track_features(s_tensor):\n",
    "    \n",
    "    ones_idxs = torch.nonzero(s_tensor)\n",
    "    n_nodes = len(ones_idxs)\n",
    "    print(ones_idxs)\n",
    "    print(n_nodes)\n",
    "    tracks = ones_idxs[0]\n",
    "    print(tracks)\n",
    "\n",
    "    n_tracks = s_tensor.size(0)\n",
    "    features = torch.zeros((n_nodes, n_tracks))\n",
    "    \n",
    "    features[torch.arange(n_nodes), tracks] = 1\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_tensor = torch.tensor([[1, 0, 0, 0], [1, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 1]])\n",
    "print(s_tensor)\n",
    "get_track_features(s_tensor.bool())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_track_edges(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset len: 2098\n",
      "TR set len: 1468\n",
      "VL set len: 209\n",
      "TS set len: 421\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Subset\n",
    "from torch.utils.data import random_split\n",
    "from torch_geometric.loader import DataLoader\n",
    "from data import PolyphemusDataset\n",
    "\n",
    "bs = 64\n",
    "nw = 10\n",
    "n_bars = 8\n",
    "\n",
    "#bs = 32\n",
    "#nw = 10\n",
    "#n_bars = 16\n",
    "\n",
    "ds_dir = \"data/prova/\"\n",
    "\n",
    "dataset = PolyphemusDataset(ds_dir, n_bars)\n",
    "ds_len = len(dataset)\n",
    "\n",
    "print('Dataset len:', len(dataset))\n",
    "\n",
    "train_len = int(0.7 * len(dataset)) \n",
    "valid_len = int(0.1 * len(dataset))\n",
    "test_len = len(dataset) - train_len - valid_len\n",
    "tr_set, vl_set, ts_set = random_split(dataset, (train_len, valid_len, test_len))\n",
    "\n",
    "trainloader = DataLoader(tr_set, batch_size=bs, shuffle=True, num_workers=nw)\n",
    "validloader = DataLoader(vl_set, batch_size=bs, shuffle=False, num_workers=nw)\n",
    "\n",
    "tr_len = len(tr_set)\n",
    "vl_len = len(vl_set)\n",
    "ts_len = len(ts_set)\n",
    "\n",
    "print('TR set len:', len(tr_set))\n",
    "print('VL set len:', len(vl_set))\n",
    "print('TS set len:', len(ts_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, g in enumerate(trainloader):\n",
    "    print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
