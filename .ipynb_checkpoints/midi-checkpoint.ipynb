{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/EmanueleCosenza/Polyphemus/blob/main/midi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "50lpUn9bO0ug",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/cosenza/thesis/Polyphemus\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraries installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!tar -C data -xvzf data/lmd_matched.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "She0QbN5Kopo",
    "outputId": "0f3fb4c7-bd7d-4ee4-b2cd-d567d8e490db",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Install the required music libraries\n",
    "#!pip3 install muspy\n",
    "#!pip3 install pypianoroll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3uveQkY7O0CF",
    "outputId": "12e1f638-ee78-4617-844a-10e9a26c298e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Install torch_geometric\n",
    "#!v=$(python3 -c \"import torch; print(torch.__version__)\"); \\\n",
    "#pip3 install torch-scatter -f https://data.pyg.org/whl/torch-${v}.html; \\\n",
    "#pip3 install torch-sparse -f https://data.pyg.org/whl/torch-${v}.html; \\\n",
    "#pip3 install torch-geometric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import os\n",
    "\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "seed = 42\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "B45l1513wJ1Q"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import muspy\n",
    "from itertools import product\n",
    "import pypianoroll as pproll\n",
    "import time\n",
    "\n",
    "\n",
    "class MIDIPreprocessor():\n",
    "    \n",
    "    def __init__():\n",
    "        pass\n",
    "\n",
    "    def preprocess_dataset(self, dir, early_exit=None):\n",
    "        pass\n",
    "    \n",
    "    def preprocess_file(self, f):\n",
    "        pass\n",
    "\n",
    "\n",
    "# Todo: to config file (or separate files)\n",
    "MAX_SIMU_NOTES = 16 # 14 + SOS and EOS\n",
    "\n",
    "PITCH_SOS = 128\n",
    "PITCH_EOS = 129\n",
    "PITCH_PAD = 130\n",
    "DUR_PAD_IND = 2\n",
    "MAX_DUR = 511 # equivalent to 16 bars (with RESOLUTION=32)\n",
    "\n",
    "RESOLUTION = 32\n",
    "NUM_BARS = 1\n",
    "\n",
    "\n",
    "def preprocess_file(filepath, dest_dir, num_samples):\n",
    "\n",
    "    saved_samples = 0\n",
    "\n",
    "    print()\n",
    "    print(\"Preprocessing file \" + filepath)\n",
    "\n",
    "    # Load the file both as a pypianoroll song and a muspy song\n",
    "    # (Need to load both since muspy.to_pypianoroll() is expensive)\n",
    "    try:\n",
    "        pproll_song = pproll.read(filepath, resolution=RESOLUTION)\n",
    "        muspy_song = muspy.read(filepath)\n",
    "    except Exception as e:\n",
    "        print(\"Song skipped (Invalid song format)\")\n",
    "        return 0\n",
    "    \n",
    "    # Only accept songs that have a time signature of 4/4 and no time changes\n",
    "    for t in muspy_song.time_signatures:\n",
    "        if t.numerator != 4 or t.denominator != 4:\n",
    "            print(\"Song skipped ({}/{} time signature)\".\n",
    "                            format(t.numerator, t.denominator))\n",
    "            return 0\n",
    "\n",
    "    # Gather tracks of pypianoroll song based on MIDI program number\n",
    "    drum_tracks = []\n",
    "    bass_tracks = []\n",
    "    guitar_tracks = []\n",
    "    strings_tracks = []\n",
    "\n",
    "    for track in pproll_song.tracks:\n",
    "        if track.is_drum:\n",
    "            track.name = 'Drums'\n",
    "            drum_tracks.append(track)\n",
    "        elif 0 <= track.program <= 31:\n",
    "            track.name = 'Guitar'\n",
    "            guitar_tracks.append(track)\n",
    "        elif 32 <= track.program <= 39:\n",
    "            track.name = 'Bass'\n",
    "            bass_tracks.append(track)\n",
    "        else:\n",
    "            # Tracks with program > 39 are all considered as strings tracks\n",
    "            # and will be merged into a single track later on\n",
    "            strings_tracks.append(track)\n",
    "\n",
    "    # Filter song if it does not contain drum, guitar, bass or strings tracks\n",
    "    if not drum_tracks or not guitar_tracks \\\n",
    "       or not bass_tracks or not strings_tracks:\n",
    "        print(\"Song skipped (does not contain drum or \"\n",
    "                \"guitar or bass or strings tracks)\")\n",
    "        return 0\n",
    "    \n",
    "    # Merge strings tracks into a single pypianoroll track\n",
    "    strings = pproll.Multitrack(tracks=strings_tracks)\n",
    "    strings_track = pproll.Track(pianoroll=strings.blend(mode='max'),\n",
    "                                 program=48, name='Strings')\n",
    "\n",
    "    combinations = list(product(drum_tracks, bass_tracks, guitar_tracks))\n",
    "\n",
    "    # Single instruments can have multiple tracks.\n",
    "    # Consider all possible combinations of drum, bass, and guitar tracks\n",
    "    for i, combination in enumerate(combinations):\n",
    "\n",
    "        print(\"Processing combination\", i+1, \"of\", len(combinations))\n",
    "        \n",
    "        # Process combination (called 'subsong' from now on)\n",
    "        drum_track, bass_track, guitar_track = combination\n",
    "        tracks = [drum_track, bass_track, guitar_track, strings_track]\n",
    "        \n",
    "        pproll_subsong = pproll.Multitrack(\n",
    "            tracks=tracks,\n",
    "            tempo=pproll_song.tempo,\n",
    "            resolution=RESOLUTION\n",
    "        )\n",
    "        muspy_subsong = muspy.from_pypianoroll(pproll_subsong)\n",
    "        \n",
    "        tracks_notes = [track.notes for track in muspy_subsong.tracks]\n",
    "        \n",
    "        # Obtain length of subsong (maximum of each track's length)\n",
    "        length = 0\n",
    "        for notes in tracks_notes:\n",
    "            track_length = max(note.end for note in notes)\n",
    "            length = max(length, track_length)\n",
    "        length += 1\n",
    "\n",
    "        # Add timesteps until length is a multiple of RESOLUTION\n",
    "        length = length if length%(RESOLUTION) == 0 \\\n",
    "                                else length + (RESOLUTION-(length%(RESOLUTION)))\n",
    "\n",
    "\n",
    "        tracks_tensors = []\n",
    "        tracks_activations = []\n",
    "\n",
    "        dur_bin_length = int(np.ceil(np.log2(MAX_DUR)))\n",
    "\n",
    "        # Todo: adapt to velocity\n",
    "        for notes in tracks_notes:\n",
    "\n",
    "            # Initialize encoder-ready track tensor\n",
    "            # track_tensor: (length x max_simu_notes x 2 (or 3 if velocity))\n",
    "            # The last dimension contains pitches and durations (and velocities)\n",
    "            # int16 is enough for small to medium duration values\n",
    "            track_tensor = np.zeros((length, MAX_SIMU_NOTES, 2), np.int16)\n",
    "\n",
    "            track_tensor[:, :, 0] = PITCH_PAD\n",
    "            track_tensor[:, 0, 0] = PITCH_SOS\n",
    "\n",
    "            # Keeps track of how many notes have been stored in each timestep\n",
    "            # (int8 imposes that MAX_SIMU_NOTES < 256)\n",
    "            notes_counter = np.ones(length, dtype=np.int8)\n",
    "\n",
    "            # Todo: np.put_along_axis?\n",
    "            for note in notes:\n",
    "                # Insert note in the lowest position available in the timestep\n",
    "                \n",
    "                t = note.time\n",
    "\n",
    "                if notes_counter[t] >= MAX_SIMU_NOTES-1:\n",
    "                    # Skip note if there is no more space\n",
    "                    continue\n",
    "\n",
    "                track_tensor[t, notes_counter[t], 0] = note.pitch\n",
    "                track_tensor[t, notes_counter[t], 1] = note.duration\n",
    "                notes_counter[t] += 1\n",
    "            \n",
    "            # Add end of sequence token\n",
    "            track_tensor[np.arange(0, length), notes_counter, 0] = PITCH_EOS\n",
    "\n",
    "            # Get track activations, a boolean tensor indicating whether notes\n",
    "            # are being played in a timestep (sustain does not count)\n",
    "            # (needed for graph rep.)\n",
    "            activations = np.array(notes_counter-1, dtype=bool)\n",
    "\n",
    "            tracks_tensors.append(track_tensor)\n",
    "            tracks_activations.append(activations)\n",
    "        \n",
    "        # (#tracks x length x max_simu_notes x 2 (or 3))\n",
    "        subsong_tensor = np.stack(tracks_tensors, axis=0)\n",
    "\n",
    "        # (#tracks x length)\n",
    "        subsong_activations = np.stack(tracks_activations, axis=0)\n",
    "\n",
    "\n",
    "        # Slide window over 'subsong_tensor' and 'subsong_activations' along the\n",
    "        # time axis (2nd dimension) with the stride of a bar\n",
    "        # Todo: np.lib.stride_tricks.as_strided(song_proll)\n",
    "        for i in range(0, length-NUM_BARS*RESOLUTION+1, RESOLUTION):\n",
    "            \n",
    "            # Get the sequence and its activations\n",
    "            seq_tensor = subsong_tensor[:, i:i+NUM_BARS*RESOLUTION, :]\n",
    "            seq_acts = subsong_activations[:, i:i+NUM_BARS*RESOLUTION]\n",
    "\n",
    "            # Skip sequence if it contains more than one bar of consecutive\n",
    "            # silence in at least one track\n",
    "            bars = seq_acts.reshape(seq_acts.shape[0], NUM_BARS, -1)\n",
    "            bars_acts = np.any(bars, axis=2)\n",
    "            \n",
    "            if 1 in np.diff(np.where(bars_acts == 0)[1]):\n",
    "                continue\n",
    "\n",
    "            # Randomly transpose the pitches of the sequence (-5 to 6 semitones)\n",
    "            shift = np.random.choice(np.arange(-5, 7), 1)\n",
    "            cond = (seq_tensor[:, :, :, 0] != PITCH_PAD) &                     \\\n",
    "                   (seq_tensor[:, :, :, 0] != PITCH_SOS) &                     \\\n",
    "                   (seq_tensor[:, :, :, 0] != PITCH_EOS)\n",
    "            seq_tensor[cond, 0] += shift\n",
    "\n",
    "            # Save sample (seq_tensor and seq_acts) to file\n",
    "            curr_sample = str(num_samples + saved_samples)\n",
    "            sample_filepath = os.path.join(dest_dir, curr_sample)\n",
    "            np.savez(sample_filepath, seq_tensor=seq_tensor, seq_acts=seq_acts)\n",
    "\n",
    "            saved_samples += 1\n",
    "\n",
    "\n",
    "    print(\"File preprocessing finished. Saved samples:\", saved_samples)\n",
    "    print()\n",
    "\n",
    "    return saved_samples\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Total number of files: 116189\n",
    "# Number of unique files: 45129\n",
    "def preprocess_dataset(dataset_dir, dest_dir, early_exit=None):\n",
    "\n",
    "    files_dict = {}\n",
    "    seen = 0\n",
    "    tot_samples = 0\n",
    "    finished = False\n",
    "\n",
    "    # Visit recursively the directories inside the dataset directory\n",
    "    for dirpath, dirs, files in os.walk(dataset_dir):\n",
    "\n",
    "        # Sort alphabetically the found directories\n",
    "        # (to help guess the remaining time) \n",
    "        dirs.sort()\n",
    "        \n",
    "        print(\"Current path:\", dirpath)\n",
    "\n",
    "        for f in files:\n",
    "            \n",
    "            seen += 1\n",
    "\n",
    "            if f in files_dict:\n",
    "                # Skip already seen file\n",
    "                files_dict[f] += 1\n",
    "                continue\n",
    "\n",
    "            # File never seen before, add to dictionary of files\n",
    "            # (from filename to # of occurrences)\n",
    "            files_dict[f] = 1\n",
    "\n",
    "            # Preprocess file\n",
    "            filepath = os.path.join(dirpath, f)\n",
    "            saved = preprocess_file(filepath, dest_dir, tot_samples)\n",
    "\n",
    "            tot_samples += saved\n",
    "\n",
    "            # Exit when a maximum number of files has been processed (if set)\n",
    "            if early_exit != None and len(files_dict) >= early_exit:\n",
    "                finished = True\n",
    "                break\n",
    "\n",
    "        # Todo: also print # of processed (not filtered) files\n",
    "        #       and # of produced sequences (samples)\n",
    "        print(\"Total number of seen files:\", seen)\n",
    "        print(\"Number of unique files:\", len(files_dict))\n",
    "        print(\"Total number of saved samples:\", tot_samples)\n",
    "        print()\n",
    "\n",
    "        if finished:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "aYc5y-CYyetK"
   },
   "outputs": [],
   "source": [
    "#!rm -rf data/preprocessed/\n",
    "#!mkdir data/preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xqnubg3oP4ES",
    "outputId": "40cc38a2-1f7d-4f6f-e6c9-9e14dfc7f683",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_dir = 'data/lmd_matched'\n",
    "dest_dir = 'data/preprocessed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess_dataset(dataset_dir, dest_dir, early_exit=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RG88mekfrrcp"
   },
   "source": [
    "Check preprocessed data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "JlP6iUNugNtP"
   },
   "outputs": [],
   "source": [
    "filepath = os.path.join(dest_dir, \"5.npz\")\n",
    "data = np.load(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3VUpOEObhwYQ",
    "outputId": "aac6e029-93b1-485f-f13a-2a00abedbc7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 32, 16, 2)\n",
      "(4, 32)\n"
     ]
    }
   ],
   "source": [
    "print(data[\"seq_tensor\"].shape)\n",
    "print(data[\"seq_acts\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A6NA5IAAmtK8",
    "outputId": "6e661b3a-05a1-4e2d-9a3d-e1c037b4d04f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[128,   0],\n",
       "       [129,   0],\n",
       "       [130,   0],\n",
       "       [130,   0],\n",
       "       [130,   0],\n",
       "       [130,   0],\n",
       "       [130,   0],\n",
       "       [130,   0],\n",
       "       [130,   0],\n",
       "       [130,   0],\n",
       "       [130,   0],\n",
       "       [130,   0],\n",
       "       [130,   0],\n",
       "       [130,   0],\n",
       "       [130,   0],\n",
       "       [130,   0]], dtype=int16)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"seq_tensor\"][0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C19X9m-3iMlm"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "zymqD-UqR8wq"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Dataset\n",
    "from torch_geometric.data import Data\n",
    "import itertools\n",
    "\n",
    "\n",
    "def unpackbits(x, num_bits):\n",
    "\n",
    "    if np.issubdtype(x.dtype, np.floating):\n",
    "        raise ValueError(\"numpy data type needs to be int-like\")\n",
    "\n",
    "    xshape = list(x.shape)\n",
    "    x = x.reshape([-1, 1])\n",
    "    mask = 2**np.arange(num_bits, dtype=x.dtype).reshape([1, num_bits])\n",
    "\n",
    "    return (x & mask).astype(bool).astype(int).reshape(xshape + [num_bits])\n",
    "\n",
    "\n",
    "class MIDIDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dir):\n",
    "        self.dir = dir\n",
    "\n",
    "    def __len__(self):\n",
    "        _, _, files = next(os.walk(self.dir))\n",
    "        return len(files)\n",
    "\n",
    "    \n",
    "    def __get_track_edges(self, acts, edge_type_ind=0):\n",
    "\n",
    "        a_t = acts.transpose()\n",
    "        inds = np.stack(np.where(a_t == 1)).transpose()\n",
    "\n",
    "        labels = np.arange(acts.shape[0]*acts.shape[1])\n",
    "        labels = labels.reshape(acts.shape[0], acts.shape[1]).transpose()\n",
    "\n",
    "        track_edges = []\n",
    "\n",
    "        for track in range(a_t.shape[1]):\n",
    "            tr_inds = list(inds[inds[:,1] == track])\n",
    "            e_inds = [(tr_inds[i],\n",
    "                    tr_inds[i+1]) for i in range(len(tr_inds)-1)]\n",
    "            edges = [(labels[tuple(e[0])], labels[tuple(e[1])], edge_type_ind, e[1][0]-e[0][0]) for e in e_inds]\n",
    "            track_edges.extend(edges)\n",
    "\n",
    "        return np.array(track_edges, dtype='long')\n",
    "\n",
    "    \n",
    "    def __get_onset_edges(self, acts, edge_type_ind=1):\n",
    "\n",
    "        a_t = acts.transpose()\n",
    "        inds = np.stack(np.where(a_t == 1)).transpose()\n",
    "        ts_acts = np.any(a_t, axis=1)\n",
    "        ts_inds = np.where(ts_acts)[0]\n",
    "\n",
    "        labels = np.arange(acts.shape[0]*acts.shape[1])\n",
    "        labels = labels.reshape(acts.shape[0], acts.shape[1]).transpose()\n",
    "\n",
    "        onset_edges = []\n",
    "\n",
    "        for i in ts_inds:\n",
    "            ts_acts_inds = list(inds[inds[:,0] == i])\n",
    "            if len(ts_acts_inds) < 2:\n",
    "                continue\n",
    "            e_inds = list(itertools.combinations(ts_acts_inds, 2))\n",
    "            edges = [(labels[tuple(e[0])], labels[tuple(e[1])], edge_type_ind, 0) for e in e_inds]\n",
    "            inv_edges = [(e[1], e[0], *e[2:]) for e in edges]\n",
    "            onset_edges.extend(edges)\n",
    "            onset_edges.extend(inv_edges)\n",
    "\n",
    "        return np.array(onset_edges, dtype='long')\n",
    "\n",
    "\n",
    "    def __get_next_edges(self, acts, edge_type_ind=2):\n",
    "\n",
    "        a_t = acts.transpose()\n",
    "        inds = np.stack(np.where(a_t == 1)).transpose()\n",
    "        ts_acts = np.any(a_t, axis=1)\n",
    "        ts_inds = np.where(ts_acts)[0]\n",
    "\n",
    "        labels = np.arange(acts.shape[0]*acts.shape[1])\n",
    "        labels = labels.reshape(acts.shape[0], acts.shape[1]).transpose()\n",
    "\n",
    "        next_edges = []\n",
    "\n",
    "        for i in range(len(ts_inds)-1):\n",
    "\n",
    "            ind_s = ts_inds[i]\n",
    "            ind_e = ts_inds[i+1]\n",
    "            s = inds[inds[:,0] == ind_s]\n",
    "            e = inds[inds[:,0] == ind_e]\n",
    "\n",
    "            e_inds = [t for t in list(itertools.product(s, e)) if t[0][1] != t[1][1]]\n",
    "            edges = [(labels[tuple(e[0])],labels[tuple(e[1])], edge_type_ind, ind_e-ind_s) for e in e_inds]\n",
    "\n",
    "            next_edges.extend(edges)\n",
    "\n",
    "        return np.array(next_edges, dtype='long')\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        # Load tensors\n",
    "        sample_path = os.path.join(self.dir, str(idx) + \".npz\")\n",
    "        data = np.load(sample_path)\n",
    "\n",
    "        seq_tensor = data[\"seq_tensor\"]\n",
    "        seq_acts = data[\"seq_acts\"]\n",
    "\n",
    "        # From decimals to one-hot (pitch)\n",
    "        pitches = seq_tensor[:, :, :, 0]\n",
    "        onehot = np.zeros((pitches.shape[0]*pitches.shape[1]*pitches.shape[2],\n",
    "                            131), dtype=float)\n",
    "        onehot[np.arange(0, onehot.shape[0]), pitches.reshape(-1)] = 1.\n",
    "        onehot = onehot.reshape(-1, pitches.shape[1], seq_tensor.shape[2], 131)\n",
    "\n",
    "        # From decimals to binary (pitch)\n",
    "        durs = seq_tensor[:, :, :, 1]\n",
    "        bin_durs = unpackbits(durs, 9)[:, :, :, ::-1]\n",
    "\n",
    "        # Concatenate pitches and durations\n",
    "        new_seq_tensor = np.concatenate((onehot[:, :, :, :], bin_durs),\n",
    "                             axis=-1)\n",
    "        \n",
    "        # Construct graph from boolean activations\n",
    "        track_edges = self.__get_track_edges(seq_acts)\n",
    "        onset_edges = self.__get_onset_edges(seq_acts)\n",
    "        next_edges = self.__get_next_edges(seq_acts)\n",
    "        edges = [track_edges, onset_edges, next_edges]\n",
    "\n",
    "        # Concatenate edge tensors (N x 4) (if any)\n",
    "        no_edges = (len(track_edges) == 0 and \n",
    "                    len(onset_edges) == 0 and len(next_edges) == 0)\n",
    "        if not no_edges:\n",
    "            edge_list = np.concatenate([x for x in edges\n",
    "                                          if x.size > 0])\n",
    "            edge_list = torch.from_numpy(edge_list)\n",
    "        \n",
    "        # Adapt tensor to torch_geometric's Data\n",
    "        # Todo: re-check no edges case\n",
    "        edge_index = (torch.LongTensor([[], []]) if no_edges else\n",
    "                               edge_list[:, :2].t().contiguous())\n",
    "        edge_attr = (torch.Tensor([[0, 0]]) if no_edges else\n",
    "                                       edge_list[:, 2:])\n",
    "        \n",
    "        n = seq_acts.shape[0]*seq_acts.shape[1]\n",
    "        graph = Data(edge_index=edge_index, edge_attr=edge_attr, num_nodes=n)\n",
    "        \n",
    "        # Todo: start with torch at mount\n",
    "        return torch.Tensor(new_seq_tensor), torch.Tensor(seq_acts), graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "hSwcnlq4g50O"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch_geometric.nn.conv import GCNConv\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "# Todo: check and think about max_len\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 256):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) *                     \\\n",
    "                             (-math.log(10000.0)/d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position*div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position*div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor, shape [seq_len, batch_size, embedding_dim]\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    \n",
    "    def __init__(self, features_dims=[256, 256, 256], num_relations=3):\n",
    "        super().__init__()\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "        for i in range(len(features_dims)-1):\n",
    "            self.layers.append(GCNConv(features_dims[i], features_dims[i+1]))\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            x = F.dropout(x, training=self.training)\n",
    "            x = layer(x, edge_index)\n",
    "            x = F.relu(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "\n",
    "    # 140 = 128+3+9\n",
    "    def __init__(self, d_token=140, d_transf=256, nhead_transf=4, \n",
    "                 num_layers_transf=2, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        # Todo: one separate encoder for drums\n",
    "        # Transformer Encoder\n",
    "        self.embedding = nn.Linear(d_token, d_transf)\n",
    "        self.pos_encoder = PositionalEncoding(d_transf, dropout)\n",
    "        transf_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_transf,\n",
    "            nhead=nhead_transf\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            transf_layer,\n",
    "            num_layers=num_layers_transf\n",
    "        )\n",
    "\n",
    "        # Graph encoder\n",
    "        self.graph_encoder = GCN()\n",
    "\n",
    "        # (LSTM)\n",
    "        \n",
    "        # Linear layers that compute the final mu and log_var\n",
    "        # Todo: as parameters\n",
    "        self.linear_mu = nn.Linear(256, 256)\n",
    "        self.linear_log_var = nn.Linear(256, 256)\n",
    "\n",
    "    def forward(self, x_seq, x_acts, x_graph):\n",
    "\n",
    "        # Collapse track (and optionally batch) dimension\n",
    "        #print(\"Init input:\", x_seq.size())\n",
    "        x_seq = x_seq.view(-1, x_seq.size(-2), x_seq.size(-1))\n",
    "        #print(\"Reshaped input:\", x_seq.size())\n",
    "\n",
    "        # Compute embeddings\n",
    "        embs = self.embedding(x_seq)\n",
    "        #print(\"Embs:\", embs.size())\n",
    "\n",
    "        # batch_first = False\n",
    "        embs = embs.permute(1, 0, 2)\n",
    "        #print(\"Seq len first input:\", embs.size())\n",
    "\n",
    "        pos_encs = self.pos_encoder(embs)\n",
    "        #print(\"Pos encodings:\", pos_encs.size())\n",
    "\n",
    "        # Todo: src_key_padding_mask = (src != pad).unsqueeze(-2) ?\n",
    "        transformer_encs = self.transformer_encoder(pos_encs)\n",
    "        #print(\"Transf encodings:\", transformer_encs.size())\n",
    "\n",
    "        pooled_encs = torch.mean(transformer_encs, 0)\n",
    "        #print(\"Pooled encodings:\", pooled_encs.size())\n",
    "\n",
    "        # Compute node encodings\n",
    "        x_graph.x = pooled_encs\n",
    "        node_encs = self.graph_encoder(x_graph)\n",
    "        #print(\"Node encodings:\", node_encs.size())\n",
    "        \n",
    "        # Compute final graph latent vector(s)\n",
    "        # (taking into account the batch size)\n",
    "        num_nodes = x_graph[0].num_nodes\n",
    "        batch_sz = node_encs.size(0) // num_nodes\n",
    "        node_encs = node_encs.view(batch_sz, num_nodes, -1)\n",
    "        encoding = torch.mean(node_encs, 1)\n",
    "\n",
    "        # Compute mu and log(std^2)\n",
    "        mu = self.linear_mu(encoding)\n",
    "        log_var = self.linear_log_var(encoding)\n",
    "        \n",
    "        return mu, log_var\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, d_z=256, n_tracks=4, resolution=32, d_token=140, d_model=256,\n",
    "                 d_transf=256, nhead_transf=4, num_layers_transf=2, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        # (LSTM)\n",
    "\n",
    "        # Boolean activations decoder (CNN/MLP)\n",
    "        self.acts_decoder = nn.Linear(d_z, n_tracks*resolution)\n",
    "\n",
    "        # GNN\n",
    "        self.graph_decoder = GCN()\n",
    "        \n",
    "        # Transformer Decoder\n",
    "        self.embedding = nn.Linear(d_token, d_transf)\n",
    "        self.pos_encoder = PositionalEncoding(d_transf,dropout)\n",
    "        decoder_layer = nn.TransformerDecoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead_transf\n",
    "        )\n",
    "        self.transf_decoder = nn.TransformerDecoder(\n",
    "            decoder_layer,\n",
    "            num_layers=num_layers_transf\n",
    "        )\n",
    "        \n",
    "        # Last linear layer\n",
    "        self.lin = nn.Linear(d_model, 140)\n",
    "\n",
    "\n",
    "    def forward(self, z, x_seq, x_acts, x_graph):\n",
    "\n",
    "        # Compute activations from z\n",
    "        acts_out = self.acts_decoder(z)\n",
    "        acts_out = acts_out.view(x_acts.size())\n",
    "        #print(\"Acts out:\", acts_out.size())\n",
    "\n",
    "        # Initialize node features with z and propagate with GNN\n",
    "        node_features = torch.repeat_interleave(\n",
    "                            z, x_acts.size(-1)*x_acts.size(-2), axis=0)\n",
    "        #print(\"Node features:\", node_features.size())\n",
    "\n",
    "        # Todo: use also edge info\n",
    "        x_graph.x = node_features\n",
    "        node_decs = self.graph_decoder(x_graph)\n",
    "        #print(\"Node decodings:\", node_decs.size())\n",
    "        \n",
    "        node_decs = node_decs.repeat(16, 1, 1)\n",
    "        #print(\"Tiled node decodings:\", node_decs.size())\n",
    "\n",
    "        # Decode features with transformer decoder\n",
    "        # forward(tgt, memory, tgt_mask=None, memory_mask=None, tgt_key_padding_mask=None, memory_key_padding_mask=None)\n",
    "        \n",
    "        # Todo: same embeddings as encoder?\n",
    "        seq = x_seq.view(-1, x_seq.size(-2), x_seq.size(-1))\n",
    "        embs = self.embedding(seq)\n",
    "        embs = embs.permute(1, 0, 2)\n",
    "        pos_encs = self.pos_encoder(embs)\n",
    "\n",
    "        seq_out = self.transf_decoder(pos_encs, node_decs)\n",
    "        #print(\"Seq out:\", seq_out.size())\n",
    "        \n",
    "        seq_out = self.lin(seq_out)\n",
    "        #print(\"Seq out after lin:\", seq_out.size())\n",
    "        \n",
    "        # Softmax on first 131 values (pitch), sigmoid on last 9 (dur)\n",
    "        #seq_out[:, :, :131] = F.log_softmax(seq_out[:, :, :131], dim=-1)\n",
    "        #seq_out[:, :, 131:] = torch.sigmoid(seq_out[:, :, 131:])\n",
    "        seq_out = seq_out.permute(1, 0, 2)\n",
    "        seq_out = seq_out.view(x_seq.size())\n",
    "        #print(\"Seq out after reshape\", seq_out.size())\n",
    "        \n",
    "\n",
    "        return seq_out, acts_out\n",
    "\n",
    "\n",
    "class VAE(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder()\n",
    "    \n",
    "    def forward(self, x_seq, x_acts, x_graph):\n",
    "        \n",
    "        mu, log_var = self.encoder(x_seq, x_acts, x_graph)\n",
    "        #print(\"Mu:\", mu.size())\n",
    "        #print(\"log_var:\", log_var.size())\n",
    "        \n",
    "        # Reparameterization trick\n",
    "        sigma = torch.exp(0.5*log_var)\n",
    "        eps = torch.randn_like(sigma)\n",
    "        #print(\"eps:\", eps.size())\n",
    "        z = mu + eps*sigma\n",
    "        \n",
    "        out = self.decoder(z, x_seq, x_acts, x_graph)\n",
    "        \n",
    "        return out, mu, log_var\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import uuid\n",
    "import copy\n",
    "\n",
    "\n",
    "class VAETrainer():\n",
    "    \n",
    "    def __init__(self, models_path, optimizer, init_lr, lr_scheduler=None, \n",
    "                 device=torch.device(\"cpu\"), print_every=1, save_every=1):\n",
    "        self.models_path = models_path\n",
    "        self.optimizer = optimizer\n",
    "        self.init_lr = init_lr\n",
    "        self.lr_scheduler = lr_scheduler\n",
    "        self.device = device\n",
    "        self.print_every = print_every\n",
    "        self.save_every = save_every\n",
    "        \n",
    "    \n",
    "    def train(self, model, trainloader, validloader=None, epochs=1, name=None):\n",
    "        \n",
    "        if name is None:\n",
    "            name = str(uuid.uuid4())\n",
    "        \n",
    "        path = os.path.join(models_path, name)\n",
    "        \n",
    "        n_batches = len(trainloader)\n",
    "                        \n",
    "        losses = []\n",
    "        acts_losses = []\n",
    "        pitches_losses = []\n",
    "        dur_losses = []\n",
    "        kld_losses = []\n",
    "        lrs = []\n",
    "        \n",
    "        ce = nn.CrossEntropyLoss()\n",
    "        bce = nn.BCEWithLogitsLoss()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        beta = 0\n",
    "        \n",
    "        model.train()\n",
    "        \n",
    "        progress_bar = tqdm(range(n_batches))\n",
    "        print(\"Starting training.\\n\")\n",
    "        \n",
    "        start = time.time()\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            \n",
    "            for batch_idx, (x_seq, x_acts, x_graph) in enumerate(trainloader):\n",
    "                \n",
    "                # Zero out the gradients\n",
    "                self.optimizer.zero_grad()\n",
    "                \n",
    "                # Get the inputs\n",
    "                x_seq = x_seq.float().to(self.device)\n",
    "                x_acts = x_acts.to(self.device)\n",
    "                x_graph = x_graph.to(self.device)\n",
    "\n",
    "                # Forward pass, get the reconstructions\n",
    "                out, mu, log_var = model(x_seq, x_acts, x_graph)\n",
    "                seq_rec, acts_rec = out\n",
    "                \n",
    "                # Compute the loss\n",
    "                acts_loss = bce(acts_rec.view(-1), x_acts.view(-1).float())\n",
    "                pitches_loss = ce(seq_rec.reshape(-1, seq_rec.size(-1))[:, :131],\n",
    "                                  x_seq.reshape(-1, x_seq.size(-1))[:, :131].argmax(dim=1))\n",
    "                dur_loss = bce(seq_rec[..., 131:].reshape(-1), \n",
    "                               x_seq[..., 131:].reshape(-1))\n",
    "                kld_loss = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "                rec_loss = pitches_loss + dur_loss + acts_loss\n",
    "                loss = rec_loss + beta*kld_loss\n",
    "                \n",
    "                # Compute gradients and update weights\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                if self.lr_scheduler is not None:\n",
    "                    self.lr_scheduler.step()\n",
    "                \n",
    "                losses.append(loss.item())\n",
    "                acts_losses.append(acts_loss.item())\n",
    "                pitches_losses.append(pitches_loss.item())\n",
    "                dur_losses.append(dur_loss.item())\n",
    "                kld_losses.append((beta*kld_loss).item())\n",
    "                last_lr = (self.lr_scheduler.get_last_lr() if self.lr_scheduler is not None\n",
    "                               else self.init_lr)\n",
    "                lrs.append(last_lr)\n",
    "                \n",
    "                running_loss += loss.item()\n",
    "\n",
    "                # Print training loss information\n",
    "                if (batch_idx + 1) % self.print_every == 0:\n",
    "                    print(\"Training on batch {}/{} of epoch {} complete.\"\n",
    "                          .format(batch_idx+1, n_batches, epoch+1))\n",
    "                    print(\"Tot_loss: {:.4f} acts_loss: {:.4f} \"\n",
    "                          .format(running_loss/self.print_every, acts_loss), end='')\n",
    "                    print(\"pitches_loss: {:.4f} dur_loss: {:.4f} kld_loss: {:.4f}\"\n",
    "                          .format(pitches_loss, dur_loss, kld_loss))\n",
    "                    print(\"----------------------------------------\")\n",
    "                    running_loss = 0.0\n",
    "                    \n",
    "                # When appropriate, save model and stats on disk\n",
    "                if self.save_every > 0 and (batch_idx + 1) % self.save_every == 0:\n",
    "                    print(\"\\nSaving model to disk...\\n\")\n",
    "                    torch.save({\n",
    "                        'epoch': epoch,\n",
    "                        'batch': batch_idx,\n",
    "                        'save_every': self.save_every,\n",
    "                        'lrs': lrs,\n",
    "                        'losses': losses,\n",
    "                        'acts_losses': acts_losses,\n",
    "                        'pitches_losses': pitches_losses,\n",
    "                        'dur_losses': dur_losses,\n",
    "                        'kld_losses': kld_losses,\n",
    "                        'model_state_dict': model.state_dict(),\n",
    "                        'optimizer_state_dict': self.optimizer.state_dict()\n",
    "                    }, path)\n",
    "                    \n",
    "                if batch_idx > 16:\n",
    "                    break\n",
    "            \n",
    "\n",
    "        end = time.time()\n",
    "        hours, rem = divmod(end-start, 3600)\n",
    "        minutes, seconds = divmod(rem, 60)\n",
    "        print(\"Training completed in (h:m:s): {:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))\n",
    "        \n",
    "        print(\"Saving model to disk...\")\n",
    "        \n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'batch': batch_idx,\n",
    "            'save_every': self.save_every,\n",
    "            'lrs': lrs,\n",
    "            'losses': losses,\n",
    "            'acts_losses': acts_losses,\n",
    "            'pitches_losses': pitches_losses,\n",
    "            'dur_losses': dur_losses,\n",
    "            'kld_losses': kld_losses,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict()\n",
    "        }, path)\n",
    "        \n",
    "        print(\"Model saved.\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_path = \"models/\"\n",
    "os.makedirs(models_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5189"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_dir = \"data/preprocessed\"\n",
    "dataset = MIDIDataset(ds_dir)\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Current device idx: 1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.set_device(1)\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "#decive = torch.device(\"cpu\")\n",
    "print(\"Device:\", device)\n",
    "print(\"Current device idx:\", torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!rm models/vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the model and moving it to the specified device...\n",
      "Number of parameters: 6323468\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Starting training.\n",
      "\n",
      "Training on batch 1/163 of epoch 1 complete.\n",
      "Tot_loss: 6.4391 acts_loss: 0.7378 pitches_loss: 4.9810 dur_loss: 0.7203 kld_loss: 661.8564\n",
      "----------------------------------------\n",
      "Training on batch 2/163 of epoch 1 complete.\n",
      "Tot_loss: 6.2803 acts_loss: 0.7325 pitches_loss: 4.8288 dur_loss: 0.7191 kld_loss: 668.2756\n",
      "----------------------------------------\n",
      "Training on batch 3/163 of epoch 1 complete.\n",
      "Tot_loss: 6.1694 acts_loss: 0.7373 pitches_loss: 4.7127 dur_loss: 0.7194 kld_loss: 663.2225\n",
      "----------------------------------------\n",
      "\n",
      "Saving model to disk...\n",
      "\n",
      "Training on batch 4/163 of epoch 1 complete.\n",
      "Tot_loss: 6.0556 acts_loss: 0.7311 pitches_loss: 4.6115 dur_loss: 0.7130 kld_loss: 662.2617\n",
      "----------------------------------------\n",
      "Training on batch 5/163 of epoch 1 complete.\n",
      "Tot_loss: 5.9376 acts_loss: 0.7367 pitches_loss: 4.4926 dur_loss: 0.7084 kld_loss: 664.1050\n",
      "----------------------------------------\n",
      "Training on batch 6/163 of epoch 1 complete.\n",
      "Tot_loss: 5.8339 acts_loss: 0.7359 pitches_loss: 4.3892 dur_loss: 0.7088 kld_loss: 670.5972\n",
      "----------------------------------------\n",
      "\n",
      "Saving model to disk...\n",
      "\n",
      "Training on batch 7/163 of epoch 1 complete.\n",
      "Tot_loss: 5.7121 acts_loss: 0.7327 pitches_loss: 4.2705 dur_loss: 0.7090 kld_loss: 669.6492\n",
      "----------------------------------------\n",
      "Training on batch 8/163 of epoch 1 complete.\n",
      "Tot_loss: 5.5638 acts_loss: 0.7326 pitches_loss: 4.1296 dur_loss: 0.7016 kld_loss: 675.3654\n",
      "----------------------------------------\n",
      "Training on batch 9/163 of epoch 1 complete.\n",
      "Tot_loss: 5.5046 acts_loss: 0.7332 pitches_loss: 4.0670 dur_loss: 0.7045 kld_loss: 678.8574\n",
      "----------------------------------------\n",
      "\n",
      "Saving model to disk...\n",
      "\n",
      "Training on batch 10/163 of epoch 1 complete.\n",
      "Tot_loss: 5.3724 acts_loss: 0.7342 pitches_loss: 3.9437 dur_loss: 0.6945 kld_loss: 678.7370\n",
      "----------------------------------------\n",
      "Training on batch 11/163 of epoch 1 complete.\n",
      "Tot_loss: 5.2583 acts_loss: 0.7371 pitches_loss: 3.8277 dur_loss: 0.6935 kld_loss: 692.3375\n",
      "----------------------------------------\n",
      "Training on batch 12/163 of epoch 1 complete.\n",
      "Tot_loss: 5.1276 acts_loss: 0.7297 pitches_loss: 3.7083 dur_loss: 0.6896 kld_loss: 700.5143\n",
      "----------------------------------------\n",
      "\n",
      "Saving model to disk...\n",
      "\n",
      "Training on batch 13/163 of epoch 1 complete.\n",
      "Tot_loss: 5.0189 acts_loss: 0.7328 pitches_loss: 3.5986 dur_loss: 0.6875 kld_loss: 701.3014\n",
      "----------------------------------------\n",
      "Training on batch 14/163 of epoch 1 complete.\n",
      "Tot_loss: 4.9261 acts_loss: 0.7356 pitches_loss: 3.5046 dur_loss: 0.6859 kld_loss: 713.1521\n",
      "----------------------------------------\n",
      "Training on batch 15/163 of epoch 1 complete.\n",
      "Tot_loss: 4.7906 acts_loss: 0.7353 pitches_loss: 3.3750 dur_loss: 0.6803 kld_loss: 715.7242\n",
      "----------------------------------------\n",
      "\n",
      "Saving model to disk...\n",
      "\n",
      "Training on batch 16/163 of epoch 1 complete.\n",
      "Tot_loss: 4.7203 acts_loss: 0.7278 pitches_loss: 3.3075 dur_loss: 0.6850 kld_loss: 716.7161\n",
      "----------------------------------------\n",
      "Training on batch 17/163 of epoch 1 complete.\n",
      "Tot_loss: 4.6021 acts_loss: 0.7327 pitches_loss: 3.1904 dur_loss: 0.6790 kld_loss: 738.5530\n",
      "----------------------------------------\n",
      "Training on batch 18/163 of epoch 1 complete.\n",
      "Tot_loss: 4.5205 acts_loss: 0.7336 pitches_loss: 3.1098 dur_loss: 0.6772 kld_loss: 748.3977\n",
      "----------------------------------------\n",
      "\n",
      "Saving model to disk...\n",
      "\n",
      "Training finished\n",
      "\n",
      "Saving model to disk...\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating the model and moving it to the specified device...\")\n",
    "\n",
    "vae = VAE().to(device)\n",
    "\n",
    "print(\"Number of parameters:\", sum(p.numel() for p in vae.parameters()))\n",
    "print()\n",
    "\n",
    "init_lr = 1e-5\n",
    "gamma = 0.999\n",
    "optimizer = optim.Adam(vae.parameters(), lr=init_lr)\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma)\n",
    "\n",
    "print('--------------------------------------------------\\n')\n",
    "\n",
    "trainer = VAETrainer(models_path, optimizer, init_lr, save_every=3, device=device)\n",
    "trainer.train(vae, loader, name='vae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.load('models/vae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7ff2717c1150>"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 248,
       "width": 362
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1, len(m['losses'])+1), m['losses'], label='Loss')\n",
    "plt.plot(range(1, len(m['acts_losses'])+1), m['acts_losses'], label='acts')\n",
    "plt.plot(range(1, len(m['pitches_losses'])+1), m['pitches_losses'], label='pitches')\n",
    "plt.plot(range(1, len(m['dur_losses'])+1), m['dur_losses'], label='dur')\n",
    "plt.plot(range(1, len(m['kld_losses'])+1), m['kld_losses'], label='kld')\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KTFN-DCJjZWM"
   },
   "source": [
    "# Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4sSvVK7CxjV8"
   },
   "outputs": [],
   "source": [
    "from typing import Optional, Union, Tuple\n",
    "from torch_geometric.typing import OptTensor, Adj\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Parameter as Param\n",
    "from torch.nn import Parameter\n",
    "from torch_scatter import scatter\n",
    "from torch_sparse import SparseTensor, matmul, masked_select_nnz\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "\n",
    "from torch_geometric.nn.inits import glorot, zeros\n",
    "\n",
    "\n",
    "@torch.jit._overload\n",
    "def masked_edge_index(edge_index, edge_mask):\n",
    "    # type: (Tensor, Tensor) -> Tensor\n",
    "    pass\n",
    "\n",
    "\n",
    "@torch.jit._overload\n",
    "def masked_edge_index(edge_index, edge_mask):\n",
    "    # type: (SparseTensor, Tensor) -> SparseTensor\n",
    "    pass\n",
    "\n",
    "\n",
    "def masked_edge_index(edge_index, edge_mask):\n",
    "    if isinstance(edge_index, Tensor):\n",
    "        return edge_index[:, edge_mask]\n",
    "    else:\n",
    "        return masked_select_nnz(edge_index, edge_mask, layout='coo')\n",
    "\n",
    "\n",
    "class RGCNConv(MessagePassing):\n",
    "    r\"\"\"The relational graph convolutional operator from the `\"Modeling\n",
    "    Relational Data with Graph Convolutional Networks\"\n",
    "    <https://arxiv.org/abs/1703.06103>`_ paper\n",
    "\n",
    "    .. math::\n",
    "        \\mathbf{x}^{\\prime}_i = \\mathbf{\\Theta}_{\\textrm{root}} \\cdot\n",
    "        \\mathbf{x}_i + \\sum_{r \\in \\mathcal{R}} \\sum_{j \\in \\mathcal{N}_r(i)}\n",
    "        \\frac{1}{|\\mathcal{N}_r(i)|} \\mathbf{\\Theta}_r \\cdot \\mathbf{x}_j,\n",
    "\n",
    "    where :math:`\\mathcal{R}` denotes the set of relations, *i.e.* edge types.\n",
    "    Edge type needs to be a one-dimensional :obj:`torch.long` tensor which\n",
    "    stores a relation identifier\n",
    "    :math:`\\in \\{ 0, \\ldots, |\\mathcal{R}| - 1\\}` for each edge.\n",
    "\n",
    "    .. note::\n",
    "        This implementation is as memory-efficient as possible by iterating\n",
    "        over each individual relation type.\n",
    "        Therefore, it may result in low GPU utilization in case the graph has a\n",
    "        large number of relations.\n",
    "        As an alternative approach, :class:`FastRGCNConv` does not iterate over\n",
    "        each individual type, but may consume a large amount of memory to\n",
    "        compensate.\n",
    "        We advise to check out both implementations to see which one fits your\n",
    "        needs.\n",
    "\n",
    "    Args:\n",
    "        in_channels (int or tuple): Size of each input sample. A tuple\n",
    "            corresponds to the sizes of source and target dimensionalities.\n",
    "            In case no input features are given, this argument should\n",
    "            correspond to the number of nodes in your graph.\n",
    "        out_channels (int): Size of each output sample.\n",
    "        num_relations (int): Number of relations.\n",
    "        num_bases (int, optional): If set to not :obj:`None`, this layer will\n",
    "            use the basis-decomposition regularization scheme where\n",
    "            :obj:`num_bases` denotes the number of bases to use.\n",
    "            (default: :obj:`None`)\n",
    "        num_blocks (int, optional): If set to not :obj:`None`, this layer will\n",
    "            use the block-diagonal-decomposition regularization scheme where\n",
    "            :obj:`num_blocks` denotes the number of blocks to use.\n",
    "            (default: :obj:`None`)\n",
    "        aggr (string, optional): The aggregation scheme to use\n",
    "            (:obj:`\"add\"`, :obj:`\"mean\"`, :obj:`\"max\"`).\n",
    "            (default: :obj:`\"mean\"`)\n",
    "        root_weight (bool, optional): If set to :obj:`False`, the layer will\n",
    "            not add transformed root node features to the output.\n",
    "            (default: :obj:`True`)\n",
    "        bias (bool, optional): If set to :obj:`False`, the layer will not learn\n",
    "            an additive bias. (default: :obj:`True`)\n",
    "        **kwargs (optional): Additional arguments of\n",
    "            :class:`torch_geometric.nn.conv.MessagePassing`.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: Union[int, Tuple[int, int]],\n",
    "        out_channels: int,\n",
    "        num_relations: int,\n",
    "        num_bases: Optional[int] = None,\n",
    "        num_blocks: Optional[int] = None,\n",
    "        aggr: str = 'mean',\n",
    "        root_weight: bool = True,\n",
    "        bias: bool = True,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(aggr=aggr, node_dim=0, **kwargs)\n",
    "\n",
    "        if num_bases is not None and num_blocks is not None:\n",
    "            raise ValueError('Can not apply both basis-decomposition and '\n",
    "                             'block-diagonal-decomposition at the same time.')\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.num_relations = num_relations\n",
    "        self.num_bases = num_bases\n",
    "        self.num_blocks = num_blocks\n",
    "\n",
    "        if isinstance(in_channels, int):\n",
    "            in_channels = (in_channels, in_channels)\n",
    "        self.in_channels_l = in_channels[0]\n",
    "\n",
    "        if num_bases is not None:\n",
    "            self.weight = Parameter(\n",
    "                torch.Tensor(num_bases, in_channels[0], out_channels))\n",
    "            self.comp = Parameter(torch.Tensor(num_relations, num_bases))\n",
    "\n",
    "        elif num_blocks is not None:\n",
    "            assert (in_channels[0] % num_blocks == 0\n",
    "                    and out_channels % num_blocks == 0)\n",
    "            self.weight = Parameter(\n",
    "                torch.Tensor(num_relations, num_blocks,\n",
    "                             in_channels[0] // num_blocks,\n",
    "                             out_channels // num_blocks))\n",
    "            self.register_parameter('comp', None)\n",
    "\n",
    "        else:\n",
    "            self.weight = Parameter(\n",
    "                torch.Tensor(num_relations, in_channels[0], out_channels))\n",
    "            self.register_parameter('comp', None)\n",
    "\n",
    "        if root_weight:\n",
    "            self.root = Param(torch.Tensor(in_channels[1], out_channels))\n",
    "        else:\n",
    "            self.register_parameter('root', None)\n",
    "\n",
    "        if bias:\n",
    "            self.bias = Param(torch.Tensor(out_channels))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        glorot(self.weight)\n",
    "        glorot(self.comp)\n",
    "        glorot(self.root)\n",
    "        zeros(self.bias)\n",
    "\n",
    "\n",
    "    def forward(self, x: Union[OptTensor, Tuple[OptTensor, Tensor]],\n",
    "                edge_index: Adj, edge_type: OptTensor = None):\n",
    "        r\"\"\"\n",
    "        Args:\n",
    "            x: The input node features. Can be either a :obj:`[num_nodes,\n",
    "                in_channels]` node feature matrix, or an optional\n",
    "                one-dimensional node index tensor (in which case input features\n",
    "                are treated as trainable node embeddings).\n",
    "                Furthermore, :obj:`x` can be of type :obj:`tuple` denoting\n",
    "                source and destination node features.\n",
    "            edge_type: The one-dimensional relation type/index for each edge in\n",
    "                :obj:`edge_index`.\n",
    "                Should be only :obj:`None` in case :obj:`edge_index` is of type\n",
    "                :class:`torch_sparse.tensor.SparseTensor`.\n",
    "                (default: :obj:`None`)\n",
    "        \"\"\"\n",
    "\n",
    "        # Convert input features to a pair of node features or node indices.\n",
    "        x_l: OptTensor = None\n",
    "        if isinstance(x, tuple):\n",
    "            x_l = x[0]\n",
    "        else:\n",
    "            x_l = x\n",
    "        if x_l is None:\n",
    "            x_l = torch.arange(self.in_channels_l, device=self.weight.device)\n",
    "\n",
    "        x_r: Tensor = x_l\n",
    "        if isinstance(x, tuple):\n",
    "            x_r = x[1]\n",
    "\n",
    "        size = (x_l.size(0), x_r.size(0))\n",
    "\n",
    "        if isinstance(edge_index, SparseTensor):\n",
    "            edge_type = edge_index.storage.value()\n",
    "        assert edge_type is not None\n",
    "\n",
    "        # propagate_type: (x: Tensor)\n",
    "        out = torch.zeros(x_r.size(0), self.out_channels, device=x_r.device)\n",
    "\n",
    "        weight = self.weight\n",
    "        if self.num_bases is not None:  # Basis-decomposition =================\n",
    "            weight = (self.comp @ weight.view(self.num_bases, -1)).view(\n",
    "                self.num_relations, self.in_channels_l, self.out_channels)\n",
    "\n",
    "        if self.num_blocks is not None:  # Block-diagonal-decomposition =====\n",
    "\n",
    "            if x_l.dtype == torch.long and self.num_blocks is not None:\n",
    "                raise ValueError('Block-diagonal decomposition not supported '\n",
    "                                 'for non-continuous input features.')\n",
    "\n",
    "            for i in range(self.num_relations):\n",
    "                tmp = masked_edge_index(edge_index, edge_type == i)\n",
    "                h = self.propagate(tmp, x=x_l, size=size)\n",
    "                h = h.view(-1, weight.size(1), weight.size(2))\n",
    "                h = torch.einsum('abc,bcd->abd', h, weight[i])\n",
    "                out += h.contiguous().view(-1, self.out_channels)\n",
    "\n",
    "        else:  # No regularization/Basis-decomposition ========================\n",
    "            for i in range(self.num_relations):\n",
    "                tmp = masked_edge_index(edge_index, edge_type == i)\n",
    "\n",
    "                if x_l.dtype == torch.long:\n",
    "                    out += self.propagate(tmp, x=weight[i, x_l], size=size)\n",
    "                else:\n",
    "                    h = self.propagate(tmp, x=x_l, size=size)\n",
    "                    out = out + (h @ weight[i])\n",
    "\n",
    "        root = self.root\n",
    "        if root is not None:\n",
    "            out += root[x_r] if x_r.dtype == torch.long else x_r @ root\n",
    "\n",
    "        if self.bias is not None:\n",
    "            out += self.bias\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "    def message(self, x_j: Tensor) -> Tensor:\n",
    "        return x_j\n",
    "\n",
    "    def message_and_aggregate(self, adj_t: SparseTensor, x: Tensor) -> Tensor:\n",
    "        adj_t = adj_t.set_value(None, layout=None)\n",
    "        return matmul(adj_t, x, reduce=self.aggr)\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return (f'{self.__class__.__name__}({self.in_channels}, '\n",
    "                f'{self.out_channels}, num_relations={self.num_relations})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hfsNpMLrEXLk"
   },
   "source": [
    "next edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2DaVTonr_XB8",
    "outputId": "9e5fa8f9-604e-4273-a34d-fad73ad9ab7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 1 1]\n",
      " [1 1 1 1]\n",
      " [1 1 0 0]\n",
      " [1 1 1 1]\n",
      " [0 1 0 1]\n",
      " [1 0 0 0]\n",
      " [1 1 1 0]\n",
      " [0 0 0 0]]\n",
      "[[ 0  8 16 24]\n",
      " [ 1  9 17 25]\n",
      " [ 2 10 18 26]\n",
      " [ 3 11 19 27]\n",
      " [ 4 12 20 28]\n",
      " [ 5 13 21 29]\n",
      " [ 6 14 22 30]\n",
      " [ 7 15 23 31]]\n",
      "[(8, 1, 1), (8, 17, 1), (8, 25, 1), (16, 1, 1), (16, 9, 1), (16, 25, 1), (24, 1, 1), (24, 9, 1), (24, 17, 1), (1, 10, 1), (9, 2, 1), (17, 2, 1), (17, 10, 1), (25, 2, 1), (25, 10, 1), (2, 11, 1), (2, 19, 1), (2, 27, 1), (10, 3, 1), (10, 19, 1), (10, 27, 1), (3, 12, 1), (3, 28, 1), (11, 28, 1), (19, 12, 1), (19, 28, 1), (27, 12, 1), (12, 5, 1), (28, 5, 1), (5, 14, 1), (5, 22, 1)]\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "a = np.random.randint(2, size=(4,8))\n",
    "a_t = a.transpose()\n",
    "print(a_t)\n",
    "inds = np.stack(np.where(a_t == 1)).transpose()\n",
    "ts_acts = np.any(a_t, axis=1)\n",
    "ts_inds = np.where(ts_acts)[0]\n",
    "\n",
    "labels = np.arange(32).reshape(4, 8).transpose()\n",
    "print(labels)\n",
    "\n",
    "next_edges = []\n",
    "for i in range(len(ts_inds)-1):\n",
    "    ind_s = ts_inds[i]\n",
    "    ind_e = ts_inds[i+1]\n",
    "    s = inds[inds[:,0] == ind_s]\n",
    "    e = inds[inds[:,0] == ind_e]\n",
    "    e_inds = [t for t in list(itertools.product(s, e)) if t[0][1] != t[1][1]]\n",
    "    edges = [(labels[tuple(e[0])],labels[tuple(e[1])], ind_e-ind_s) for e in e_inds]\n",
    "    next_edges.extend(edges)\n",
    "\n",
    "print(next_edges)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lJ5JQm1aEbmb"
   },
   "source": [
    "onset edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DISmsJB3EatR",
    "outputId": "fc864608-63a6-4ad0-84d9-1478001ce60e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 1 1]\n",
      " [1 1 1 1]\n",
      " [1 1 0 0]\n",
      " [1 1 1 1]\n",
      " [0 1 0 1]\n",
      " [1 0 0 0]\n",
      " [1 1 1 0]\n",
      " [0 0 0 0]]\n",
      "[[ 0  8 16 24]\n",
      " [ 1  9 17 25]\n",
      " [ 2 10 18 26]\n",
      " [ 3 11 19 27]\n",
      " [ 4 12 20 28]\n",
      " [ 5 13 21 29]\n",
      " [ 6 14 22 30]\n",
      " [ 7 15 23 31]]\n",
      "[(8, 16, 0), (8, 24, 0), (16, 24, 0), (16, 8, 0), (24, 8, 0), (24, 16, 0), (1, 9, 0), (1, 17, 0), (1, 25, 0), (9, 17, 0), (9, 25, 0), (17, 25, 0), (9, 1, 0), (17, 1, 0), (25, 1, 0), (17, 9, 0), (25, 9, 0), (25, 17, 0), (2, 10, 0), (10, 2, 0), (3, 11, 0), (3, 19, 0), (3, 27, 0), (11, 19, 0), (11, 27, 0), (19, 27, 0), (11, 3, 0), (19, 3, 0), (27, 3, 0), (19, 11, 0), (27, 11, 0), (27, 19, 0), (12, 28, 0), (28, 12, 0), (6, 14, 0), (6, 22, 0), (14, 22, 0), (14, 6, 0), (22, 6, 0), (22, 14, 0)]\n"
     ]
    }
   ],
   "source": [
    "onset_edges = []\n",
    "print(a_t)\n",
    "print(labels)\n",
    "\n",
    "for i in ts_inds:\n",
    "    ts_acts_inds = list(inds[inds[:,0] == i])\n",
    "    if len(ts_acts_inds) < 2:\n",
    "        continue\n",
    "    e_inds = list(itertools.combinations(ts_acts_inds, 2))\n",
    "    edges = [(labels[tuple(e[0])], labels[tuple(e[1])], 0) for e in e_inds]\n",
    "    inv_edges = [(e[1], e[0], *e[2:]) for e in edges]\n",
    "    onset_edges.extend(edges)\n",
    "    onset_edges.extend(inv_edges)\n",
    "\n",
    "print(onset_edges)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ujitZCKaa7nu"
   },
   "source": [
    "track edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NbVG1vdFa-7e",
    "outputId": "c042449b-eef2-4707-a524-5f66f3ec07c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 1]\n",
      " [1 0 0 1]\n",
      " [0 1 0 0]\n",
      " [0 0 0 0]\n",
      " [1 1 0 0]\n",
      " [0 0 1 1]\n",
      " [0 0 1 0]\n",
      " [0 0 1 1]]\n",
      "[[ 0  8 16 24]\n",
      " [ 1  9 17 25]\n",
      " [ 2 10 18 26]\n",
      " [ 3 11 19 27]\n",
      " [ 4 12 20 28]\n",
      " [ 5 13 21 29]\n",
      " [ 6 14 22 30]\n",
      " [ 7 15 23 31]]\n",
      "[(array([0, 0]), array([1, 0])), (array([1, 0]), array([4, 0]))]\n",
      "[(array([0, 1]), array([2, 1])), (array([2, 1]), array([4, 1]))]\n",
      "[(array([0, 2]), array([5, 2])), (array([5, 2]), array([6, 2])), (array([6, 2]), array([7, 2]))]\n",
      "[(array([0, 3]), array([1, 3])), (array([1, 3]), array([5, 3])), (array([5, 3]), array([7, 3]))]\n",
      "[(0, 1, 1), (1, 4, 3), (8, 10, 2), (10, 12, 2), (16, 21, 5), (21, 22, 1), (22, 23, 1), (24, 25, 1), (25, 29, 4), (29, 31, 2)]\n"
     ]
    }
   ],
   "source": [
    "print(a_t)\n",
    "print(labels)\n",
    "track_edges = []\n",
    "\n",
    "for track in range(a_t.shape[1]):\n",
    "    tr_inds = list(inds[inds[:,1] == track])\n",
    "    e_inds = [(tr_inds[i],\n",
    "               tr_inds[i+1]) for i in range(len(tr_inds)-1)]\n",
    "    print(e_inds)\n",
    "    edges = [(labels[tuple(e[0])], labels[tuple(e[1])], e[1][0]-e[0][0]) for e in e_inds]\n",
    "    track_edges.extend(edges)\n",
    "\n",
    "print(track_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8DzouJ5NqALB",
    "outputId": "20a76e82-6305-4154-d894-6d69a64435a1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 3)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "track_edges = np.array(track_edges)\n",
    "onset_edges = np.array(onset_edges)\n",
    "np.concatenate((track_edges, onset_edges)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ihIYkPWPzyGX"
   },
   "outputs": [],
   "source": [
    "pip install pypianoroll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ie0pU8NWAUNM"
   },
   "outputs": [],
   "source": [
    "import pypianoroll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QTbGBSrdAZGH"
   },
   "outputs": [],
   "source": [
    "multitrack = pypianoroll.read(\"tests_fur-elise.mid\")\n",
    "print(multitrack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3eVo_BKzAmz4"
   },
   "outputs": [],
   "source": [
    "multitrack.tracks[0].pianoroll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PPpWw-rLA7CI"
   },
   "outputs": [],
   "source": [
    "multitrack.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x-PYbS7FA-Gg"
   },
   "outputs": [],
   "source": [
    "multitrack.trim(0, 12 * multitrack.resolution)\n",
    "multitrack.binarize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "psxuoTsZBFXY"
   },
   "outputs": [],
   "source": [
    "multitrack.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ovyixmSvBG3w"
   },
   "outputs": [],
   "source": [
    "multitrack.tracks[0].pianoroll.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wHlKNufuBzLn"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOhjCOJb34P4bTid7qFDg58",
   "collapsed_sections": [],
   "include_colab_link": true,
   "mount_file_id": "1NeVldMsPVJd6pXbxZDmuiUP-QJBRhYtj",
   "name": "midi.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
