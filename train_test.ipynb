{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 256\n",
    "nw = 10\n",
    "n_bars = 2\n",
    "device_idx = 3\n",
    "ds_dir = \"data/prova/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset len: 5149\n",
      "TR set len: 3604\n",
      "VL set len: 514\n",
      "TS set len: 1031\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Subset\n",
    "from torch.utils.data import random_split\n",
    "from torch_geometric.loader import DataLoader\n",
    "from data import PolyphemusDataset\n",
    "import torch\n",
    "\n",
    "\n",
    "dataset = PolyphemusDataset(ds_dir, n_bars)\n",
    "ds_len = len(dataset)\n",
    "\n",
    "print('Dataset len:', len(dataset))\n",
    "\n",
    "train_len = int(0.7 * len(dataset)) \n",
    "valid_len = int(0.1 * len(dataset))\n",
    "test_len = len(dataset) - train_len - valid_len\n",
    "tr_set, vl_set, ts_set = random_split(dataset, (train_len, valid_len, test_len))\n",
    "\n",
    "trainloader = DataLoader(tr_set, batch_size=bs, shuffle=True, num_workers=nw)\n",
    "validloader = DataLoader(vl_set, batch_size=bs, shuffle=False, num_workers=nw)\n",
    "\n",
    "tr_len = len(tr_set)\n",
    "vl_len = len(vl_set)\n",
    "ts_len = len(ts_set)\n",
    "\n",
    "print('TR set len:', len(tr_set))\n",
    "print('VL set len:', len(vl_set))\n",
    "print('TS set len:', len(ts_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Current device idx: 0\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.set_device(0)\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "#device = torch.device(\"cpu\")\n",
    "print(\"Device:\", device)\n",
    "print(\"Current device idx:\", torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch.optim import Optimizer\n",
    "\n",
    "\n",
    "class ExpDecayLRScheduler():\n",
    "    def __init__(\n",
    "        self,\n",
    "        optimizer: Optimizer,\n",
    "        peak_lr: float,\n",
    "        warmup_steps: int,\n",
    "        final_lr_scale: float,\n",
    "        decay_steps: int\n",
    "    ):\n",
    "\n",
    "        self.optimizer = optimizer\n",
    "        self.peak_lr = peak_lr\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.decay_steps = decay_steps\n",
    "\n",
    "        # Find the decay factor that is needed to reach the learning rate scale\n",
    "        # after decay_steps steps\n",
    "        self.decay_factor = -math.log(final_lr_scale) / self.decay_steps\n",
    "\n",
    "        self.update_steps = 0\n",
    "\n",
    "    def set_lr(self, optimizer, lr):\n",
    "        for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "                \n",
    "    \n",
    "    def step(self):\n",
    "        self.update_steps += 1\n",
    "        \n",
    "        if self.update_steps <= self.warmup_steps:\n",
    "            self.lr = self.peak_lr\n",
    "        else:\n",
    "            steps_after_warmup = self.update_steps - self. warmup_steps\n",
    "            self.lr = \\\n",
    "                self.peak_lr * math.exp(-self.decay_factor*steps_after_warmup)\n",
    "\n",
    "        self.set_lr(self.optimizer, self.lr)\n",
    "\n",
    "        return self.lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'training': {\n",
    "        'batch_size': bs,\n",
    "        'num_workers': nw,\n",
    "        'ds_len': ds_len,\n",
    "        'tr_len': tr_len,\n",
    "        'vl_len': vl_len,\n",
    "        'ts_len': ts_len,\n",
    "    },\n",
    "    'model': {\n",
    "        'dropout': 0,\n",
    "        'batch_norm': True,\n",
    "        'gnn_n_layers': 8,\n",
    "        'actsnn_n_layers': 2,\n",
    "        'd': 512,\n",
    "        'd_token': 230,\n",
    "        'd_token_pitches': 131,\n",
    "        'd_token_dur': 99,\n",
    "        'n_bars': n_bars,\n",
    "        'n_relations': 6,\n",
    "        'n_tracks': 4,\n",
    "        'resolution': 8,\n",
    "        'max_simu_notes': 16\n",
    "    },\n",
    "    'scheduler': {\n",
    "        'peak_lr': 1e-4,\n",
    "        'final_lr_scale': 0.01,\n",
    "        'warmup_steps': 8000,\n",
    "        'decay_steps': 800000\n",
    "    },\n",
    "    'optimizer': {\n",
    "        'betas': (0.9, 0.98),\n",
    "        'eps': 1e-09,\n",
    "        'lr': 5e-6\n",
    "    },\n",
    "    'beta_annealing': {\n",
    "        'beta_update': True,\n",
    "        'anneal_start': 40000,\n",
    "        'beta_max': 0.01,\n",
    "        'step_size': 0.001,\n",
    "        'anneal_end': 500000\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the model and moving it to the specified device...\n",
      "+-------------------------------------------------------------+------------+\n",
      "|                           Modules                           | Parameters |\n",
      "+-------------------------------------------------------------+------------+\n",
      "|                encoder.notes_pitch_emb.weight               |   33536    |\n",
      "|                 encoder.notes_pitch_emb.bias                |    256     |\n",
      "|                encoder.drums_pitch_emb.weight               |   33536    |\n",
      "|                 encoder.drums_pitch_emb.bias                |    256     |\n",
      "|                    encoder.dur_emb.weight                   |   25344    |\n",
      "|                     encoder.dur_emb.bias                    |    256     |\n",
      "|                    encoder.bn_npe.weight                    |    256     |\n",
      "|                     encoder.bn_npe.bias                     |    256     |\n",
      "|                    encoder.bn_dpe.weight                    |    256     |\n",
      "|                     encoder.bn_dpe.bias                     |    256     |\n",
      "|                     encoder.bn_de.weight                    |    256     |\n",
      "|                      encoder.bn_de.bias                     |    256     |\n",
      "|                 encoder.chord_encoder.weight                |  3932160   |\n",
      "|                  encoder.chord_encoder.bias                 |    512     |\n",
      "|            encoder.graph_encoder.layers.0.weight            |  1572864   |\n",
      "|             encoder.graph_encoder.layers.0.root             |   262144   |\n",
      "|             encoder.graph_encoder.layers.0.bias             |    512     |\n",
      "|           encoder.graph_encoder.layers.0.nn.weight          |   16384    |\n",
      "|            encoder.graph_encoder.layers.0.nn.bias           |    512     |\n",
      "|            encoder.graph_encoder.layers.1.weight            |  1572864   |\n",
      "|             encoder.graph_encoder.layers.1.root             |   262144   |\n",
      "|             encoder.graph_encoder.layers.1.bias             |    512     |\n",
      "|            encoder.graph_encoder.layers.2.weight            |  1572864   |\n",
      "|             encoder.graph_encoder.layers.2.root             |   262144   |\n",
      "|             encoder.graph_encoder.layers.2.bias             |    512     |\n",
      "|            encoder.graph_encoder.layers.3.weight            |  1572864   |\n",
      "|             encoder.graph_encoder.layers.3.root             |   262144   |\n",
      "|             encoder.graph_encoder.layers.3.bias             |    512     |\n",
      "|            encoder.graph_encoder.layers.4.weight            |  1572864   |\n",
      "|             encoder.graph_encoder.layers.4.root             |   262144   |\n",
      "|             encoder.graph_encoder.layers.4.bias             |    512     |\n",
      "|            encoder.graph_encoder.layers.5.weight            |  1572864   |\n",
      "|             encoder.graph_encoder.layers.5.root             |   262144   |\n",
      "|             encoder.graph_encoder.layers.5.bias             |    512     |\n",
      "|            encoder.graph_encoder.layers.6.weight            |  1572864   |\n",
      "|             encoder.graph_encoder.layers.6.root             |   262144   |\n",
      "|             encoder.graph_encoder.layers.6.bias             |    512     |\n",
      "|            encoder.graph_encoder.layers.7.weight            |  1572864   |\n",
      "|             encoder.graph_encoder.layers.7.root             |   262144   |\n",
      "|             encoder.graph_encoder.layers.7.bias             |    512     |\n",
      "|      encoder.graph_encoder.norm_layers.0.module.weight      |    512     |\n",
      "|       encoder.graph_encoder.norm_layers.0.module.bias       |    512     |\n",
      "|      encoder.graph_encoder.norm_layers.1.module.weight      |    512     |\n",
      "|       encoder.graph_encoder.norm_layers.1.module.bias       |    512     |\n",
      "|      encoder.graph_encoder.norm_layers.2.module.weight      |    512     |\n",
      "|       encoder.graph_encoder.norm_layers.2.module.bias       |    512     |\n",
      "|      encoder.graph_encoder.norm_layers.3.module.weight      |    512     |\n",
      "|       encoder.graph_encoder.norm_layers.3.module.bias       |    512     |\n",
      "|      encoder.graph_encoder.norm_layers.4.module.weight      |    512     |\n",
      "|       encoder.graph_encoder.norm_layers.4.module.bias       |    512     |\n",
      "|      encoder.graph_encoder.norm_layers.5.module.weight      |    512     |\n",
      "|       encoder.graph_encoder.norm_layers.5.module.bias       |    512     |\n",
      "|      encoder.graph_encoder.norm_layers.6.module.weight      |    512     |\n",
      "|       encoder.graph_encoder.norm_layers.6.module.bias       |    512     |\n",
      "|      encoder.graph_encoder.norm_layers.7.module.weight      |    512     |\n",
      "|       encoder.graph_encoder.norm_layers.7.module.bias       |    512     |\n",
      "|      encoder.graph_attention.gate_nn.0.layers.0.weight      |    512     |\n",
      "|       encoder.graph_attention.gate_nn.0.layers.0.bias       |     1      |\n",
      "|           encoder.graph_attention.gate_nn.1.weight          |     1      |\n",
      "|            encoder.graph_attention.gate_nn.1.bias           |     1      |\n",
      "|               encoder.bars_encoder_attr.weight              |   524288   |\n",
      "|                encoder.bars_encoder_attr.bias               |    512     |\n",
      "|              encoder.cnn_encoder.conv.0.weight              |     72     |\n",
      "|               encoder.cnn_encoder.conv.0.bias               |     8      |\n",
      "|              encoder.cnn_encoder.conv.1.weight              |     8      |\n",
      "|               encoder.cnn_encoder.conv.1.bias               |     8      |\n",
      "|              encoder.cnn_encoder.conv.4.weight              |    1152    |\n",
      "|               encoder.cnn_encoder.conv.4.bias               |     16     |\n",
      "|              encoder.cnn_encoder.conv.5.weight              |     16     |\n",
      "|               encoder.cnn_encoder.conv.5.bias               |     16     |\n",
      "|               encoder.cnn_encoder.lin.1.weight              |   262144   |\n",
      "|                encoder.cnn_encoder.lin.1.bias               |    512     |\n",
      "|               encoder.cnn_encoder.lin.4.weight              |   262144   |\n",
      "|                encoder.cnn_encoder.lin.4.bias               |    512     |\n",
      "|              encoder.bars_encoder_struct.weight             |   524288   |\n",
      "|               encoder.bars_encoder_struct.bias              |    512     |\n",
      "|                 encoder.linear_merge.weight                 |   524288   |\n",
      "|                  encoder.linear_merge.bias                  |    512     |\n",
      "|                     encoder.bn_lm.weight                    |    512     |\n",
      "|                      encoder.bn_lm.bias                     |    512     |\n",
      "|                   encoder.linear_mu.weight                  |   262144   |\n",
      "|                    encoder.linear_mu.bias                   |    512     |\n",
      "|                encoder.linear_log_var.weight                |   262144   |\n",
      "|                 encoder.linear_log_var.bias                 |    512     |\n",
      "|                  decoder.lin_decoder.weight                 |   524288   |\n",
      "|                   decoder.lin_decoder.bias                  |    1024    |\n",
      "|                  decoder.batch_norm.weight                  |    1024    |\n",
      "|                   decoder.batch_norm.bias                   |    1024    |\n",
      "|            decoder.s_decoder.bars_decoder.weight            |   524288   |\n",
      "|             decoder.s_decoder.bars_decoder.bias             |    1024    |\n",
      "|          decoder.s_decoder.cnn_decoder.lin.1.weight         |   262144   |\n",
      "|           decoder.s_decoder.cnn_decoder.lin.1.bias          |    512     |\n",
      "|          decoder.s_decoder.cnn_decoder.lin.4.weight         |   262144   |\n",
      "|           decoder.s_decoder.cnn_decoder.lin.4.bias          |    512     |\n",
      "|         decoder.s_decoder.cnn_decoder.conv.1.weight         |    1152    |\n",
      "|          decoder.s_decoder.cnn_decoder.conv.1.bias          |     8      |\n",
      "|         decoder.s_decoder.cnn_decoder.conv.2.weight         |     8      |\n",
      "|          decoder.s_decoder.cnn_decoder.conv.2.bias          |     8      |\n",
      "|         decoder.s_decoder.cnn_decoder.conv.4.weight         |     72     |\n",
      "|          decoder.s_decoder.cnn_decoder.conv.4.bias          |     1      |\n",
      "|            decoder.c_decoder.bars_decoder.weight            |   524288   |\n",
      "|             decoder.c_decoder.bars_decoder.bias             |    1024    |\n",
      "|       decoder.c_decoder.graph_decoder.layers.0.weight       |  1572864   |\n",
      "|        decoder.c_decoder.graph_decoder.layers.0.root        |   262144   |\n",
      "|        decoder.c_decoder.graph_decoder.layers.0.bias        |    512     |\n",
      "|      decoder.c_decoder.graph_decoder.layers.0.nn.weight     |   16384    |\n",
      "|       decoder.c_decoder.graph_decoder.layers.0.nn.bias      |    512     |\n",
      "|       decoder.c_decoder.graph_decoder.layers.1.weight       |  1572864   |\n",
      "|        decoder.c_decoder.graph_decoder.layers.1.root        |   262144   |\n",
      "|        decoder.c_decoder.graph_decoder.layers.1.bias        |    512     |\n",
      "|       decoder.c_decoder.graph_decoder.layers.2.weight       |  1572864   |\n",
      "|        decoder.c_decoder.graph_decoder.layers.2.root        |   262144   |\n",
      "|        decoder.c_decoder.graph_decoder.layers.2.bias        |    512     |\n",
      "|       decoder.c_decoder.graph_decoder.layers.3.weight       |  1572864   |\n",
      "|        decoder.c_decoder.graph_decoder.layers.3.root        |   262144   |\n",
      "|        decoder.c_decoder.graph_decoder.layers.3.bias        |    512     |\n",
      "|       decoder.c_decoder.graph_decoder.layers.4.weight       |  1572864   |\n",
      "|        decoder.c_decoder.graph_decoder.layers.4.root        |   262144   |\n",
      "|        decoder.c_decoder.graph_decoder.layers.4.bias        |    512     |\n",
      "|       decoder.c_decoder.graph_decoder.layers.5.weight       |  1572864   |\n",
      "|        decoder.c_decoder.graph_decoder.layers.5.root        |   262144   |\n",
      "|        decoder.c_decoder.graph_decoder.layers.5.bias        |    512     |\n",
      "|       decoder.c_decoder.graph_decoder.layers.6.weight       |  1572864   |\n",
      "|        decoder.c_decoder.graph_decoder.layers.6.root        |   262144   |\n",
      "|        decoder.c_decoder.graph_decoder.layers.6.bias        |    512     |\n",
      "|       decoder.c_decoder.graph_decoder.layers.7.weight       |  1572864   |\n",
      "|        decoder.c_decoder.graph_decoder.layers.7.root        |   262144   |\n",
      "|        decoder.c_decoder.graph_decoder.layers.7.bias        |    512     |\n",
      "| decoder.c_decoder.graph_decoder.norm_layers.0.module.weight |    512     |\n",
      "|  decoder.c_decoder.graph_decoder.norm_layers.0.module.bias  |    512     |\n",
      "| decoder.c_decoder.graph_decoder.norm_layers.1.module.weight |    512     |\n",
      "|  decoder.c_decoder.graph_decoder.norm_layers.1.module.bias  |    512     |\n",
      "| decoder.c_decoder.graph_decoder.norm_layers.2.module.weight |    512     |\n",
      "|  decoder.c_decoder.graph_decoder.norm_layers.2.module.bias  |    512     |\n",
      "| decoder.c_decoder.graph_decoder.norm_layers.3.module.weight |    512     |\n",
      "|  decoder.c_decoder.graph_decoder.norm_layers.3.module.bias  |    512     |\n",
      "| decoder.c_decoder.graph_decoder.norm_layers.4.module.weight |    512     |\n",
      "|  decoder.c_decoder.graph_decoder.norm_layers.4.module.bias  |    512     |\n",
      "| decoder.c_decoder.graph_decoder.norm_layers.5.module.weight |    512     |\n",
      "|  decoder.c_decoder.graph_decoder.norm_layers.5.module.bias  |    512     |\n",
      "| decoder.c_decoder.graph_decoder.norm_layers.6.module.weight |    512     |\n",
      "|  decoder.c_decoder.graph_decoder.norm_layers.6.module.bias  |    512     |\n",
      "| decoder.c_decoder.graph_decoder.norm_layers.7.module.weight |    512     |\n",
      "|  decoder.c_decoder.graph_decoder.norm_layers.7.module.bias  |    512     |\n",
      "|            decoder.c_decoder.chord_decoder.weight           |  3932160   |\n",
      "|             decoder.c_decoder.chord_decoder.bias            |    7680    |\n",
      "|           decoder.c_decoder.drums_pitch_emb.weight          |   33536    |\n",
      "|            decoder.c_decoder.drums_pitch_emb.bias           |    131     |\n",
      "|         decoder.c_decoder.non_drums_pitch_emb.weight        |   33536    |\n",
      "|          decoder.c_decoder.non_drums_pitch_emb.bias         |    131     |\n",
      "|               decoder.c_decoder.dur_emb.weight              |   25344    |\n",
      "|                decoder.c_decoder.dur_emb.bias               |     99     |\n",
      "+-------------------------------------------------------------+------------+\n",
      "Total Trainable Params: 42210909\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec224f523e814aa99b1590ed872807bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on batch 1/15 of epoch 1/100 complete.\n",
      "Elapsed time from start (h:m:s): 00:00:03.79\n",
      "Losses:\n",
      "{ 'acts': 0.64,\n",
      "  'beta*kld': 0.0,\n",
      "  'dur': 5.57,\n",
      "  'kld': 66.0,\n",
      "  'pitches': 5.56,\n",
      "  'rec': 11.77,\n",
      "  'tot': 11.77}\n",
      "Accuracies:\n",
      "{ 'dur': 0.0,\n",
      "  'note': 0.0,\n",
      "  'pitch': 0.0,\n",
      "  'pitch_drums': 0.0,\n",
      "  'pitch_non_drums': 0.01,\n",
      "  's_acc': 0.14,\n",
      "  's_f1': 0.25,\n",
      "  's_precision': 0.14,\n",
      "  's_recall': 1.0}\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Saving model to disk...\n",
      "\n",
      "The model has been successfully saved.\n",
      "Training on batch 2/15 of epoch 1/100 complete.\n",
      "Elapsed time from start (h:m:s): 00:00:06.78\n",
      "Losses:\n",
      "{ 'acts': 0.64,\n",
      "  'beta*kld': 0.0,\n",
      "  'dur': 5.51,\n",
      "  'kld': 66.69,\n",
      "  'pitches': 5.5,\n",
      "  'rec': 11.65,\n",
      "  'tot': 11.65}\n",
      "Accuracies:\n",
      "{ 'dur': 0.0,\n",
      "  'note': 0.0,\n",
      "  'pitch': 0.0,\n",
      "  'pitch_drums': 0.0,\n",
      "  'pitch_non_drums': 0.01,\n",
      "  's_acc': 0.14,\n",
      "  's_f1': 0.25,\n",
      "  's_precision': 0.14,\n",
      "  's_recall': 1.0}\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Saving model to disk...\n",
      "\n",
      "The model has been successfully saved.\n",
      "Training on batch 3/15 of epoch 1/100 complete.\n",
      "Elapsed time from start (h:m:s): 00:00:09.58\n",
      "Losses:\n",
      "{ 'acts': 0.64,\n",
      "  'beta*kld': 0.0,\n",
      "  'dur': 4.64,\n",
      "  'kld': 65.79,\n",
      "  'pitches': 4.93,\n",
      "  'rec': 10.22,\n",
      "  'tot': 10.22}\n",
      "Accuracies:\n",
      "{ 'dur': 0.03,\n",
      "  'note': 0.0,\n",
      "  'pitch': 0.03,\n",
      "  'pitch_drums': 0.03,\n",
      "  'pitch_non_drums': 0.02,\n",
      "  's_acc': 0.14,\n",
      "  's_f1': 0.25,\n",
      "  's_precision': 0.14,\n",
      "  's_recall': 1.0}\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Saving model to disk...\n",
      "\n",
      "The model has been successfully saved.\n",
      "Training on batch 4/15 of epoch 1/100 complete.\n",
      "Elapsed time from start (h:m:s): 00:00:11.06\n",
      "Losses:\n",
      "{ 'acts': 0.64,\n",
      "  'beta*kld': 0.0,\n",
      "  'dur': 3.85,\n",
      "  'kld': 66.18,\n",
      "  'pitches': 4.42,\n",
      "  'rec': 8.91,\n",
      "  'tot': 8.91}\n",
      "Accuracies:\n",
      "{ 'dur': 0.21,\n",
      "  'note': 0.09,\n",
      "  'pitch': 0.19,\n",
      "  'pitch_drums': 0.18,\n",
      "  'pitch_non_drums': 0.2,\n",
      "  's_acc': 0.14,\n",
      "  's_f1': 0.25,\n",
      "  's_precision': 0.14,\n",
      "  's_recall': 1.0}\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Saving model to disk...\n",
      "\n",
      "The model has been successfully saved.\n",
      "Training on batch 5/15 of epoch 1/100 complete.\n",
      "Elapsed time from start (h:m:s): 00:00:12.98\n",
      "Losses:\n",
      "{ 'acts': 0.64,\n",
      "  'beta*kld': 0.0,\n",
      "  'dur': 3.18,\n",
      "  'kld': 65.91,\n",
      "  'pitches': 3.95,\n",
      "  'rec': 7.77,\n",
      "  'tot': 7.77}\n",
      "Accuracies:\n",
      "{ 'dur': 0.45,\n",
      "  'note': 0.23,\n",
      "  'pitch': 0.29,\n",
      "  'pitch_drums': 0.25,\n",
      "  'pitch_non_drums': 0.32,\n",
      "  's_acc': 0.14,\n",
      "  's_f1': 0.25,\n",
      "  's_precision': 0.14,\n",
      "  's_recall': 1.0}\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Saving model to disk...\n",
      "\n",
      "The model has been successfully saved.\n",
      "Training on batch 6/15 of epoch 1/100 complete.\n",
      "Elapsed time from start (h:m:s): 00:00:14.99\n",
      "Losses:\n",
      "{ 'acts': 0.64,\n",
      "  'beta*kld': 0.0,\n",
      "  'dur': 2.74,\n",
      "  'kld': 66.75,\n",
      "  'pitches': 3.63,\n",
      "  'rec': 7.01,\n",
      "  'tot': 7.01}\n",
      "Accuracies:\n",
      "{ 'dur': 0.55,\n",
      "  'note': 0.34,\n",
      "  'pitch': 0.35,\n",
      "  'pitch_drums': 0.35,\n",
      "  'pitch_non_drums': 0.35,\n",
      "  's_acc': 0.14,\n",
      "  's_f1': 0.25,\n",
      "  's_precision': 0.14,\n",
      "  's_recall': 1.0}\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Saving model to disk...\n",
      "\n",
      "The model has been successfully saved.\n",
      "Training on batch 7/15 of epoch 1/100 complete.\n",
      "Elapsed time from start (h:m:s): 00:00:16.94\n",
      "Losses:\n",
      "{ 'acts': 0.64,\n",
      "  'beta*kld': 0.0,\n",
      "  'dur': 2.5,\n",
      "  'kld': 66.97,\n",
      "  'pitches': 3.43,\n",
      "  'rec': 6.58,\n",
      "  'tot': 6.58}\n",
      "Accuracies:\n",
      "{ 'dur': 0.57,\n",
      "  'note': 0.37,\n",
      "  'pitch': 0.38,\n",
      "  'pitch_drums': 0.42,\n",
      "  'pitch_non_drums': 0.35,\n",
      "  's_acc': 0.14,\n",
      "  's_f1': 0.24,\n",
      "  's_precision': 0.14,\n",
      "  's_recall': 1.0}\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Saving model to disk...\n",
      "\n",
      "The model has been successfully saved.\n",
      "Training on batch 8/15 of epoch 1/100 complete.\n",
      "Elapsed time from start (h:m:s): 00:00:18.91\n",
      "Losses:\n",
      "{ 'acts': 0.64,\n",
      "  'beta*kld': 0.0,\n",
      "  'dur': 2.46,\n",
      "  'kld': 67.99,\n",
      "  'pitches': 3.35,\n",
      "  'rec': 6.45,\n",
      "  'tot': 6.45}\n",
      "Accuracies:\n",
      "{ 'dur': 0.56,\n",
      "  'note': 0.38,\n",
      "  'pitch': 0.39,\n",
      "  'pitch_drums': 0.44,\n",
      "  'pitch_non_drums': 0.35,\n",
      "  's_acc': 0.14,\n",
      "  's_f1': 0.25,\n",
      "  's_precision': 0.14,\n",
      "  's_recall': 1.0}\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Saving model to disk...\n",
      "\n",
      "The model has been successfully saved.\n",
      "Training on batch 9/15 of epoch 1/100 complete.\n",
      "Elapsed time from start (h:m:s): 00:00:20.84\n",
      "Losses:\n",
      "{ 'acts': 0.64,\n",
      "  'beta*kld': 0.0,\n",
      "  'dur': 2.38,\n",
      "  'kld': 68.99,\n",
      "  'pitches': 3.19,\n",
      "  'rec': 6.21,\n",
      "  'tot': 6.21}\n",
      "Accuracies:\n",
      "{ 'dur': 0.57,\n",
      "  'note': 0.4,\n",
      "  'pitch': 0.4,\n",
      "  'pitch_drums': 0.47,\n",
      "  'pitch_non_drums': 0.35,\n",
      "  's_acc': 0.14,\n",
      "  's_f1': 0.24,\n",
      "  's_precision': 0.14,\n",
      "  's_recall': 1.0}\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Saving model to disk...\n",
      "\n",
      "The model has been successfully saved.\n",
      "Training on batch 10/15 of epoch 1/100 complete.\n",
      "Elapsed time from start (h:m:s): 00:00:22.85\n",
      "Losses:\n",
      "{ 'acts': 0.64,\n",
      "  'beta*kld': 0.0,\n",
      "  'dur': 2.29,\n",
      "  'kld': 71.5,\n",
      "  'pitches': 3.11,\n",
      "  'rec': 6.04,\n",
      "  'tot': 6.04}\n",
      "Accuracies:\n",
      "{ 'dur': 0.57,\n",
      "  'note': 0.41,\n",
      "  'pitch': 0.42,\n",
      "  'pitch_drums': 0.5,\n",
      "  'pitch_non_drums': 0.36,\n",
      "  's_acc': 0.15,\n",
      "  's_f1': 0.25,\n",
      "  's_precision': 0.15,\n",
      "  's_recall': 1.0}\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Saving model to disk...\n",
      "\n",
      "The model has been successfully saved.\n",
      "Training on batch 11/15 of epoch 1/100 complete.\n",
      "Elapsed time from start (h:m:s): 00:00:24.93\n",
      "Losses:\n",
      "{ 'acts': 0.64,\n",
      "  'beta*kld': 0.0,\n",
      "  'dur': 2.13,\n",
      "  'kld': 73.02,\n",
      "  'pitches': 3.01,\n",
      "  'rec': 5.78,\n",
      "  'tot': 5.78}\n",
      "Accuracies:\n",
      "{ 'dur': 0.58,\n",
      "  'note': 0.42,\n",
      "  'pitch': 0.43,\n",
      "  'pitch_drums': 0.51,\n",
      "  'pitch_non_drums': 0.37,\n",
      "  's_acc': 0.14,\n",
      "  's_f1': 0.24,\n",
      "  's_precision': 0.14,\n",
      "  's_recall': 1.0}\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Saving model to disk...\n",
      "\n",
      "The model has been successfully saved.\n",
      "Training on batch 12/15 of epoch 1/100 complete.\n",
      "Elapsed time from start (h:m:s): 00:00:26.92\n",
      "Losses:\n",
      "{ 'acts': 0.64,\n",
      "  'beta*kld': 0.0,\n",
      "  'dur': 2.02,\n",
      "  'kld': 75.43,\n",
      "  'pitches': 2.99,\n",
      "  'rec': 5.65,\n",
      "  'tot': 5.65}\n",
      "Accuracies:\n",
      "{ 'dur': 0.59,\n",
      "  'note': 0.42,\n",
      "  'pitch': 0.44,\n",
      "  'pitch_drums': 0.52,\n",
      "  'pitch_non_drums': 0.37,\n",
      "  's_acc': 0.14,\n",
      "  's_f1': 0.25,\n",
      "  's_precision': 0.14,\n",
      "  's_recall': 1.0}\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Saving model to disk...\n",
      "\n",
      "The model has been successfully saved.\n",
      "Training on batch 13/15 of epoch 1/100 complete.\n",
      "Elapsed time from start (h:m:s): 00:00:28.92\n",
      "Losses:\n",
      "{ 'acts': 0.64,\n",
      "  'beta*kld': 0.0,\n",
      "  'dur': 1.95,\n",
      "  'kld': 77.34,\n",
      "  'pitches': 2.88,\n",
      "  'rec': 5.46,\n",
      "  'tot': 5.46}\n",
      "Accuracies:\n",
      "{ 'dur': 0.59,\n",
      "  'note': 0.39,\n",
      "  'pitch': 0.44,\n",
      "  'pitch_drums': 0.52,\n",
      "  'pitch_non_drums': 0.39,\n",
      "  's_acc': 0.14,\n",
      "  's_f1': 0.25,\n",
      "  's_precision': 0.14,\n",
      "  's_recall': 1.0}\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Saving model to disk...\n",
      "\n",
      "The model has been successfully saved.\n",
      "Training on batch 14/15 of epoch 1/100 complete.\n",
      "Elapsed time from start (h:m:s): 00:00:30.83\n",
      "Losses:\n",
      "{ 'acts': 0.64,\n",
      "  'beta*kld': 0.0,\n",
      "  'dur': 1.95,\n",
      "  'kld': 78.23,\n",
      "  'pitches': 2.9,\n",
      "  'rec': 5.49,\n",
      "  'tot': 5.49}\n",
      "Accuracies:\n",
      "{ 'dur': 0.57,\n",
      "  'note': 0.37,\n",
      "  'pitch': 0.44,\n",
      "  'pitch_drums': 0.55,\n",
      "  'pitch_non_drums': 0.37,\n",
      "  's_acc': 0.14,\n",
      "  's_f1': 0.25,\n",
      "  's_precision': 0.14,\n",
      "  's_recall': 1.0}\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Saving model to disk...\n",
      "\n",
      "The model has been successfully saved.\n",
      "Training on batch 15/15 of epoch 1/100 complete.\n",
      "Elapsed time from start (h:m:s): 00:00:32.74\n",
      "Losses:\n",
      "{ 'acts': 0.64,\n",
      "  'beta*kld': 0.0,\n",
      "  'dur': 2.1,\n",
      "  'kld': 78.4,\n",
      "  'pitches': 3.05,\n",
      "  'rec': 5.79,\n",
      "  'tot': 5.79}\n",
      "Accuracies:\n",
      "{ 'dur': 0.53,\n",
      "  'note': 0.33,\n",
      "  'pitch': 0.42,\n",
      "  'pitch_drums': 0.52,\n",
      "  'pitch_non_drums': 0.36,\n",
      "  's_acc': 0.15,\n",
      "  's_f1': 0.25,\n",
      "  's_precision': 0.15,\n",
      "  's_recall': 1.0}\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Saving model to disk...\n",
      "\n",
      "The model has been successfully saved.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_121642/2180637210.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;34m**\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'beta_annealing'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m )\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/thesis/Polyphemus/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, trainloader, validloader, epochs, early_exit)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtot_batches\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miters_to_accumulate\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m                     \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m                     \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/test/lib/python3.7/site-packages/torch/cuda/amp/grad_scaler.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"No inf checks were recorded for this optimizer.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/test/lib/python3.7/site-packages/torch/cuda/amp/grad_scaler.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"No inf checks were recorded for this optimizer.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from utils import print_params\n",
    "import os\n",
    "from model import VAE\n",
    "import torch.optim as optim\n",
    "from train import PolyphemusTrainer\n",
    "\n",
    "print(\"Creating the model and moving it to the specified device...\")\n",
    "\n",
    "# Create model dir\n",
    "models_dir = 'models_prova/'\n",
    "model_name = 'prova'\n",
    "model_dir = os.path.join(models_dir, model_name)\n",
    "os.makedirs(models_dir, exist_ok=True) \n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# Creating the model\n",
    "vae = VAE(**parameters['model'], device=device).to(device)\n",
    "\n",
    "print_params(vae)\n",
    "print()\n",
    "\n",
    "# Creating optimizer and scheduler\n",
    "optimizer = optim.Adam(vae.parameters(), **parameters['optimizer'])\n",
    "scheduler = ExpDecayLRScheduler(\n",
    "    optimizer=optimizer,\n",
    "    **parameters['scheduler']\n",
    ")\n",
    "\n",
    "# Save parameters\n",
    "params_path = os.path.join(model_dir, 'params')\n",
    "torch.save(parameters, params_path)\n",
    "\n",
    "print('--------------------------------------------------\\n')\n",
    "\n",
    "trainer = PolyphemusTrainer(\n",
    "    model_dir,\n",
    "    model=vae,\n",
    "    optimizer=optimizer,\n",
    "    lr_scheduler=scheduler,\n",
    "    save_every=1,\n",
    "    print_every=1,\n",
    "    eval_every=18631,\n",
    "    iters_to_accumulate=1,\n",
    "    device=device,\n",
    "    **parameters['beta_annealing']\n",
    ")\n",
    "trainer.train(trainloader, validloader=None, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
