{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/EmanueleCosenza/Polyphemus/blob/main/midi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "50lpUn9bO0ug",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/cosenza/thesis/Polyphemus\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraries installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!tar -C data -xvzf data/lmd_matched.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "She0QbN5Kopo",
    "outputId": "0f3fb4c7-bd7d-4ee4-b2cd-d567d8e490db",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Install the required music libraries\n",
    "#!pip3 install muspy\n",
    "#!pip3 install pypianoroll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3uveQkY7O0CF",
    "outputId": "12e1f638-ee78-4617-844a-10e9a26c298e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Install torch_geometric\n",
    "#!v=$(python3 -c \"import torch; print(torch.__version__)\"); \\\n",
    "#pip3 install torch-scatter -f https://data.pyg.org/whl/torch-${v}.html; \\\n",
    "#pip3 install torch-sparse -f https://data.pyg.org/whl/torch-${v}.html; \\\n",
    "#pip3 install torch-geometric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import os\n",
    "\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "seed = 42\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "B45l1513wJ1Q"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import muspy\n",
    "from itertools import product\n",
    "import pypianoroll as pproll\n",
    "import time\n",
    "\n",
    "\n",
    "class MIDIPreprocessor():\n",
    "    \n",
    "    def __init__():\n",
    "        pass\n",
    "\n",
    "    def preprocess_dataset(self, dir, early_exit=None):\n",
    "        pass\n",
    "    \n",
    "    def preprocess_file(self, f):\n",
    "        pass\n",
    "\n",
    "\n",
    "# Todo: to config file (or separate files)\n",
    "MAX_SIMU_NOTES = 16 # 14 + SOS and EOS\n",
    "\n",
    "PITCH_SOS = 128\n",
    "PITCH_EOS = 129\n",
    "PITCH_PAD = 130\n",
    "DUR_PAD_IND = 2\n",
    "MAX_DUR = 511 # equivalent to 16 bars (with RESOLUTION=32)\n",
    "\n",
    "RESOLUTION = 32\n",
    "NUM_BARS = 1\n",
    "\n",
    "\n",
    "def preprocess_file(filepath, dest_dir, num_samples):\n",
    "\n",
    "    saved_samples = 0\n",
    "\n",
    "    print()\n",
    "    print(\"Preprocessing file \" + filepath)\n",
    "\n",
    "    # Load the file both as a pypianoroll song and a muspy song\n",
    "    # (Need to load both since muspy.to_pypianoroll() is expensive)\n",
    "    try:\n",
    "        pproll_song = pproll.read(filepath, resolution=RESOLUTION)\n",
    "        muspy_song = muspy.read(filepath)\n",
    "    except Exception as e:\n",
    "        print(\"Song skipped (Invalid song format)\")\n",
    "        return 0\n",
    "    \n",
    "    # Only accept songs that have a time signature of 4/4 and no time changes\n",
    "    for t in muspy_song.time_signatures:\n",
    "        if t.numerator != 4 or t.denominator != 4:\n",
    "            print(\"Song skipped ({}/{} time signature)\".\n",
    "                            format(t.numerator, t.denominator))\n",
    "            return 0\n",
    "\n",
    "    # Gather tracks of pypianoroll song based on MIDI program number\n",
    "    drum_tracks = []\n",
    "    bass_tracks = []\n",
    "    guitar_tracks = []\n",
    "    strings_tracks = []\n",
    "\n",
    "    for track in pproll_song.tracks:\n",
    "        if track.is_drum:\n",
    "            track.name = 'Drums'\n",
    "            drum_tracks.append(track)\n",
    "        elif 0 <= track.program <= 31:\n",
    "            track.name = 'Guitar'\n",
    "            guitar_tracks.append(track)\n",
    "        elif 32 <= track.program <= 39:\n",
    "            track.name = 'Bass'\n",
    "            bass_tracks.append(track)\n",
    "        else:\n",
    "            # Tracks with program > 39 are all considered as strings tracks\n",
    "            # and will be merged into a single track later on\n",
    "            strings_tracks.append(track)\n",
    "\n",
    "    # Filter song if it does not contain drum, guitar, bass or strings tracks\n",
    "    if not drum_tracks or not guitar_tracks \\\n",
    "       or not bass_tracks or not strings_tracks:\n",
    "        print(\"Song skipped (does not contain drum or \"\n",
    "                \"guitar or bass or strings tracks)\")\n",
    "        return 0\n",
    "    \n",
    "    # Merge strings tracks into a single pypianoroll track\n",
    "    strings = pproll.Multitrack(tracks=strings_tracks)\n",
    "    strings_track = pproll.Track(pianoroll=strings.blend(mode='max'),\n",
    "                                 program=48, name='Strings')\n",
    "\n",
    "    combinations = list(product(drum_tracks, bass_tracks, guitar_tracks))\n",
    "\n",
    "    # Single instruments can have multiple tracks.\n",
    "    # Consider all possible combinations of drum, bass, and guitar tracks\n",
    "    for i, combination in enumerate(combinations):\n",
    "\n",
    "        print(\"Processing combination\", i+1, \"of\", len(combinations))\n",
    "        \n",
    "        # Process combination (called 'subsong' from now on)\n",
    "        drum_track, bass_track, guitar_track = combination\n",
    "        tracks = [drum_track, bass_track, guitar_track, strings_track]\n",
    "        \n",
    "        pproll_subsong = pproll.Multitrack(\n",
    "            tracks=tracks,\n",
    "            tempo=pproll_song.tempo,\n",
    "            resolution=RESOLUTION\n",
    "        )\n",
    "        muspy_subsong = muspy.from_pypianoroll(pproll_subsong)\n",
    "        \n",
    "        tracks_notes = [track.notes for track in muspy_subsong.tracks]\n",
    "        \n",
    "        # Obtain length of subsong (maximum of each track's length)\n",
    "        length = 0\n",
    "        for notes in tracks_notes:\n",
    "            track_length = max(note.end for note in notes)\n",
    "            length = max(length, track_length)\n",
    "        length += 1\n",
    "\n",
    "        # Add timesteps until length is a multiple of RESOLUTION\n",
    "        length = length if length%(RESOLUTION) == 0 \\\n",
    "                                else length + (RESOLUTION-(length%(RESOLUTION)))\n",
    "\n",
    "\n",
    "        tracks_tensors = []\n",
    "        tracks_activations = []\n",
    "\n",
    "        dur_bin_length = int(np.ceil(np.log2(MAX_DUR)))\n",
    "\n",
    "        # Todo: adapt to velocity\n",
    "        for notes in tracks_notes:\n",
    "\n",
    "            # Initialize encoder-ready track tensor\n",
    "            # track_tensor: (length x max_simu_notes x 2 (or 3 if velocity))\n",
    "            # The last dimension contains pitches and durations (and velocities)\n",
    "            # int16 is enough for small to medium duration values\n",
    "            track_tensor = np.zeros((length, MAX_SIMU_NOTES, 2), np.int16)\n",
    "\n",
    "            track_tensor[:, :, 0] = PITCH_PAD\n",
    "            track_tensor[:, 0, 0] = PITCH_SOS\n",
    "\n",
    "            # Keeps track of how many notes have been stored in each timestep\n",
    "            # (int8 imposes that MAX_SIMU_NOTES < 256)\n",
    "            notes_counter = np.ones(length, dtype=np.int8)\n",
    "\n",
    "            # Todo: np.put_along_axis?\n",
    "            for note in notes:\n",
    "                # Insert note in the lowest position available in the timestep\n",
    "                \n",
    "                t = note.time\n",
    "\n",
    "                if notes_counter[t] >= MAX_SIMU_NOTES-1:\n",
    "                    # Skip note if there is no more space\n",
    "                    continue\n",
    "\n",
    "                track_tensor[t, notes_counter[t], 0] = note.pitch\n",
    "                track_tensor[t, notes_counter[t], 1] = note.duration\n",
    "                notes_counter[t] += 1\n",
    "            \n",
    "            # Add end of sequence token\n",
    "            track_tensor[np.arange(0, length), notes_counter, 0] = PITCH_EOS\n",
    "\n",
    "            # Get track activations, a boolean tensor indicating whether notes\n",
    "            # are being played in a timestep (sustain does not count)\n",
    "            # (needed for graph rep.)\n",
    "            activations = np.array(notes_counter-1, dtype=bool)\n",
    "\n",
    "            tracks_tensors.append(track_tensor)\n",
    "            tracks_activations.append(activations)\n",
    "        \n",
    "        # (#tracks x length x max_simu_notes x 2 (or 3))\n",
    "        subsong_tensor = np.stack(tracks_tensors, axis=0)\n",
    "\n",
    "        # (#tracks x length)\n",
    "        subsong_activations = np.stack(tracks_activations, axis=0)\n",
    "\n",
    "\n",
    "        # Slide window over 'subsong_tensor' and 'subsong_activations' along the\n",
    "        # time axis (2nd dimension) with the stride of a bar\n",
    "        # Todo: np.lib.stride_tricks.as_strided(song_proll)\n",
    "        for i in range(0, length-NUM_BARS*RESOLUTION+1, RESOLUTION):\n",
    "            \n",
    "            # Get the sequence and its activations\n",
    "            seq_tensor = subsong_tensor[:, i:i+NUM_BARS*RESOLUTION, :]\n",
    "            seq_acts = subsong_activations[:, i:i+NUM_BARS*RESOLUTION]\n",
    "\n",
    "            # Skip sequence if it contains more than one bar of consecutive\n",
    "            # silence in at least one track\n",
    "            bars = seq_acts.reshape(seq_acts.shape[0], NUM_BARS, -1)\n",
    "            bars_acts = np.any(bars, axis=2)\n",
    "            \n",
    "            if 1 in np.diff(np.where(bars_acts == 0)[1]):\n",
    "                continue\n",
    "\n",
    "            # Randomly transpose the pitches of the sequence (-5 to 6 semitones)\n",
    "            shift = np.random.choice(np.arange(-5, 7), 1)\n",
    "            cond = (seq_tensor[:, :, :, 0] != PITCH_PAD) &                     \\\n",
    "                   (seq_tensor[:, :, :, 0] != PITCH_SOS) &                     \\\n",
    "                   (seq_tensor[:, :, :, 0] != PITCH_EOS)\n",
    "            seq_tensor[cond, 0] += shift\n",
    "\n",
    "            # Save sample (seq_tensor and seq_acts) to file\n",
    "            curr_sample = str(num_samples + saved_samples)\n",
    "            sample_filepath = os.path.join(dest_dir, curr_sample)\n",
    "            np.savez(sample_filepath, seq_tensor=seq_tensor, seq_acts=seq_acts)\n",
    "\n",
    "            saved_samples += 1\n",
    "\n",
    "\n",
    "    print(\"File preprocessing finished. Saved samples:\", saved_samples)\n",
    "    print()\n",
    "\n",
    "    return saved_samples\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Total number of files: 116189\n",
    "# Number of unique files: 45129\n",
    "def preprocess_dataset(dataset_dir, dest_dir, early_exit=None):\n",
    "\n",
    "    files_dict = {}\n",
    "    seen = 0\n",
    "    tot_samples = 0\n",
    "    finished = False\n",
    "\n",
    "    # Visit recursively the directories inside the dataset directory\n",
    "    for dirpath, dirs, files in os.walk(dataset_dir):\n",
    "\n",
    "        # Sort alphabetically the found directories\n",
    "        # (to help guess the remaining time) \n",
    "        dirs.sort()\n",
    "        \n",
    "        print(\"Current path:\", dirpath)\n",
    "\n",
    "        for f in files:\n",
    "            \n",
    "            seen += 1\n",
    "\n",
    "            if f in files_dict:\n",
    "                # Skip already seen file\n",
    "                files_dict[f] += 1\n",
    "                continue\n",
    "\n",
    "            # File never seen before, add to dictionary of files\n",
    "            # (from filename to # of occurrences)\n",
    "            files_dict[f] = 1\n",
    "\n",
    "            # Preprocess file\n",
    "            filepath = os.path.join(dirpath, f)\n",
    "            saved = preprocess_file(filepath, dest_dir, tot_samples)\n",
    "\n",
    "            tot_samples += saved\n",
    "\n",
    "            # Exit when a maximum number of files has been processed (if set)\n",
    "            if early_exit != None and len(files_dict) >= early_exit:\n",
    "                finished = True\n",
    "                break\n",
    "\n",
    "        # Todo: also print # of processed (not filtered) files\n",
    "        #       and # of produced sequences (samples)\n",
    "        print(\"Total number of seen files:\", seen)\n",
    "        print(\"Number of unique files:\", len(files_dict))\n",
    "        print(\"Total number of saved samples:\", tot_samples)\n",
    "        print()\n",
    "\n",
    "        if finished:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "aYc5y-CYyetK"
   },
   "outputs": [],
   "source": [
    "#!rm -rf data/preprocessed/\n",
    "#!mkdir data/preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xqnubg3oP4ES",
    "outputId": "40cc38a2-1f7d-4f6f-e6c9-9e14dfc7f683",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_dir = 'data/lmd_matched'\n",
    "dest_dir = 'data/preprocessed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess_dataset(dataset_dir, dest_dir, early_exit=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RG88mekfrrcp"
   },
   "source": [
    "Check preprocessed data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "JlP6iUNugNtP"
   },
   "outputs": [],
   "source": [
    "filepath = os.path.join(dest_dir, \"5.npz\")\n",
    "data = np.load(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3VUpOEObhwYQ",
    "outputId": "aac6e029-93b1-485f-f13a-2a00abedbc7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 32, 16, 2)\n",
      "(4, 32)\n"
     ]
    }
   ],
   "source": [
    "print(data[\"seq_tensor\"].shape)\n",
    "print(data[\"seq_acts\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A6NA5IAAmtK8",
    "outputId": "6e661b3a-05a1-4e2d-9a3d-e1c037b4d04f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[128,   0],\n",
       "       [129,   0],\n",
       "       [130,   0],\n",
       "       [130,   0],\n",
       "       [130,   0],\n",
       "       [130,   0],\n",
       "       [130,   0],\n",
       "       [130,   0],\n",
       "       [130,   0],\n",
       "       [130,   0],\n",
       "       [130,   0],\n",
       "       [130,   0],\n",
       "       [130,   0],\n",
       "       [130,   0],\n",
       "       [130,   0],\n",
       "       [130,   0]], dtype=int16)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"seq_tensor\"][0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C19X9m-3iMlm"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "zymqD-UqR8wq"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Dataset\n",
    "from torch_geometric.data import Data\n",
    "import itertools\n",
    "\n",
    "\n",
    "def unpackbits(x, num_bits):\n",
    "\n",
    "    if np.issubdtype(x.dtype, np.floating):\n",
    "        raise ValueError(\"numpy data type needs to be int-like\")\n",
    "\n",
    "    xshape = list(x.shape)\n",
    "    x = x.reshape([-1, 1])\n",
    "    mask = 2**np.arange(num_bits, dtype=x.dtype).reshape([1, num_bits])\n",
    "\n",
    "    return (x & mask).astype(bool).astype(int).reshape(xshape + [num_bits])\n",
    "\n",
    "\n",
    "class MIDIDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dir):\n",
    "        self.dir = dir\n",
    "\n",
    "    def __len__(self):\n",
    "        _, _, files = next(os.walk(self.dir))\n",
    "        return len(files)\n",
    "\n",
    "    \n",
    "    def __get_track_edges(self, acts, edge_type_ind=0):\n",
    "\n",
    "        a_t = acts.transpose()\n",
    "        inds = np.stack(np.where(a_t == 1)).transpose()\n",
    "\n",
    "        labels = np.arange(acts.shape[0]*acts.shape[1])\n",
    "        labels = labels.reshape(acts.shape[0], acts.shape[1]).transpose()\n",
    "\n",
    "        track_edges = []\n",
    "\n",
    "        for track in range(a_t.shape[1]):\n",
    "            tr_inds = list(inds[inds[:,1] == track])\n",
    "            e_inds = [(tr_inds[i],\n",
    "                    tr_inds[i+1]) for i in range(len(tr_inds)-1)]\n",
    "            edges = [(labels[tuple(e[0])], labels[tuple(e[1])], edge_type_ind, e[1][0]-e[0][0]) for e in e_inds]\n",
    "            track_edges.extend(edges)\n",
    "\n",
    "        return np.array(track_edges, dtype='long')\n",
    "\n",
    "    \n",
    "    def __get_onset_edges(self, acts, edge_type_ind=1):\n",
    "\n",
    "        a_t = acts.transpose()\n",
    "        inds = np.stack(np.where(a_t == 1)).transpose()\n",
    "        ts_acts = np.any(a_t, axis=1)\n",
    "        ts_inds = np.where(ts_acts)[0]\n",
    "\n",
    "        labels = np.arange(acts.shape[0]*acts.shape[1])\n",
    "        labels = labels.reshape(acts.shape[0], acts.shape[1]).transpose()\n",
    "\n",
    "        onset_edges = []\n",
    "\n",
    "        for i in ts_inds:\n",
    "            ts_acts_inds = list(inds[inds[:,0] == i])\n",
    "            if len(ts_acts_inds) < 2:\n",
    "                continue\n",
    "            e_inds = list(itertools.combinations(ts_acts_inds, 2))\n",
    "            edges = [(labels[tuple(e[0])], labels[tuple(e[1])], edge_type_ind, 0) for e in e_inds]\n",
    "            inv_edges = [(e[1], e[0], *e[2:]) for e in edges]\n",
    "            onset_edges.extend(edges)\n",
    "            onset_edges.extend(inv_edges)\n",
    "\n",
    "        return np.array(onset_edges, dtype='long')\n",
    "\n",
    "\n",
    "    def __get_next_edges(self, acts, edge_type_ind=2):\n",
    "\n",
    "        a_t = acts.transpose()\n",
    "        inds = np.stack(np.where(a_t == 1)).transpose()\n",
    "        ts_acts = np.any(a_t, axis=1)\n",
    "        ts_inds = np.where(ts_acts)[0]\n",
    "\n",
    "        labels = np.arange(acts.shape[0]*acts.shape[1])\n",
    "        labels = labels.reshape(acts.shape[0], acts.shape[1]).transpose()\n",
    "\n",
    "        next_edges = []\n",
    "\n",
    "        for i in range(len(ts_inds)-1):\n",
    "\n",
    "            ind_s = ts_inds[i]\n",
    "            ind_e = ts_inds[i+1]\n",
    "            s = inds[inds[:,0] == ind_s]\n",
    "            e = inds[inds[:,0] == ind_e]\n",
    "\n",
    "            e_inds = [t for t in list(itertools.product(s, e)) if t[0][1] != t[1][1]]\n",
    "            edges = [(labels[tuple(e[0])],labels[tuple(e[1])], edge_type_ind, ind_e-ind_s) for e in e_inds]\n",
    "\n",
    "            next_edges.extend(edges)\n",
    "\n",
    "        return np.array(next_edges, dtype='long')\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        # Load tensors\n",
    "        sample_path = os.path.join(self.dir, str(idx) + \".npz\")\n",
    "        data = np.load(sample_path)\n",
    "\n",
    "        seq_tensor = data[\"seq_tensor\"]\n",
    "        seq_acts = data[\"seq_acts\"]\n",
    "\n",
    "        # From decimals to one-hot (pitch)\n",
    "        pitches = seq_tensor[:, :, :, 0]\n",
    "        onehot = np.zeros((pitches.shape[0]*pitches.shape[1]*pitches.shape[2],\n",
    "                            131), dtype=float)\n",
    "        onehot[np.arange(0, onehot.shape[0]), pitches.reshape(-1)] = 1.\n",
    "        onehot = onehot.reshape(-1, pitches.shape[1], seq_tensor.shape[2], 131)\n",
    "\n",
    "        # From decimals to binary (pitch)\n",
    "        durs = seq_tensor[:, :, :, 1]\n",
    "        bin_durs = unpackbits(durs, 9)[:, :, :, ::-1]\n",
    "\n",
    "        # Concatenate pitches and durations\n",
    "        new_seq_tensor = np.concatenate((onehot[:, :, :, :], bin_durs),\n",
    "                             axis=-1)\n",
    "        \n",
    "        # Construct graph from boolean activations\n",
    "        track_edges = self.__get_track_edges(seq_acts)\n",
    "        onset_edges = self.__get_onset_edges(seq_acts)\n",
    "        next_edges = self.__get_next_edges(seq_acts)\n",
    "        edges = [track_edges, onset_edges, next_edges]\n",
    "\n",
    "        # Concatenate edge tensors (N x 4) (if any)\n",
    "        no_edges = (len(track_edges) == 0 and \n",
    "                    len(onset_edges) == 0 and len(next_edges) == 0)\n",
    "        if not no_edges:\n",
    "            edge_list = np.concatenate([x for x in edges\n",
    "                                          if x.size > 0])\n",
    "            edge_list = torch.from_numpy(edge_list)\n",
    "        \n",
    "        # Adapt tensor to torch_geometric's Data\n",
    "        # Todo: re-check no edges case\n",
    "        edge_index = (torch.LongTensor([[], []]) if no_edges else\n",
    "                               edge_list[:, :2].t().contiguous())\n",
    "        edge_attr = (torch.Tensor([[0, 0]]) if no_edges else\n",
    "                                       edge_list[:, 2:])\n",
    "        \n",
    "        n = seq_acts.shape[0]*seq_acts.shape[1]\n",
    "        graph = Data(edge_index=edge_index, edge_attr=edge_attr, num_nodes=n)\n",
    "        \n",
    "        # Todo: start with torch at mount\n",
    "        return torch.Tensor(new_seq_tensor), torch.Tensor(seq_acts), graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "hSwcnlq4g50O"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch_geometric.nn.conv import GCNConv\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "# Todo: check and think about max_len\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 256):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) *                     \\\n",
    "                             (-math.log(10000.0)/d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position*div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position*div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor, shape [seq_len, batch_size, embedding_dim]\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    \n",
    "    def __init__(self, features_dims=[256, 256, 256], num_relations=3):\n",
    "        super().__init__()\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "        for i in range(len(features_dims)-1):\n",
    "            self.layers.append(GCNConv(features_dims[i], features_dims[i+1]))\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            x = F.dropout(x, training=self.training)\n",
    "            x = layer(x, edge_index)\n",
    "            x = F.relu(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "\n",
    "    # 140 = 128+3+9\n",
    "    def __init__(self, d_token=140, d_transf=256, nhead_transf=4, \n",
    "                 num_layers_transf=2, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        # Todo: one separate encoder for drums\n",
    "        # Transformer Encoder\n",
    "        self.embedding = nn.Linear(d_token, d_transf)\n",
    "        self.pos_encoder = PositionalEncoding(d_transf, dropout)\n",
    "        transf_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_transf,\n",
    "            nhead=nhead_transf\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            transf_layer,\n",
    "            num_layers=num_layers_transf\n",
    "        )\n",
    "\n",
    "        # Graph encoder\n",
    "        self.graph_encoder = GCN()\n",
    "\n",
    "        # (LSTM)\n",
    "        \n",
    "        # Linear layers that compute the final mu and log_var\n",
    "        # Todo: as parameters\n",
    "        self.linear_mu = nn.Linear(256, 256)\n",
    "        self.linear_log_var = nn.Linear(256, 256)\n",
    "\n",
    "    def forward(self, x_seq, x_acts, x_graph):\n",
    "\n",
    "        # Collapse track (and optionally batch) dimension\n",
    "        #print(\"Init input:\", x_seq.size())\n",
    "        x_seq = x_seq.view(-1, x_seq.size(-2), x_seq.size(-1))\n",
    "        #print(\"Reshaped input:\", x_seq.size())\n",
    "\n",
    "        # Compute embeddings\n",
    "        embs = self.embedding(x_seq)\n",
    "        #print(\"Embs:\", embs.size())\n",
    "\n",
    "        # batch_first = False\n",
    "        embs = embs.permute(1, 0, 2)\n",
    "        #print(\"Seq len first input:\", embs.size())\n",
    "\n",
    "        pos_encs = self.pos_encoder(embs)\n",
    "        #print(\"Pos encodings:\", pos_encs.size())\n",
    "\n",
    "        # Todo: src_key_padding_mask = (src != pad).unsqueeze(-2) ?\n",
    "        transformer_encs = self.transformer_encoder(pos_encs)\n",
    "        #print(\"Transf encodings:\", transformer_encs.size())\n",
    "\n",
    "        pooled_encs = torch.mean(transformer_encs, 0)\n",
    "        #print(\"Pooled encodings:\", pooled_encs.size())\n",
    "\n",
    "        # Compute node encodings\n",
    "        x_graph.x = pooled_encs\n",
    "        node_encs = self.graph_encoder(x_graph)\n",
    "        #print(\"Node encodings:\", node_encs.size())\n",
    "        \n",
    "        # Compute final graph latent vector(s)\n",
    "        # (taking into account the batch size)\n",
    "        num_nodes = x_graph[0].num_nodes\n",
    "        batch_sz = node_encs.size(0) // num_nodes\n",
    "        node_encs = node_encs.view(batch_sz, num_nodes, -1)\n",
    "        encoding = torch.mean(node_encs, 1)\n",
    "\n",
    "        # Compute mu and log(std^2)\n",
    "        mu = self.linear_mu(encoding)\n",
    "        log_var = self.linear_log_var(encoding)\n",
    "        \n",
    "        return mu, log_var\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, d_z=256, n_tracks=4, resolution=32, d_token=140, d_model=256,\n",
    "                 d_transf=256, nhead_transf=4, num_layers_transf=2, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        # (LSTM)\n",
    "\n",
    "        # Boolean activations decoder (CNN/MLP)\n",
    "        self.acts_decoder = nn.Linear(d_z, n_tracks*resolution)\n",
    "\n",
    "        # GNN\n",
    "        self.graph_decoder = GCN()\n",
    "        \n",
    "        # Transformer Decoder\n",
    "        self.embedding = nn.Linear(d_token, d_transf)\n",
    "        self.pos_encoder = PositionalEncoding(d_transf,dropout)\n",
    "        decoder_layer = nn.TransformerDecoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead_transf\n",
    "        )\n",
    "        self.transf_decoder = nn.TransformerDecoder(\n",
    "            decoder_layer,\n",
    "            num_layers=num_layers_transf\n",
    "        )\n",
    "        \n",
    "        # Last linear layer\n",
    "        self.lin = nn.Linear(d_model, 140)\n",
    "\n",
    "\n",
    "    def forward(self, z, x_seq, x_acts, x_graph):\n",
    "\n",
    "        # Compute activations from z\n",
    "        acts_out = self.acts_decoder(z)\n",
    "        acts_out = acts_out.view(x_acts.size())\n",
    "        #print(\"Acts out:\", acts_out.size())\n",
    "\n",
    "        # Initialize node features with z and propagate with GNN\n",
    "        node_features = torch.repeat_interleave(\n",
    "                            z, x_acts.size(-1)*x_acts.size(-2), axis=0)\n",
    "        #print(\"Node features:\", node_features.size())\n",
    "\n",
    "        # Todo: use also edge info\n",
    "        x_graph.x = node_features\n",
    "        node_decs = self.graph_decoder(x_graph)\n",
    "        #print(\"Node decodings:\", node_decs.size())\n",
    "        \n",
    "        node_decs = node_decs.repeat(16, 1, 1)\n",
    "        #print(\"Tiled node decodings:\", node_decs.size())\n",
    "\n",
    "        # Decode features with transformer decoder\n",
    "        # forward(tgt, memory, tgt_mask=None, memory_mask=None, tgt_key_padding_mask=None, memory_key_padding_mask=None)\n",
    "        \n",
    "        # Todo: same embeddings as encoder?\n",
    "        seq = x_seq.view(-1, x_seq.size(-2), x_seq.size(-1))\n",
    "        embs = self.embedding(seq)\n",
    "        embs = embs.permute(1, 0, 2)\n",
    "        pos_encs = self.pos_encoder(embs)\n",
    "\n",
    "        seq_out = self.transf_decoder(pos_encs, node_decs)\n",
    "        #print(\"Seq out:\", seq_out.size())\n",
    "        \n",
    "        seq_out = self.lin(seq_out)\n",
    "        #print(\"Seq out after lin:\", seq_out.size())\n",
    "        \n",
    "        # Softmax on first 131 values (pitch), sigmoid on last 9 (dur)\n",
    "        #seq_out[:, :, :131] = F.log_softmax(seq_out[:, :, :131], dim=-1)\n",
    "        #seq_out[:, :, 131:] = torch.sigmoid(seq_out[:, :, 131:])\n",
    "        seq_out = seq_out.permute(1, 0, 2)\n",
    "        seq_out = seq_out.view(x_seq.size())\n",
    "        #print(\"Seq out after reshape\", seq_out.size())\n",
    "        \n",
    "\n",
    "        return seq_out, acts_out\n",
    "\n",
    "\n",
    "class VAE(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder()\n",
    "    \n",
    "    def forward(self, x_seq, x_acts, x_graph):\n",
    "        \n",
    "        mu, log_var = self.encoder(x_seq, x_acts, x_graph)\n",
    "        #print(\"Mu:\", mu.size())\n",
    "        #print(\"log_var:\", log_var.size())\n",
    "        \n",
    "        # Reparameterization trick\n",
    "        sigma = torch.exp(0.5*log_var)\n",
    "        eps = torch.randn_like(sigma)\n",
    "        #print(\"eps:\", eps.size())\n",
    "        z = mu + eps*sigma\n",
    "        \n",
    "        out = self.decoder(z, x_seq, x_acts, x_graph)\n",
    "        \n",
    "        return out, mu, log_var\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import uuid\n",
    "import copy\n",
    "\n",
    "\n",
    "class VAETrainer():\n",
    "    \n",
    "    def __init__(self, models_path, optimizer, init_lr, lr_scheduler=None, \n",
    "                 device=torch.device(\"cpu\"), print_every=1, save_every=1):\n",
    "        self.models_path = models_path\n",
    "        self.optimizer = optimizer\n",
    "        self.init_lr = init_lr\n",
    "        self.lr_scheduler = lr_scheduler\n",
    "        self.device = device\n",
    "        self.print_every = print_every\n",
    "        self.save_every = save_every\n",
    "        \n",
    "    \n",
    "    def train(self, model, trainloader, validloader=None, epochs=1, name=None):\n",
    "        \n",
    "        if name is None:\n",
    "            name = str(uuid.uuid4())\n",
    "        \n",
    "        path = os.path.join(models_path, name)\n",
    "        \n",
    "        n_batches = len(trainloader)\n",
    "                        \n",
    "        losses = []\n",
    "        acts_losses = []\n",
    "        pitches_losses = []\n",
    "        dur_losses = []\n",
    "        kld_losses = []\n",
    "        lrs = []\n",
    "        \n",
    "        ce = nn.CrossEntropyLoss()\n",
    "        bce = nn.BCEWithLogitsLoss()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        beta = 0\n",
    "        \n",
    "        model.train()\n",
    "        \n",
    "        print(\"Starting training.\\n\")\n",
    "        \n",
    "        progress_bar = tqdm(range(n_batches))\n",
    "        start = time.time()\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            \n",
    "            for batch_idx, (x_seq, x_acts, x_graph) in enumerate(trainloader):\n",
    "                \n",
    "                # Zero out the gradients\n",
    "                self.optimizer.zero_grad()\n",
    "                \n",
    "                # Get the inputs\n",
    "                x_seq = x_seq.float().to(self.device)\n",
    "                x_acts = x_acts.to(self.device)\n",
    "                x_graph = x_graph.to(self.device)\n",
    "\n",
    "                # Forward pass, get the reconstructions\n",
    "                out, mu, log_var = model(x_seq, x_acts, x_graph)\n",
    "                seq_rec, acts_rec = out\n",
    "                \n",
    "                # Compute the loss\n",
    "                acts_loss = bce(acts_rec.view(-1), x_acts.view(-1).float())\n",
    "                pitches_loss = ce(seq_rec.reshape(-1, seq_rec.size(-1))[:, :131],\n",
    "                                  x_seq.reshape(-1, x_seq.size(-1))[:, :131].argmax(dim=1))\n",
    "                dur_loss = bce(seq_rec[..., 131:].reshape(-1), \n",
    "                               x_seq[..., 131:].reshape(-1))\n",
    "                kld_loss = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "                rec_loss = pitches_loss + dur_loss + acts_loss\n",
    "                loss = rec_loss + beta*kld_loss\n",
    "                \n",
    "                # Compute gradients and update weights\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                if self.lr_scheduler is not None:\n",
    "                    self.lr_scheduler.step()\n",
    "                \n",
    "                losses.append(loss.item())\n",
    "                acts_losses.append(acts_loss.item())\n",
    "                pitches_losses.append(pitches_loss.item())\n",
    "                dur_losses.append(dur_loss.item())\n",
    "                kld_losses.append((beta*kld_loss).item())\n",
    "                last_lr = (self.lr_scheduler.get_last_lr() if self.lr_scheduler is not None\n",
    "                               else self.init_lr)\n",
    "                lrs.append(last_lr)\n",
    "                \n",
    "                running_loss += loss.item()\n",
    "\n",
    "                # Print training loss information\n",
    "                if (batch_idx + 1) % self.print_every == 0:\n",
    "                    print(\"Training on batch {}/{} of epoch {} complete.\"\n",
    "                          .format(batch_idx+1, n_batches, epoch+1))\n",
    "                    print(\"Tot_loss: {:.4f} acts_loss: {:.4f} \"\n",
    "                          .format(running_loss/self.print_every, acts_loss), end='')\n",
    "                    print(\"pitches_loss: {:.4f} dur_loss: {:.4f} kld_loss: {:.4f}\"\n",
    "                          .format(pitches_loss, dur_loss, kld_loss))\n",
    "                    print(\"----------------------------------------\")\n",
    "                    running_loss = 0.0\n",
    "                    \n",
    "                # When appropriate, save model and stats on disk\n",
    "                if self.save_every > 0 and (batch_idx + 1) % self.save_every == 0:\n",
    "                    print(\"\\nSaving model to disk...\\n\")\n",
    "                    torch.save({\n",
    "                        'epoch': epoch,\n",
    "                        'batch': batch_idx,\n",
    "                        'save_every': self.save_every,\n",
    "                        'lrs': lrs,\n",
    "                        'losses': losses,\n",
    "                        'acts_losses': acts_losses,\n",
    "                        'pitches_losses': pitches_losses,\n",
    "                        'dur_losses': dur_losses,\n",
    "                        'kld_losses': kld_losses,\n",
    "                        'model_state_dict': model.state_dict(),\n",
    "                        'optimizer_state_dict': self.optimizer.state_dict()\n",
    "                    }, path)\n",
    "                \n",
    "                progress_bar.update(1)\n",
    "                    \n",
    "                if batch_idx > 16:\n",
    "                    break\n",
    "            \n",
    "\n",
    "        end = time.time()\n",
    "        hours, rem = divmod(end-start, 3600)\n",
    "        minutes, seconds = divmod(rem, 60)\n",
    "        print(\"Training completed in (h:m:s): {:0>2}:{:0>2}:{:05.2f}\"\n",
    "                  .format(int(hours),int(minutes),seconds))\n",
    "        \n",
    "        print(\"Saving model to disk...\")\n",
    "        \n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'batch': batch_idx,\n",
    "            'save_every': self.save_every,\n",
    "            'lrs': lrs,\n",
    "            'losses': losses,\n",
    "            'acts_losses': acts_losses,\n",
    "            'pitches_losses': pitches_losses,\n",
    "            'dur_losses': dur_losses,\n",
    "            'kld_losses': kld_losses,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict()\n",
    "        }, path)\n",
    "        \n",
    "        print(\"Model saved.\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_path = \"models/\"\n",
    "os.makedirs(models_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5189"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_dir = \"data/preprocessed\"\n",
    "dataset = MIDIDataset(ds_dir)\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Current device idx: 1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.set_device(1)\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "#decive = torch.device(\"cpu\")\n",
    "print(\"Device:\", device)\n",
    "print(\"Current device idx:\", torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!rm models/vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the model and moving it to the specified device...\n",
      "Number of parameters: 6323468\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Starting training.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c847744de1b4da3ba4121c387df50ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/163 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on batch 1/163 of epoch 1 complete.\n",
      "Tot_loss: 6.5691 acts_loss: 0.7308 pitches_loss: 5.1305 dur_loss: 0.7078 kld_loss: 775.0526\n",
      "----------------------------------------\n",
      "Training on batch 2/163 of epoch 1 complete.\n",
      "Tot_loss: 6.4138 acts_loss: 0.7477 pitches_loss: 4.9690 dur_loss: 0.6972 kld_loss: 800.8081\n",
      "----------------------------------------\n",
      "Training on batch 3/163 of epoch 1 complete.\n",
      "Tot_loss: 6.3037 acts_loss: 0.7449 pitches_loss: 4.8685 dur_loss: 0.6903 kld_loss: 810.9001\n",
      "----------------------------------------\n",
      "\n",
      "Saving model to disk...\n",
      "\n",
      "Training on batch 4/163 of epoch 1 complete.\n",
      "Tot_loss: 6.2072 acts_loss: 0.7465 pitches_loss: 4.7661 dur_loss: 0.6945 kld_loss: 841.2460\n",
      "----------------------------------------\n",
      "Training on batch 5/163 of epoch 1 complete.\n",
      "Tot_loss: 6.0638 acts_loss: 0.7367 pitches_loss: 4.6512 dur_loss: 0.6759 kld_loss: 846.8110\n",
      "----------------------------------------\n",
      "Training on batch 6/163 of epoch 1 complete.\n",
      "Tot_loss: 5.9362 acts_loss: 0.7331 pitches_loss: 4.5318 dur_loss: 0.6713 kld_loss: 874.5565\n",
      "----------------------------------------\n",
      "\n",
      "Saving model to disk...\n",
      "\n",
      "Training on batch 7/163 of epoch 1 complete.\n",
      "Tot_loss: 5.8592 acts_loss: 0.7359 pitches_loss: 4.4567 dur_loss: 0.6666 kld_loss: 883.3382\n",
      "----------------------------------------\n",
      "Training on batch 8/163 of epoch 1 complete.\n",
      "Tot_loss: 5.6881 acts_loss: 0.7348 pitches_loss: 4.2941 dur_loss: 0.6593 kld_loss: 915.2643\n",
      "----------------------------------------\n",
      "Training on batch 9/163 of epoch 1 complete.\n",
      "Tot_loss: 5.6277 acts_loss: 0.7424 pitches_loss: 4.2334 dur_loss: 0.6519 kld_loss: 942.6115\n",
      "----------------------------------------\n",
      "\n",
      "Saving model to disk...\n",
      "\n",
      "Training on batch 10/163 of epoch 1 complete.\n",
      "Tot_loss: 5.4332 acts_loss: 0.7332 pitches_loss: 4.0550 dur_loss: 0.6449 kld_loss: 960.1237\n",
      "----------------------------------------\n",
      "Training on batch 11/163 of epoch 1 complete.\n",
      "Tot_loss: 5.3512 acts_loss: 0.7335 pitches_loss: 3.9823 dur_loss: 0.6355 kld_loss: 989.7944\n",
      "----------------------------------------\n",
      "Training on batch 12/163 of epoch 1 complete.\n",
      "Tot_loss: 5.2512 acts_loss: 0.7360 pitches_loss: 3.8861 dur_loss: 0.6291 kld_loss: 1010.9086\n",
      "----------------------------------------\n",
      "\n",
      "Saving model to disk...\n",
      "\n",
      "Training on batch 13/163 of epoch 1 complete.\n",
      "Tot_loss: 5.1575 acts_loss: 0.7393 pitches_loss: 3.7892 dur_loss: 0.6291 kld_loss: 1035.9622\n",
      "----------------------------------------\n",
      "Training on batch 14/163 of epoch 1 complete.\n",
      "Tot_loss: 5.0082 acts_loss: 0.7345 pitches_loss: 3.6547 dur_loss: 0.6189 kld_loss: 1075.1157\n",
      "----------------------------------------\n",
      "Training on batch 15/163 of epoch 1 complete.\n",
      "Tot_loss: 4.8854 acts_loss: 0.7314 pitches_loss: 3.5400 dur_loss: 0.6140 kld_loss: 1117.8092\n",
      "----------------------------------------\n",
      "\n",
      "Saving model to disk...\n",
      "\n",
      "Training on batch 16/163 of epoch 1 complete.\n",
      "Tot_loss: 4.7735 acts_loss: 0.7292 pitches_loss: 3.4360 dur_loss: 0.6083 kld_loss: 1141.0176\n",
      "----------------------------------------\n",
      "Training on batch 17/163 of epoch 1 complete.\n",
      "Tot_loss: 4.6666 acts_loss: 0.7325 pitches_loss: 3.3278 dur_loss: 0.6064 kld_loss: 1158.0435\n",
      "----------------------------------------\n",
      "Training on batch 18/163 of epoch 1 complete.\n",
      "Tot_loss: 4.5701 acts_loss: 0.7364 pitches_loss: 3.2373 dur_loss: 0.5964 kld_loss: 1204.2712\n",
      "----------------------------------------\n",
      "\n",
      "Saving model to disk...\n",
      "\n",
      "Training completed in (h:m:s): 00:00:09.00\n",
      "Saving model to disk...\n",
      "Model saved.\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating the model and moving it to the specified device...\")\n",
    "\n",
    "vae = VAE().to(device)\n",
    "\n",
    "print(\"Number of parameters:\", sum(p.numel() for p in vae.parameters()))\n",
    "print()\n",
    "\n",
    "init_lr = 1e-5\n",
    "gamma = 0.999\n",
    "optimizer = optim.Adam(vae.parameters(), lr=init_lr)\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma)\n",
    "\n",
    "print('--------------------------------------------------\\n')\n",
    "\n",
    "trainer = VAETrainer(models_path, optimizer, init_lr, save_every=3, device=device)\n",
    "trainer.train(vae, loader, name='vae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.load('models/vae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7ff271578ed0>"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 248,
       "width": 362
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1, len(m['losses'])+1), m['losses'], label='Loss')\n",
    "plt.plot(range(1, len(m['acts_losses'])+1), m['acts_losses'], label='acts')\n",
    "plt.plot(range(1, len(m['pitches_losses'])+1), m['pitches_losses'], label='pitches')\n",
    "plt.plot(range(1, len(m['dur_losses'])+1), m['dur_losses'], label='dur')\n",
    "plt.plot(range(1, len(m['kld_losses'])+1), m['kld_losses'], label='kld')\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KTFN-DCJjZWM"
   },
   "source": [
    "# Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4sSvVK7CxjV8"
   },
   "outputs": [],
   "source": [
    "from typing import Optional, Union, Tuple\n",
    "from torch_geometric.typing import OptTensor, Adj\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Parameter as Param\n",
    "from torch.nn import Parameter\n",
    "from torch_scatter import scatter\n",
    "from torch_sparse import SparseTensor, matmul, masked_select_nnz\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "\n",
    "from torch_geometric.nn.inits import glorot, zeros\n",
    "\n",
    "\n",
    "@torch.jit._overload\n",
    "def masked_edge_index(edge_index, edge_mask):\n",
    "    # type: (Tensor, Tensor) -> Tensor\n",
    "    pass\n",
    "\n",
    "\n",
    "@torch.jit._overload\n",
    "def masked_edge_index(edge_index, edge_mask):\n",
    "    # type: (SparseTensor, Tensor) -> SparseTensor\n",
    "    pass\n",
    "\n",
    "\n",
    "def masked_edge_index(edge_index, edge_mask):\n",
    "    if isinstance(edge_index, Tensor):\n",
    "        return edge_index[:, edge_mask]\n",
    "    else:\n",
    "        return masked_select_nnz(edge_index, edge_mask, layout='coo')\n",
    "\n",
    "\n",
    "class RGCNConv(MessagePassing):\n",
    "    r\"\"\"The relational graph convolutional operator from the `\"Modeling\n",
    "    Relational Data with Graph Convolutional Networks\"\n",
    "    <https://arxiv.org/abs/1703.06103>`_ paper\n",
    "\n",
    "    .. math::\n",
    "        \\mathbf{x}^{\\prime}_i = \\mathbf{\\Theta}_{\\textrm{root}} \\cdot\n",
    "        \\mathbf{x}_i + \\sum_{r \\in \\mathcal{R}} \\sum_{j \\in \\mathcal{N}_r(i)}\n",
    "        \\frac{1}{|\\mathcal{N}_r(i)|} \\mathbf{\\Theta}_r \\cdot \\mathbf{x}_j,\n",
    "\n",
    "    where :math:`\\mathcal{R}` denotes the set of relations, *i.e.* edge types.\n",
    "    Edge type needs to be a one-dimensional :obj:`torch.long` tensor which\n",
    "    stores a relation identifier\n",
    "    :math:`\\in \\{ 0, \\ldots, |\\mathcal{R}| - 1\\}` for each edge.\n",
    "\n",
    "    .. note::\n",
    "        This implementation is as memory-efficient as possible by iterating\n",
    "        over each individual relation type.\n",
    "        Therefore, it may result in low GPU utilization in case the graph has a\n",
    "        large number of relations.\n",
    "        As an alternative approach, :class:`FastRGCNConv` does not iterate over\n",
    "        each individual type, but may consume a large amount of memory to\n",
    "        compensate.\n",
    "        We advise to check out both implementations to see which one fits your\n",
    "        needs.\n",
    "\n",
    "    Args:\n",
    "        in_channels (int or tuple): Size of each input sample. A tuple\n",
    "            corresponds to the sizes of source and target dimensionalities.\n",
    "            In case no input features are given, this argument should\n",
    "            correspond to the number of nodes in your graph.\n",
    "        out_channels (int): Size of each output sample.\n",
    "        num_relations (int): Number of relations.\n",
    "        num_bases (int, optional): If set to not :obj:`None`, this layer will\n",
    "            use the basis-decomposition regularization scheme where\n",
    "            :obj:`num_bases` denotes the number of bases to use.\n",
    "            (default: :obj:`None`)\n",
    "        num_blocks (int, optional): If set to not :obj:`None`, this layer will\n",
    "            use the block-diagonal-decomposition regularization scheme where\n",
    "            :obj:`num_blocks` denotes the number of blocks to use.\n",
    "            (default: :obj:`None`)\n",
    "        aggr (string, optional): The aggregation scheme to use\n",
    "            (:obj:`\"add\"`, :obj:`\"mean\"`, :obj:`\"max\"`).\n",
    "            (default: :obj:`\"mean\"`)\n",
    "        root_weight (bool, optional): If set to :obj:`False`, the layer will\n",
    "            not add transformed root node features to the output.\n",
    "            (default: :obj:`True`)\n",
    "        bias (bool, optional): If set to :obj:`False`, the layer will not learn\n",
    "            an additive bias. (default: :obj:`True`)\n",
    "        **kwargs (optional): Additional arguments of\n",
    "            :class:`torch_geometric.nn.conv.MessagePassing`.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: Union[int, Tuple[int, int]],\n",
    "        out_channels: int,\n",
    "        num_relations: int,\n",
    "        num_bases: Optional[int] = None,\n",
    "        num_blocks: Optional[int] = None,\n",
    "        aggr: str = 'mean',\n",
    "        root_weight: bool = True,\n",
    "        bias: bool = True,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(aggr=aggr, node_dim=0, **kwargs)\n",
    "\n",
    "        if num_bases is not None and num_blocks is not None:\n",
    "            raise ValueError('Can not apply both basis-decomposition and '\n",
    "                             'block-diagonal-decomposition at the same time.')\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.num_relations = num_relations\n",
    "        self.num_bases = num_bases\n",
    "        self.num_blocks = num_blocks\n",
    "\n",
    "        if isinstance(in_channels, int):\n",
    "            in_channels = (in_channels, in_channels)\n",
    "        self.in_channels_l = in_channels[0]\n",
    "\n",
    "        if num_bases is not None:\n",
    "            self.weight = Parameter(\n",
    "                torch.Tensor(num_bases, in_channels[0], out_channels))\n",
    "            self.comp = Parameter(torch.Tensor(num_relations, num_bases))\n",
    "\n",
    "        elif num_blocks is not None:\n",
    "            assert (in_channels[0] % num_blocks == 0\n",
    "                    and out_channels % num_blocks == 0)\n",
    "            self.weight = Parameter(\n",
    "                torch.Tensor(num_relations, num_blocks,\n",
    "                             in_channels[0] // num_blocks,\n",
    "                             out_channels // num_blocks))\n",
    "            self.register_parameter('comp', None)\n",
    "\n",
    "        else:\n",
    "            self.weight = Parameter(\n",
    "                torch.Tensor(num_relations, in_channels[0], out_channels))\n",
    "            self.register_parameter('comp', None)\n",
    "\n",
    "        if root_weight:\n",
    "            self.root = Param(torch.Tensor(in_channels[1], out_channels))\n",
    "        else:\n",
    "            self.register_parameter('root', None)\n",
    "\n",
    "        if bias:\n",
    "            self.bias = Param(torch.Tensor(out_channels))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        glorot(self.weight)\n",
    "        glorot(self.comp)\n",
    "        glorot(self.root)\n",
    "        zeros(self.bias)\n",
    "\n",
    "\n",
    "    def forward(self, x: Union[OptTensor, Tuple[OptTensor, Tensor]],\n",
    "                edge_index: Adj, edge_type: OptTensor = None):\n",
    "        r\"\"\"\n",
    "        Args:\n",
    "            x: The input node features. Can be either a :obj:`[num_nodes,\n",
    "                in_channels]` node feature matrix, or an optional\n",
    "                one-dimensional node index tensor (in which case input features\n",
    "                are treated as trainable node embeddings).\n",
    "                Furthermore, :obj:`x` can be of type :obj:`tuple` denoting\n",
    "                source and destination node features.\n",
    "            edge_type: The one-dimensional relation type/index for each edge in\n",
    "                :obj:`edge_index`.\n",
    "                Should be only :obj:`None` in case :obj:`edge_index` is of type\n",
    "                :class:`torch_sparse.tensor.SparseTensor`.\n",
    "                (default: :obj:`None`)\n",
    "        \"\"\"\n",
    "\n",
    "        # Convert input features to a pair of node features or node indices.\n",
    "        x_l: OptTensor = None\n",
    "        if isinstance(x, tuple):\n",
    "            x_l = x[0]\n",
    "        else:\n",
    "            x_l = x\n",
    "        if x_l is None:\n",
    "            x_l = torch.arange(self.in_channels_l, device=self.weight.device)\n",
    "\n",
    "        x_r: Tensor = x_l\n",
    "        if isinstance(x, tuple):\n",
    "            x_r = x[1]\n",
    "\n",
    "        size = (x_l.size(0), x_r.size(0))\n",
    "\n",
    "        if isinstance(edge_index, SparseTensor):\n",
    "            edge_type = edge_index.storage.value()\n",
    "        assert edge_type is not None\n",
    "\n",
    "        # propagate_type: (x: Tensor)\n",
    "        out = torch.zeros(x_r.size(0), self.out_channels, device=x_r.device)\n",
    "\n",
    "        weight = self.weight\n",
    "        if self.num_bases is not None:  # Basis-decomposition =================\n",
    "            weight = (self.comp @ weight.view(self.num_bases, -1)).view(\n",
    "                self.num_relations, self.in_channels_l, self.out_channels)\n",
    "\n",
    "        if self.num_blocks is not None:  # Block-diagonal-decomposition =====\n",
    "\n",
    "            if x_l.dtype == torch.long and self.num_blocks is not None:\n",
    "                raise ValueError('Block-diagonal decomposition not supported '\n",
    "                                 'for non-continuous input features.')\n",
    "\n",
    "            for i in range(self.num_relations):\n",
    "                tmp = masked_edge_index(edge_index, edge_type == i)\n",
    "                h = self.propagate(tmp, x=x_l, size=size)\n",
    "                h = h.view(-1, weight.size(1), weight.size(2))\n",
    "                h = torch.einsum('abc,bcd->abd', h, weight[i])\n",
    "                out += h.contiguous().view(-1, self.out_channels)\n",
    "\n",
    "        else:  # No regularization/Basis-decomposition ========================\n",
    "            for i in range(self.num_relations):\n",
    "                tmp = masked_edge_index(edge_index, edge_type == i)\n",
    "\n",
    "                if x_l.dtype == torch.long:\n",
    "                    out += self.propagate(tmp, x=weight[i, x_l], size=size)\n",
    "                else:\n",
    "                    h = self.propagate(tmp, x=x_l, size=size)\n",
    "                    out = out + (h @ weight[i])\n",
    "\n",
    "        root = self.root\n",
    "        if root is not None:\n",
    "            out += root[x_r] if x_r.dtype == torch.long else x_r @ root\n",
    "\n",
    "        if self.bias is not None:\n",
    "            out += self.bias\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "    def message(self, x_j: Tensor) -> Tensor:\n",
    "        return x_j\n",
    "\n",
    "    def message_and_aggregate(self, adj_t: SparseTensor, x: Tensor) -> Tensor:\n",
    "        adj_t = adj_t.set_value(None, layout=None)\n",
    "        return matmul(adj_t, x, reduce=self.aggr)\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return (f'{self.__class__.__name__}({self.in_channels}, '\n",
    "                f'{self.out_channels}, num_relations={self.num_relations})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hfsNpMLrEXLk"
   },
   "source": [
    "next edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2DaVTonr_XB8",
    "outputId": "9e5fa8f9-604e-4273-a34d-fad73ad9ab7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 1 1]\n",
      " [1 1 1 1]\n",
      " [1 1 0 0]\n",
      " [1 1 1 1]\n",
      " [0 1 0 1]\n",
      " [1 0 0 0]\n",
      " [1 1 1 0]\n",
      " [0 0 0 0]]\n",
      "[[ 0  8 16 24]\n",
      " [ 1  9 17 25]\n",
      " [ 2 10 18 26]\n",
      " [ 3 11 19 27]\n",
      " [ 4 12 20 28]\n",
      " [ 5 13 21 29]\n",
      " [ 6 14 22 30]\n",
      " [ 7 15 23 31]]\n",
      "[(8, 1, 1), (8, 17, 1), (8, 25, 1), (16, 1, 1), (16, 9, 1), (16, 25, 1), (24, 1, 1), (24, 9, 1), (24, 17, 1), (1, 10, 1), (9, 2, 1), (17, 2, 1), (17, 10, 1), (25, 2, 1), (25, 10, 1), (2, 11, 1), (2, 19, 1), (2, 27, 1), (10, 3, 1), (10, 19, 1), (10, 27, 1), (3, 12, 1), (3, 28, 1), (11, 28, 1), (19, 12, 1), (19, 28, 1), (27, 12, 1), (12, 5, 1), (28, 5, 1), (5, 14, 1), (5, 22, 1)]\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "a = np.random.randint(2, size=(4,8))\n",
    "a_t = a.transpose()\n",
    "print(a_t)\n",
    "inds = np.stack(np.where(a_t == 1)).transpose()\n",
    "ts_acts = np.any(a_t, axis=1)\n",
    "ts_inds = np.where(ts_acts)[0]\n",
    "\n",
    "labels = np.arange(32).reshape(4, 8).transpose()\n",
    "print(labels)\n",
    "\n",
    "next_edges = []\n",
    "for i in range(len(ts_inds)-1):\n",
    "    ind_s = ts_inds[i]\n",
    "    ind_e = ts_inds[i+1]\n",
    "    s = inds[inds[:,0] == ind_s]\n",
    "    e = inds[inds[:,0] == ind_e]\n",
    "    e_inds = [t for t in list(itertools.product(s, e)) if t[0][1] != t[1][1]]\n",
    "    edges = [(labels[tuple(e[0])],labels[tuple(e[1])], ind_e-ind_s) for e in e_inds]\n",
    "    next_edges.extend(edges)\n",
    "\n",
    "print(next_edges)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lJ5JQm1aEbmb"
   },
   "source": [
    "onset edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DISmsJB3EatR",
    "outputId": "fc864608-63a6-4ad0-84d9-1478001ce60e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 1 1]\n",
      " [1 1 1 1]\n",
      " [1 1 0 0]\n",
      " [1 1 1 1]\n",
      " [0 1 0 1]\n",
      " [1 0 0 0]\n",
      " [1 1 1 0]\n",
      " [0 0 0 0]]\n",
      "[[ 0  8 16 24]\n",
      " [ 1  9 17 25]\n",
      " [ 2 10 18 26]\n",
      " [ 3 11 19 27]\n",
      " [ 4 12 20 28]\n",
      " [ 5 13 21 29]\n",
      " [ 6 14 22 30]\n",
      " [ 7 15 23 31]]\n",
      "[(8, 16, 0), (8, 24, 0), (16, 24, 0), (16, 8, 0), (24, 8, 0), (24, 16, 0), (1, 9, 0), (1, 17, 0), (1, 25, 0), (9, 17, 0), (9, 25, 0), (17, 25, 0), (9, 1, 0), (17, 1, 0), (25, 1, 0), (17, 9, 0), (25, 9, 0), (25, 17, 0), (2, 10, 0), (10, 2, 0), (3, 11, 0), (3, 19, 0), (3, 27, 0), (11, 19, 0), (11, 27, 0), (19, 27, 0), (11, 3, 0), (19, 3, 0), (27, 3, 0), (19, 11, 0), (27, 11, 0), (27, 19, 0), (12, 28, 0), (28, 12, 0), (6, 14, 0), (6, 22, 0), (14, 22, 0), (14, 6, 0), (22, 6, 0), (22, 14, 0)]\n"
     ]
    }
   ],
   "source": [
    "onset_edges = []\n",
    "print(a_t)\n",
    "print(labels)\n",
    "\n",
    "for i in ts_inds:\n",
    "    ts_acts_inds = list(inds[inds[:,0] == i])\n",
    "    if len(ts_acts_inds) < 2:\n",
    "        continue\n",
    "    e_inds = list(itertools.combinations(ts_acts_inds, 2))\n",
    "    edges = [(labels[tuple(e[0])], labels[tuple(e[1])], 0) for e in e_inds]\n",
    "    inv_edges = [(e[1], e[0], *e[2:]) for e in edges]\n",
    "    onset_edges.extend(edges)\n",
    "    onset_edges.extend(inv_edges)\n",
    "\n",
    "print(onset_edges)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ujitZCKaa7nu"
   },
   "source": [
    "track edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NbVG1vdFa-7e",
    "outputId": "c042449b-eef2-4707-a524-5f66f3ec07c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 1]\n",
      " [1 0 0 1]\n",
      " [0 1 0 0]\n",
      " [0 0 0 0]\n",
      " [1 1 0 0]\n",
      " [0 0 1 1]\n",
      " [0 0 1 0]\n",
      " [0 0 1 1]]\n",
      "[[ 0  8 16 24]\n",
      " [ 1  9 17 25]\n",
      " [ 2 10 18 26]\n",
      " [ 3 11 19 27]\n",
      " [ 4 12 20 28]\n",
      " [ 5 13 21 29]\n",
      " [ 6 14 22 30]\n",
      " [ 7 15 23 31]]\n",
      "[(array([0, 0]), array([1, 0])), (array([1, 0]), array([4, 0]))]\n",
      "[(array([0, 1]), array([2, 1])), (array([2, 1]), array([4, 1]))]\n",
      "[(array([0, 2]), array([5, 2])), (array([5, 2]), array([6, 2])), (array([6, 2]), array([7, 2]))]\n",
      "[(array([0, 3]), array([1, 3])), (array([1, 3]), array([5, 3])), (array([5, 3]), array([7, 3]))]\n",
      "[(0, 1, 1), (1, 4, 3), (8, 10, 2), (10, 12, 2), (16, 21, 5), (21, 22, 1), (22, 23, 1), (24, 25, 1), (25, 29, 4), (29, 31, 2)]\n"
     ]
    }
   ],
   "source": [
    "print(a_t)\n",
    "print(labels)\n",
    "track_edges = []\n",
    "\n",
    "for track in range(a_t.shape[1]):\n",
    "    tr_inds = list(inds[inds[:,1] == track])\n",
    "    e_inds = [(tr_inds[i],\n",
    "               tr_inds[i+1]) for i in range(len(tr_inds)-1)]\n",
    "    print(e_inds)\n",
    "    edges = [(labels[tuple(e[0])], labels[tuple(e[1])], e[1][0]-e[0][0]) for e in e_inds]\n",
    "    track_edges.extend(edges)\n",
    "\n",
    "print(track_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8DzouJ5NqALB",
    "outputId": "20a76e82-6305-4154-d894-6d69a64435a1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 3)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "track_edges = np.array(track_edges)\n",
    "onset_edges = np.array(onset_edges)\n",
    "np.concatenate((track_edges, onset_edges)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ihIYkPWPzyGX"
   },
   "outputs": [],
   "source": [
    "pip install pypianoroll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ie0pU8NWAUNM"
   },
   "outputs": [],
   "source": [
    "import pypianoroll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QTbGBSrdAZGH"
   },
   "outputs": [],
   "source": [
    "multitrack = pypianoroll.read(\"tests_fur-elise.mid\")\n",
    "print(multitrack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3eVo_BKzAmz4"
   },
   "outputs": [],
   "source": [
    "multitrack.tracks[0].pianoroll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PPpWw-rLA7CI"
   },
   "outputs": [],
   "source": [
    "multitrack.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x-PYbS7FA-Gg"
   },
   "outputs": [],
   "source": [
    "multitrack.trim(0, 12 * multitrack.resolution)\n",
    "multitrack.binarize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "psxuoTsZBFXY"
   },
   "outputs": [],
   "source": [
    "multitrack.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ovyixmSvBG3w"
   },
   "outputs": [],
   "source": [
    "multitrack.tracks[0].pianoroll.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wHlKNufuBzLn"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOhjCOJb34P4bTid7qFDg58",
   "collapsed_sections": [],
   "include_colab_link": true,
   "mount_file_id": "1NeVldMsPVJd6pXbxZDmuiUP-QJBRhYtj",
   "name": "midi.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
