{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/EmanueleCosenza/Polyphemus/blob/main/midi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "50lpUn9bO0ug",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/cosenza/thesis/Polyphemus\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraries installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!tar -C data -xvzf data/lmd_matched.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "She0QbN5Kopo",
    "outputId": "0f3fb4c7-bd7d-4ee4-b2cd-d567d8e490db",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Install the required music libraries\n",
    "#!pip3 install muspy\n",
    "#!pip3 install pypianoroll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3uveQkY7O0CF",
    "outputId": "12e1f638-ee78-4617-844a-10e9a26c298e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Install torch_geometric\n",
    "#!v=$(python3 -c \"import torch; print(torch.__version__)\"); \\\n",
    "#pip3 install torch-scatter -f https://data.pyg.org/whl/torch-${v}.html; \\\n",
    "#pip3 install torch-sparse -f https://data.pyg.org/whl/torch-${v}.html; \\\n",
    "#pip3 install torch-geometric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import os\n",
    "\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "seed = 42\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "B45l1513wJ1Q"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import muspy\n",
    "from itertools import product\n",
    "import pypianoroll as pproll\n",
    "import time\n",
    "\n",
    "\n",
    "class MIDIPreprocessor():\n",
    "    \n",
    "    def __init__():\n",
    "        pass\n",
    "\n",
    "    def preprocess_dataset(self, dir, early_exit=None):\n",
    "        pass\n",
    "    \n",
    "    def preprocess_file(self, f):\n",
    "        pass\n",
    "\n",
    "\n",
    "# Todo: to config file (or separate files)\n",
    "MAX_SIMU_NOTES = 16 # 14 + SOS and EOS\n",
    "\n",
    "PITCH_SOS = 128\n",
    "PITCH_EOS = 129\n",
    "PITCH_PAD = 130\n",
    "DUR_PAD_IND = 2\n",
    "MAX_DUR = 511 # equivalent to 16 bars (with RESOLUTION=32)\n",
    "\n",
    "RESOLUTION = 32\n",
    "NUM_BARS = 1\n",
    "\n",
    "\n",
    "def preprocess_file(filepath, dest_dir, num_samples):\n",
    "\n",
    "    saved_samples = 0\n",
    "\n",
    "    print()\n",
    "    print(\"Preprocessing file \" + filepath)\n",
    "\n",
    "    # Load the file both as a pypianoroll song and a muspy song\n",
    "    # (Need to load both since muspy.to_pypianoroll() is expensive)\n",
    "    try:\n",
    "        pproll_song = pproll.read(filepath, resolution=RESOLUTION)\n",
    "        muspy_song = muspy.read(filepath)\n",
    "    except Exception as e:\n",
    "        print(\"Song skipped (Invalid song format)\")\n",
    "        return 0\n",
    "    \n",
    "    # Only accept songs that have a time signature of 4/4 and no time changes\n",
    "    for t in muspy_song.time_signatures:\n",
    "        if t.numerator != 4 or t.denominator != 4:\n",
    "            print(\"Song skipped ({}/{} time signature)\".\n",
    "                            format(t.numerator, t.denominator))\n",
    "            return 0\n",
    "\n",
    "    # Gather tracks of pypianoroll song based on MIDI program number\n",
    "    drum_tracks = []\n",
    "    bass_tracks = []\n",
    "    guitar_tracks = []\n",
    "    strings_tracks = []\n",
    "\n",
    "    for track in pproll_song.tracks:\n",
    "        if track.is_drum:\n",
    "            track.name = 'Drums'\n",
    "            drum_tracks.append(track)\n",
    "        elif 0 <= track.program <= 31:\n",
    "            track.name = 'Guitar'\n",
    "            guitar_tracks.append(track)\n",
    "        elif 32 <= track.program <= 39:\n",
    "            track.name = 'Bass'\n",
    "            bass_tracks.append(track)\n",
    "        else:\n",
    "            # Tracks with program > 39 are all considered as strings tracks\n",
    "            # and will be merged into a single track later on\n",
    "            strings_tracks.append(track)\n",
    "\n",
    "    # Filter song if it does not contain drum, guitar, bass or strings tracks\n",
    "    if not drum_tracks or not guitar_tracks \\\n",
    "       or not bass_tracks or not strings_tracks:\n",
    "        print(\"Song skipped (does not contain drum or \"\n",
    "                \"guitar or bass or strings tracks)\")\n",
    "        return 0\n",
    "    \n",
    "    # Merge strings tracks into a single pypianoroll track\n",
    "    strings = pproll.Multitrack(tracks=strings_tracks)\n",
    "    strings_track = pproll.Track(pianoroll=strings.blend(mode='max'),\n",
    "                                 program=48, name='Strings')\n",
    "\n",
    "    combinations = list(product(drum_tracks, bass_tracks, guitar_tracks))\n",
    "\n",
    "    # Single instruments can have multiple tracks.\n",
    "    # Consider all possible combinations of drum, bass, and guitar tracks\n",
    "    for i, combination in enumerate(combinations):\n",
    "\n",
    "        print(\"Processing combination\", i+1, \"of\", len(combinations))\n",
    "        \n",
    "        # Process combination (called 'subsong' from now on)\n",
    "        drum_track, bass_track, guitar_track = combination\n",
    "        tracks = [drum_track, bass_track, guitar_track, strings_track]\n",
    "        \n",
    "        pproll_subsong = pproll.Multitrack(\n",
    "            tracks=tracks,\n",
    "            tempo=pproll_song.tempo,\n",
    "            resolution=RESOLUTION\n",
    "        )\n",
    "        muspy_subsong = muspy.from_pypianoroll(pproll_subsong)\n",
    "        \n",
    "        tracks_notes = [track.notes for track in muspy_subsong.tracks]\n",
    "        \n",
    "        # Obtain length of subsong (maximum of each track's length)\n",
    "        length = 0\n",
    "        for notes in tracks_notes:\n",
    "            track_length = max(note.end for note in notes)\n",
    "            length = max(length, track_length)\n",
    "        length += 1\n",
    "\n",
    "        # Add timesteps until length is a multiple of RESOLUTION\n",
    "        length = length if length%(RESOLUTION) == 0 \\\n",
    "                                else length + (RESOLUTION-(length%(RESOLUTION)))\n",
    "\n",
    "\n",
    "        tracks_tensors = []\n",
    "        tracks_activations = []\n",
    "\n",
    "        dur_bin_length = int(np.ceil(np.log2(MAX_DUR)))\n",
    "\n",
    "        # Todo: adapt to velocity\n",
    "        for notes in tracks_notes:\n",
    "\n",
    "            # Initialize encoder-ready track tensor\n",
    "            # track_tensor: (length x max_simu_notes x 2 (or 3 if velocity))\n",
    "            # The last dimension contains pitches and durations (and velocities)\n",
    "            # int16 is enough for small to medium duration values\n",
    "            track_tensor = np.zeros((length, MAX_SIMU_NOTES, 2), np.int16)\n",
    "\n",
    "            track_tensor[:, :, 0] = PITCH_PAD\n",
    "            track_tensor[:, 0, 0] = PITCH_SOS\n",
    "\n",
    "            # Keeps track of how many notes have been stored in each timestep\n",
    "            # (int8 imposes that MAX_SIMU_NOTES < 256)\n",
    "            notes_counter = np.ones(length, dtype=np.int8)\n",
    "\n",
    "            # Todo: np.put_along_axis?\n",
    "            for note in notes:\n",
    "                # Insert note in the lowest position available in the timestep\n",
    "                \n",
    "                t = note.time\n",
    "\n",
    "                if notes_counter[t] >= MAX_SIMU_NOTES-1:\n",
    "                    # Skip note if there is no more space\n",
    "                    continue\n",
    "\n",
    "                track_tensor[t, notes_counter[t], 0] = note.pitch\n",
    "                track_tensor[t, notes_counter[t], 1] = note.duration\n",
    "                notes_counter[t] += 1\n",
    "            \n",
    "            # Add end of sequence token\n",
    "            track_tensor[np.arange(0, length), notes_counter, 0] = PITCH_EOS\n",
    "\n",
    "            # Get track activations, a boolean tensor indicating whether notes\n",
    "            # are being played in a timestep (sustain does not count)\n",
    "            # (needed for graph rep.)\n",
    "            activations = np.array(notes_counter-1, dtype=bool)\n",
    "\n",
    "            tracks_tensors.append(track_tensor)\n",
    "            tracks_activations.append(activations)\n",
    "        \n",
    "        # (#tracks x length x max_simu_notes x 2 (or 3))\n",
    "        subsong_tensor = np.stack(tracks_tensors, axis=0)\n",
    "\n",
    "        # (#tracks x length)\n",
    "        subsong_activations = np.stack(tracks_activations, axis=0)\n",
    "\n",
    "\n",
    "        # Slide window over 'subsong_tensor' and 'subsong_activations' along the\n",
    "        # time axis (2nd dimension) with the stride of a bar\n",
    "        # Todo: np.lib.stride_tricks.as_strided(song_proll)\n",
    "        for i in range(0, length-NUM_BARS*RESOLUTION+1, RESOLUTION):\n",
    "            \n",
    "            # Get the sequence and its activations\n",
    "            seq_tensor = subsong_tensor[:, i:i+NUM_BARS*RESOLUTION, :]\n",
    "            seq_acts = subsong_activations[:, i:i+NUM_BARS*RESOLUTION]\n",
    "\n",
    "            # Skip sequence if it contains more than one bar of consecutive\n",
    "            # silence in at least one track\n",
    "            bars = seq_acts.reshape(seq_acts.shape[0], NUM_BARS, -1)\n",
    "            bars_acts = np.any(bars, axis=2)\n",
    "            \n",
    "            if 1 in np.diff(np.where(bars_acts == 0)[1]):\n",
    "                continue\n",
    "\n",
    "            # Randomly transpose the pitches of the sequence (-5 to 6 semitones)\n",
    "            shift = np.random.choice(np.arange(-5, 7), 1)\n",
    "            cond = (seq_tensor[:, :, :, 0] != PITCH_PAD) &                     \\\n",
    "                   (seq_tensor[:, :, :, 0] != PITCH_SOS) &                     \\\n",
    "                   (seq_tensor[:, :, :, 0] != PITCH_EOS)\n",
    "            seq_tensor[cond, 0] += shift\n",
    "\n",
    "            # Save sample (seq_tensor and seq_acts) to file\n",
    "            curr_sample = str(num_samples + saved_samples)\n",
    "            sample_filepath = os.path.join(dest_dir, curr_sample)\n",
    "            np.savez(sample_filepath, seq_tensor=seq_tensor, seq_acts=seq_acts)\n",
    "\n",
    "            saved_samples += 1\n",
    "\n",
    "\n",
    "    print(\"File preprocessing finished. Saved samples:\", saved_samples)\n",
    "    print()\n",
    "\n",
    "    return saved_samples\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Total number of files: 116189\n",
    "# Number of unique files: 45129\n",
    "def preprocess_dataset(dataset_dir, dest_dir, early_exit=None):\n",
    "\n",
    "    files_dict = {}\n",
    "    seen = 0\n",
    "    tot_samples = 0\n",
    "    finished = False\n",
    "\n",
    "    # Visit recursively the directories inside the dataset directory\n",
    "    for dirpath, dirs, files in os.walk(dataset_dir):\n",
    "\n",
    "        # Sort alphabetically the found directories\n",
    "        # (to help guess the remaining time) \n",
    "        dirs.sort()\n",
    "        \n",
    "        print(\"Current path:\", dirpath)\n",
    "\n",
    "        for f in files:\n",
    "            \n",
    "            seen += 1\n",
    "\n",
    "            if f in files_dict:\n",
    "                # Skip already seen file\n",
    "                files_dict[f] += 1\n",
    "                continue\n",
    "\n",
    "            # File never seen before, add to dictionary of files\n",
    "            # (from filename to # of occurrences)\n",
    "            files_dict[f] = 1\n",
    "\n",
    "            # Preprocess file\n",
    "            filepath = os.path.join(dirpath, f)\n",
    "            saved = preprocess_file(filepath, dest_dir, tot_samples)\n",
    "\n",
    "            tot_samples += saved\n",
    "\n",
    "            # Exit when a maximum number of files has been processed (if set)\n",
    "            if early_exit != None and len(files_dict) >= early_exit:\n",
    "                finished = True\n",
    "                break\n",
    "\n",
    "        # Todo: also print # of processed (not filtered) files\n",
    "        #       and # of produced sequences (samples)\n",
    "        print(\"Total number of seen files:\", seen)\n",
    "        print(\"Number of unique files:\", len(files_dict))\n",
    "        print(\"Total number of saved samples:\", tot_samples)\n",
    "        print()\n",
    "\n",
    "        if finished:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "aYc5y-CYyetK"
   },
   "outputs": [],
   "source": [
    "#!rm -rf data/preprocessed/\n",
    "#!mkdir data/preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xqnubg3oP4ES",
    "outputId": "40cc38a2-1f7d-4f6f-e6c9-9e14dfc7f683",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_dir = 'data/lmd_matched'\n",
    "dest_dir = 'data/preprocessed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess_dataset(dataset_dir, dest_dir, early_exit=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RG88mekfrrcp"
   },
   "source": [
    "Check preprocessed data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "JlP6iUNugNtP"
   },
   "outputs": [],
   "source": [
    "filepath = os.path.join(dest_dir, \"5.npz\")\n",
    "data = np.load(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3VUpOEObhwYQ",
    "outputId": "aac6e029-93b1-485f-f13a-2a00abedbc7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 32, 16, 2)\n",
      "(4, 32)\n"
     ]
    }
   ],
   "source": [
    "print(data[\"seq_tensor\"].shape)\n",
    "print(data[\"seq_acts\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A6NA5IAAmtK8",
    "outputId": "6e661b3a-05a1-4e2d-9a3d-e1c037b4d04f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[128,   0],\n",
       "       [129,   0],\n",
       "       [130,   0],\n",
       "       [130,   0],\n",
       "       [130,   0],\n",
       "       [130,   0],\n",
       "       [130,   0],\n",
       "       [130,   0],\n",
       "       [130,   0],\n",
       "       [130,   0],\n",
       "       [130,   0],\n",
       "       [130,   0],\n",
       "       [130,   0],\n",
       "       [130,   0],\n",
       "       [130,   0],\n",
       "       [130,   0]], dtype=int16)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"seq_tensor\"][0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C19X9m-3iMlm"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "zymqD-UqR8wq"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Dataset\n",
    "from torch_geometric.data import Data\n",
    "import itertools\n",
    "\n",
    "\n",
    "def unpackbits(x, num_bits):\n",
    "\n",
    "    if np.issubdtype(x.dtype, np.floating):\n",
    "        raise ValueError(\"numpy data type needs to be int-like\")\n",
    "\n",
    "    xshape = list(x.shape)\n",
    "    x = x.reshape([-1, 1])\n",
    "    mask = 2**np.arange(num_bits, dtype=x.dtype).reshape([1, num_bits])\n",
    "\n",
    "    return (x & mask).astype(bool).astype(int).reshape(xshape + [num_bits])\n",
    "\n",
    "\n",
    "class MIDIDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dir):\n",
    "        self.dir = dir\n",
    "\n",
    "    def __len__(self):\n",
    "        _, _, files = next(os.walk(self.dir))\n",
    "        return len(files)\n",
    "\n",
    "    \n",
    "    def __get_track_edges(self, acts, edge_type_ind=0):\n",
    "\n",
    "        a_t = acts.transpose()\n",
    "        inds = np.stack(np.where(a_t == 1)).transpose()\n",
    "\n",
    "        labels = np.arange(acts.shape[0]*acts.shape[1])\n",
    "        labels = labels.reshape(acts.shape[0], acts.shape[1]).transpose()\n",
    "\n",
    "        track_edges = []\n",
    "\n",
    "        for track in range(a_t.shape[1]):\n",
    "            tr_inds = list(inds[inds[:,1] == track])\n",
    "            e_inds = [(tr_inds[i],\n",
    "                    tr_inds[i+1]) for i in range(len(tr_inds)-1)]\n",
    "            edges = [(labels[tuple(e[0])], labels[tuple(e[1])], edge_type_ind, e[1][0]-e[0][0]) for e in e_inds]\n",
    "            track_edges.extend(edges)\n",
    "\n",
    "        return np.array(track_edges, dtype='long')\n",
    "\n",
    "    \n",
    "    def __get_onset_edges(self, acts, edge_type_ind=1):\n",
    "\n",
    "        a_t = acts.transpose()\n",
    "        inds = np.stack(np.where(a_t == 1)).transpose()\n",
    "        ts_acts = np.any(a_t, axis=1)\n",
    "        ts_inds = np.where(ts_acts)[0]\n",
    "\n",
    "        labels = np.arange(acts.shape[0]*acts.shape[1])\n",
    "        labels = labels.reshape(acts.shape[0], acts.shape[1]).transpose()\n",
    "\n",
    "        onset_edges = []\n",
    "\n",
    "        for i in ts_inds:\n",
    "            ts_acts_inds = list(inds[inds[:,0] == i])\n",
    "            if len(ts_acts_inds) < 2:\n",
    "                continue\n",
    "            e_inds = list(itertools.combinations(ts_acts_inds, 2))\n",
    "            edges = [(labels[tuple(e[0])], labels[tuple(e[1])], edge_type_ind, 0) for e in e_inds]\n",
    "            inv_edges = [(e[1], e[0], *e[2:]) for e in edges]\n",
    "            onset_edges.extend(edges)\n",
    "            onset_edges.extend(inv_edges)\n",
    "\n",
    "        return np.array(onset_edges, dtype='long')\n",
    "\n",
    "\n",
    "    def __get_next_edges(self, acts, edge_type_ind=2):\n",
    "\n",
    "        a_t = acts.transpose()\n",
    "        inds = np.stack(np.where(a_t == 1)).transpose()\n",
    "        ts_acts = np.any(a_t, axis=1)\n",
    "        ts_inds = np.where(ts_acts)[0]\n",
    "\n",
    "        labels = np.arange(acts.shape[0]*acts.shape[1])\n",
    "        labels = labels.reshape(acts.shape[0], acts.shape[1]).transpose()\n",
    "\n",
    "        next_edges = []\n",
    "\n",
    "        for i in range(len(ts_inds)-1):\n",
    "\n",
    "            ind_s = ts_inds[i]\n",
    "            ind_e = ts_inds[i+1]\n",
    "            s = inds[inds[:,0] == ind_s]\n",
    "            e = inds[inds[:,0] == ind_e]\n",
    "\n",
    "            e_inds = [t for t in list(itertools.product(s, e)) if t[0][1] != t[1][1]]\n",
    "            edges = [(labels[tuple(e[0])],labels[tuple(e[1])], edge_type_ind, ind_e-ind_s) for e in e_inds]\n",
    "\n",
    "            next_edges.extend(edges)\n",
    "\n",
    "        return np.array(next_edges, dtype='long')\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        # Load tensors\n",
    "        sample_path = os.path.join(self.dir, str(idx) + \".npz\")\n",
    "        data = np.load(sample_path)\n",
    "\n",
    "        seq_tensor = data[\"seq_tensor\"]\n",
    "        seq_acts = data[\"seq_acts\"]\n",
    "\n",
    "        # From decimals to one-hot (pitch)\n",
    "        pitches = seq_tensor[:, :, :, 0]\n",
    "        onehot = np.zeros((pitches.shape[0]*pitches.shape[1]*pitches.shape[2],\n",
    "                            131), dtype=float)\n",
    "        onehot[np.arange(0, onehot.shape[0]), pitches.reshape(-1)] = 1.\n",
    "        onehot = onehot.reshape(-1, pitches.shape[1], seq_tensor.shape[2], 131)\n",
    "\n",
    "        # From decimals to binary (pitch)\n",
    "        durs = seq_tensor[:, :, :, 1]\n",
    "        bin_durs = unpackbits(durs, 9)[:, :, :, ::-1]\n",
    "\n",
    "        # Concatenate pitches and durations\n",
    "        new_seq_tensor = np.concatenate((onehot[:, :, :, :], bin_durs),\n",
    "                             axis=-1)\n",
    "        \n",
    "        # Construct graph from boolean activations\n",
    "        track_edges = self.__get_track_edges(seq_acts)\n",
    "        onset_edges = self.__get_onset_edges(seq_acts)\n",
    "        next_edges = self.__get_next_edges(seq_acts)\n",
    "        edges = [track_edges, onset_edges, next_edges]\n",
    "\n",
    "        # Concatenate edge tensors (N x 4) (if any)\n",
    "        no_edges = (len(track_edges) == 0 and \n",
    "                    len(onset_edges) == 0 and len(next_edges) == 0)\n",
    "        if not no_edges:\n",
    "            edge_list = np.concatenate([x for x in edges\n",
    "                                          if x.size > 0])\n",
    "            edge_list = torch.from_numpy(edge_list)\n",
    "        \n",
    "        # Adapt tensor to torch_geometric's Data\n",
    "        # Todo: re-check no edges case\n",
    "        edge_index = (torch.LongTensor([[], []]) if no_edges else\n",
    "                               edge_list[:, :2].t().contiguous())\n",
    "        edge_attr = (torch.Tensor([[0, 0]]) if no_edges else\n",
    "                                       edge_list[:, 2:])\n",
    "        \n",
    "        n = seq_acts.shape[0]*seq_acts.shape[1]\n",
    "        graph = Data(edge_index=edge_index, edge_attr=edge_attr, num_nodes=n)\n",
    "        \n",
    "        # Todo: start with torch at mount\n",
    "        return torch.Tensor(new_seq_tensor), torch.Tensor(seq_acts), graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "hSwcnlq4g50O"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch_geometric.nn.conv import GCNConv\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "# Todo: check and think about max_len\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 256):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) *                     \\\n",
    "                             (-math.log(10000.0)/d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position*div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position*div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor, shape [seq_len, batch_size, embedding_dim]\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    \n",
    "    def __init__(self, features_dims=[256, 256, 256], num_relations=3):\n",
    "        super().__init__()\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "        for i in range(len(features_dims)-1):\n",
    "            self.layers.append(GCNConv(features_dims[i], features_dims[i+1]))\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            x = F.dropout(x, training=self.training)\n",
    "            x = layer(x, edge_index)\n",
    "            x = F.relu(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "\n",
    "    # 140 = 128+3+9\n",
    "    def __init__(self, d_token=140, d_transf=256, nhead_transf=4, \n",
    "                 num_layers_transf=2, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        # Todo: one separate encoder for drums\n",
    "        # Transformer Encoder\n",
    "        self.embedding = nn.Linear(d_token, d_transf)\n",
    "        self.pos_encoder = PositionalEncoding(d_transf, dropout)\n",
    "        transf_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_transf,\n",
    "            nhead=nhead_transf\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            transf_layer,\n",
    "            num_layers=num_layers_transf\n",
    "        )\n",
    "\n",
    "        # Graph encoder\n",
    "        self.graph_encoder = GCN()\n",
    "\n",
    "        # (LSTM)\n",
    "        \n",
    "        # Linear layers that compute the final mu and log_var\n",
    "        # Todo: as parameters\n",
    "        self.linear_mu = nn.Linear(256, 256)\n",
    "        self.linear_log_var = nn.Linear(256, 256)\n",
    "\n",
    "    def forward(self, x_seq, x_acts, x_graph):\n",
    "\n",
    "        # Collapse track (and optionally batch) dimension\n",
    "        #print(\"Init input:\", x_seq.size())\n",
    "        x_seq = x_seq.view(-1, x_seq.size(-2), x_seq.size(-1))\n",
    "        #print(\"Reshaped input:\", x_seq.size())\n",
    "\n",
    "        # Compute embeddings\n",
    "        embs = self.embedding(x_seq)\n",
    "        #print(\"Embs:\", embs.size())\n",
    "\n",
    "        # batch_first = False\n",
    "        embs = embs.permute(1, 0, 2)\n",
    "        #print(\"Seq len first input:\", embs.size())\n",
    "\n",
    "        pos_encs = self.pos_encoder(embs)\n",
    "        #print(\"Pos encodings:\", pos_encs.size())\n",
    "\n",
    "        # Todo: src_key_padding_mask = (src != pad).unsqueeze(-2) ?\n",
    "        transformer_encs = self.transformer_encoder(pos_encs)\n",
    "        #print(\"Transf encodings:\", transformer_encs.size())\n",
    "\n",
    "        pooled_encs = torch.mean(transformer_encs, 0)\n",
    "        #print(\"Pooled encodings:\", pooled_encs.size())\n",
    "\n",
    "        # Compute node encodings\n",
    "        x_graph.x = pooled_encs\n",
    "        node_encs = self.graph_encoder(x_graph)\n",
    "        #print(\"Node encodings:\", node_encs.size())\n",
    "        \n",
    "        # Compute final graph latent vector(s)\n",
    "        # (taking into account the batch size)\n",
    "        num_nodes = x_graph[0].num_nodes\n",
    "        batch_sz = node_encs.size(0) // num_nodes\n",
    "        node_encs = node_encs.view(batch_sz, num_nodes, -1)\n",
    "        encoding = torch.mean(node_encs, 1)\n",
    "\n",
    "        # Compute mu and log(std^2)\n",
    "        mu = self.linear_mu(encoding)\n",
    "        log_var = self.linear_log_var(encoding)\n",
    "        \n",
    "        return mu, log_var\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, d_z=256, n_tracks=4, resolution=32, d_token=140, d_model=256,\n",
    "                 d_transf=256, nhead_transf=4, num_layers_transf=2, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        # (LSTM)\n",
    "\n",
    "        # Boolean activations decoder (CNN/MLP)\n",
    "        self.acts_decoder = nn.Linear(d_z, n_tracks*resolution)\n",
    "\n",
    "        # GNN\n",
    "        self.graph_decoder = GCN()\n",
    "        \n",
    "        # Transformer Decoder\n",
    "        self.embedding = nn.Linear(d_token, d_transf)\n",
    "        self.pos_encoder = PositionalEncoding(d_transf,dropout)\n",
    "        decoder_layer = nn.TransformerDecoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead_transf\n",
    "        )\n",
    "        self.transf_decoder = nn.TransformerDecoder(\n",
    "            decoder_layer,\n",
    "            num_layers=num_layers_transf\n",
    "        )\n",
    "        \n",
    "        # Last linear layer\n",
    "        self.lin = nn.Linear(d_model, 140)\n",
    "\n",
    "\n",
    "    def forward(self, z, x_seq, x_acts, x_graph):\n",
    "\n",
    "        # Compute activations from z\n",
    "        acts_out = self.acts_decoder(z)\n",
    "        acts_out = acts_out.view(x_acts.size())\n",
    "        #print(\"Acts out:\", acts_out.size())\n",
    "\n",
    "        # Initialize node features with z and propagate with GNN\n",
    "        node_features = torch.repeat_interleave(\n",
    "                            z, x_acts.size(-1)*x_acts.size(-2), axis=0)\n",
    "        #print(\"Node features:\", node_features.size())\n",
    "\n",
    "        # Todo: use also edge info\n",
    "        x_graph.x = node_features\n",
    "        node_decs = self.graph_decoder(x_graph)\n",
    "        #print(\"Node decodings:\", node_decs.size())\n",
    "        \n",
    "        node_decs = node_decs.repeat(16, 1, 1)\n",
    "        #print(\"Tiled node decodings:\", node_decs.size())\n",
    "\n",
    "        # Decode features with transformer decoder\n",
    "        # forward(tgt, memory, tgt_mask=None, memory_mask=None, tgt_key_padding_mask=None, memory_key_padding_mask=None)\n",
    "        \n",
    "        # Todo: same embeddings as encoder?\n",
    "        seq = x_seq.view(-1, x_seq.size(-2), x_seq.size(-1))\n",
    "        embs = self.embedding(seq)\n",
    "        embs = embs.permute(1, 0, 2)\n",
    "        pos_encs = self.pos_encoder(embs)\n",
    "\n",
    "        seq_out = self.transf_decoder(pos_encs, node_decs)\n",
    "        #print(\"Seq out:\", seq_out.size())\n",
    "        \n",
    "        seq_out = self.lin(seq_out)\n",
    "        #print(\"Seq out after lin:\", seq_out.size())\n",
    "        \n",
    "        # Softmax on first 131 values (pitch), sigmoid on last 9 (dur)\n",
    "        #seq_out[:, :, :131] = F.log_softmax(seq_out[:, :, :131], dim=-1)\n",
    "        #seq_out[:, :, 131:] = torch.sigmoid(seq_out[:, :, 131:])\n",
    "        seq_out = seq_out.permute(1, 0, 2)\n",
    "        seq_out = seq_out.view(x_seq.size())\n",
    "        #print(\"Seq out after reshape\", seq_out.size())\n",
    "        \n",
    "\n",
    "        return seq_out, acts_out\n",
    "\n",
    "\n",
    "class VAE(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder()\n",
    "    \n",
    "    def forward(self, x_seq, x_acts, x_graph):\n",
    "        \n",
    "        mu, log_var = self.encoder(x_seq, x_acts, x_graph)\n",
    "        #print(\"Mu:\", mu.size())\n",
    "        #print(\"log_var:\", log_var.size())\n",
    "        \n",
    "        # Reparameterization trick\n",
    "        sigma = torch.exp(0.5*log_var)\n",
    "        eps = torch.randn_like(sigma)\n",
    "        #print(\"eps:\", eps.size())\n",
    "        z = mu + eps*sigma\n",
    "        \n",
    "        out = self.decoder(z, x_seq, x_acts, x_graph)\n",
    "        \n",
    "        return out, mu, log_var\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import uuid\n",
    "import copy\n",
    "\n",
    "\n",
    "class VAETrainer():\n",
    "    \n",
    "    def __init__(self, models_path, optimizer, init_lr, lr_scheduler=None, \n",
    "                 device=torch.device(\"cpu\"), print_every=1, save_every=1):\n",
    "        self.models_path = models_path\n",
    "        self.optimizer = optimizer\n",
    "        self.init_lr = init_lr\n",
    "        self.lr_scheduler = lr_scheduler\n",
    "        self.device = device\n",
    "        self.print_every = print_every\n",
    "        self.save_every = save_every\n",
    "        \n",
    "    \n",
    "    def train(self, model, trainloader, validloader=None, epochs=1, name=None):\n",
    "        \n",
    "        if name is None:\n",
    "            name = str(uuid.uuid4())\n",
    "        \n",
    "        path = os.path.join(models_path, name)\n",
    "        \n",
    "        n_batches = len(trainloader)\n",
    "                        \n",
    "        losses = []\n",
    "        acts_losses = []\n",
    "        pitches_losses = []\n",
    "        dur_losses = []\n",
    "        kld_losses = []\n",
    "        lrs = []\n",
    "        \n",
    "        ce = nn.CrossEntropyLoss()\n",
    "        bce = nn.BCEWithLogitsLoss()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        beta = 0\n",
    "        \n",
    "        model.train()\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            \n",
    "            for batch_idx, (x_seq, x_acts, x_graph) in enumerate(trainloader):\n",
    "                \n",
    "                # Zero out the gradients\n",
    "                self.optimizer.zero_grad()\n",
    "                \n",
    "                # Get the inputs\n",
    "                x_seq = x_seq.float().to(self.device)\n",
    "                x_acts = x_acts.to(self.device)\n",
    "                x_graph = x_graph.to(self.device)\n",
    "\n",
    "                # Forward pass, get the reconstructions\n",
    "                out, mu, log_var = model(x_seq, x_acts, x_graph)\n",
    "                seq_rec, acts_rec = out\n",
    "                \n",
    "                # Compute the loss\n",
    "                acts_loss = bce(acts_rec.view(-1), x_acts.view(-1).float())\n",
    "                pitches_loss = ce(seq_rec.reshape(-1, seq_rec.size(-1))[:, :131],\n",
    "                                  x_seq.reshape(-1, x_seq.size(-1))[:, :131].argmax(dim=1))/6 # :oooooooooooo\n",
    "                dur_loss = bce(seq_rec[..., 131:].reshape(-1), \n",
    "                               x_seq[..., 131:].reshape(-1))\n",
    "                kld_loss = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "                rec_loss = pitches_loss + dur_loss + acts_loss\n",
    "                loss = rec_loss + beta*kld_loss\n",
    "                \n",
    "                # Compute gradients and update weights\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                if self.lr_scheduler is not None:\n",
    "                    self.lr_scheduler.step()\n",
    "                \n",
    "                losses.append(loss.item())\n",
    "                acts_losses.append(acts_loss.item())\n",
    "                pitches_losses.append(pitches_loss.item())\n",
    "                dur_losses.append(dur_loss.item())\n",
    "                kld_losses.append((beta*kld_loss).item())\n",
    "                last_lr = (self.lr_scheduler.get_last_lr() if self.lr_scheduler is not None\n",
    "                               else self.init_lr)\n",
    "                lrs.append(last_lr)\n",
    "                \n",
    "                running_loss += loss.item()\n",
    "\n",
    "                # Print training loss information\n",
    "                if (batch_idx + 1) % self.print_every == 0:\n",
    "                    print(\"Training on batch {}/{} of epoch {} complete.\"\n",
    "                          .format(batch_idx+1, n_batches, epoch+1))\n",
    "                    print(\"Tot_loss: {:.4f} acts_loss: {:.4f} \"\n",
    "                          .format(running_loss/self.print_every, acts_loss), end='')\n",
    "                    print(\"pitches_loss: {:.4f} dur_loss: {:.4f} kld_loss: {:.4f}\"\n",
    "                          .format(pitches_loss, dur_loss, kld_loss))\n",
    "                    print(\"----------------------------------------\")\n",
    "                    running_loss = 0.0\n",
    "                    \n",
    "                # When appropriate, save model and stats on disk\n",
    "                if self.save_every > 0 and (batch_idx + 1) % self.save_every == 0:\n",
    "                    print(\"\\nSaving model to disk...\\n\")\n",
    "                    torch.save({\n",
    "                        'epoch': epoch,\n",
    "                        'batch': batch_idx,\n",
    "                        'save_every': self.save_every,\n",
    "                        'lrs': lrs,\n",
    "                        'losses': losses,\n",
    "                        'acts_losses': acts_losses,\n",
    "                        'pitches_losses': pitches_losses,\n",
    "                        'dur_losses': dur_losses,\n",
    "                        'kld_losses': kld_losses,\n",
    "                        'model_state_dict': model.state_dict(),\n",
    "                        'optimizer_state_dict': self.optimizer.state_dict()\n",
    "                    }, path)\n",
    "                    \n",
    "                if batch_idx > 16:\n",
    "                    break\n",
    "            \n",
    "\n",
    "        print('Training finished\\n')\n",
    "        print(\"Saving model to disk...\")\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'batch': batch_idx,\n",
    "            'save_every': self.save_every,\n",
    "            'lrs': lrs,\n",
    "            'losses': losses,\n",
    "            'acts_losses': acts_losses,\n",
    "            'pitches_losses': pitches_losses,\n",
    "            'dur_losses': dur_losses,\n",
    "            'kld_losses': kld_losses,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict()\n",
    "        }, path)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_path = \"models/\"\n",
    "os.makedirs(models_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5189"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_dir = \"data/preprocessed\"\n",
    "dataset = MIDIDataset(ds_dir)\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Current device idx: 1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.set_device(1)\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "#decive = torch.device(\"cpu\")\n",
    "print(\"Device:\", device)\n",
    "print(\"Current device idx:\", torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!rm models/vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the model and moving it to the specified device...\n",
      "Number of parameters: 6323468\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39f951976e004b579cf37cab7c5dca83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/163 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on batch 1/163 of epoch 1 complete.\n",
      "Tot_loss: 2.2356 acts_loss: 0.7308 pitches_loss: 0.7382 dur_loss: 0.7666 kld_loss: 745.0841\n",
      "----------------------------------------\n",
      "Training on batch 2/163 of epoch 1 complete.\n",
      "Tot_loss: 1.9264 acts_loss: 0.7159 pitches_loss: 0.6156 dur_loss: 0.5950 kld_loss: 761.4629\n",
      "----------------------------------------\n",
      "Training on batch 3/163 of epoch 1 complete.\n",
      "Tot_loss: 1.6585 acts_loss: 0.6992 pitches_loss: 0.4965 dur_loss: 0.4628 kld_loss: 842.4723\n",
      "----------------------------------------\n",
      "\n",
      "Saving model to disk...\n",
      "\n",
      "Training on batch 4/163 of epoch 1 complete.\n",
      "Tot_loss: 1.4562 acts_loss: 0.6957 pitches_loss: 0.3939 dur_loss: 0.3667 kld_loss: 993.5341\n",
      "----------------------------------------\n",
      "Training on batch 5/163 of epoch 1 complete.\n",
      "Tot_loss: 1.3016 acts_loss: 0.6847 pitches_loss: 0.3161 dur_loss: 0.3008 kld_loss: 1177.5730\n",
      "----------------------------------------\n",
      "Training on batch 6/163 of epoch 1 complete.\n",
      "Tot_loss: 1.1837 acts_loss: 0.6743 pitches_loss: 0.2557 dur_loss: 0.2537 kld_loss: 1397.1965\n",
      "----------------------------------------\n",
      "\n",
      "Saving model to disk...\n",
      "\n",
      "Training on batch 7/163 of epoch 1 complete.\n",
      "Tot_loss: 1.1055 acts_loss: 0.6663 pitches_loss: 0.2170 dur_loss: 0.2222 kld_loss: 1616.9828\n",
      "----------------------------------------\n",
      "Training on batch 8/163 of epoch 1 complete.\n",
      "Tot_loss: 1.0349 acts_loss: 0.6458 pitches_loss: 0.1917 dur_loss: 0.1974 kld_loss: 1892.6614\n",
      "----------------------------------------\n",
      "Training on batch 9/163 of epoch 1 complete.\n",
      "Tot_loss: 0.9946 acts_loss: 0.6400 pitches_loss: 0.1763 dur_loss: 0.1783 kld_loss: 2150.9912\n",
      "----------------------------------------\n",
      "\n",
      "Saving model to disk...\n",
      "\n",
      "Training on batch 10/163 of epoch 1 complete.\n",
      "Tot_loss: 0.9439 acts_loss: 0.6127 pitches_loss: 0.1672 dur_loss: 0.1640 kld_loss: 2423.6257\n",
      "----------------------------------------\n",
      "Training on batch 11/163 of epoch 1 complete.\n",
      "Tot_loss: 0.9052 acts_loss: 0.5942 pitches_loss: 0.1600 dur_loss: 0.1510 kld_loss: 2743.7578\n",
      "----------------------------------------\n",
      "Training on batch 12/163 of epoch 1 complete.\n",
      "Tot_loss: 0.8796 acts_loss: 0.5834 pitches_loss: 0.1563 dur_loss: 0.1400 kld_loss: 3045.0642\n",
      "----------------------------------------\n",
      "\n",
      "Saving model to disk...\n",
      "\n",
      "Training on batch 13/163 of epoch 1 complete.\n",
      "Tot_loss: 0.8470 acts_loss: 0.5631 pitches_loss: 0.1528 dur_loss: 0.1311 kld_loss: 3465.2031\n",
      "----------------------------------------\n",
      "Training on batch 14/163 of epoch 1 complete.\n",
      "Tot_loss: 0.8240 acts_loss: 0.5516 pitches_loss: 0.1499 dur_loss: 0.1225 kld_loss: 3810.9536\n",
      "----------------------------------------\n",
      "Training on batch 15/163 of epoch 1 complete.\n",
      "Tot_loss: 0.7938 acts_loss: 0.5305 pitches_loss: 0.1474 dur_loss: 0.1159 kld_loss: 4193.3965\n",
      "----------------------------------------\n",
      "\n",
      "Saving model to disk...\n",
      "\n",
      "Training on batch 16/163 of epoch 1 complete.\n",
      "Tot_loss: 0.7752 acts_loss: 0.5200 pitches_loss: 0.1458 dur_loss: 0.1094 kld_loss: 4587.9185\n",
      "----------------------------------------\n",
      "Training on batch 17/163 of epoch 1 complete.\n",
      "Tot_loss: 0.7418 acts_loss: 0.4919 pitches_loss: 0.1451 dur_loss: 0.1047 kld_loss: 5062.2637\n",
      "----------------------------------------\n",
      "Training on batch 18/163 of epoch 1 complete.\n",
      "Tot_loss: 0.7210 acts_loss: 0.4769 pitches_loss: 0.1440 dur_loss: 0.1002 kld_loss: 5522.2915\n",
      "----------------------------------------\n",
      "\n",
      "Saving model to disk...\n",
      "\n",
      "Training finished\n",
      "\n",
      "Saving model to disk...\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating the model and moving it to the specified device...\")\n",
    "\n",
    "vae = VAE().to(device)\n",
    "\n",
    "print(\"Number of parameters:\", sum(p.numel() for p in vae.parameters()))\n",
    "print()\n",
    "\n",
    "init_lr = 1e-4\n",
    "gamma = 0.999\n",
    "optimizer = optim.Adam(vae.parameters(), lr=init_lr)\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma)\n",
    "\n",
    "print('--------------------------------------------------\\n')\n",
    "\n",
    "trainer = VAETrainer(models_path, optimizer, init_lr, save_every=3, device=device)\n",
    "trainer.train(vae, loader, name='vae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.load('models/vae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7ff27186d1d0>"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 249,
       "width": 372
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1, len(m['losses'])+1), m['losses'], label='Loss')\n",
    "plt.plot(range(1, len(m['acts_losses'])+1), m['acts_losses'], label='acts')\n",
    "plt.plot(range(1, len(m['pitches_losses'])+1), m['pitches_losses'], label='pitches')\n",
    "plt.plot(range(1, len(m['dur_losses'])+1), m['dur_losses'], label='dur')\n",
    "plt.plot(range(1, len(m['kld_losses'])+1), m['kld_losses'], label='kld')\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KTFN-DCJjZWM"
   },
   "source": [
    "# Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4sSvVK7CxjV8"
   },
   "outputs": [],
   "source": [
    "from typing import Optional, Union, Tuple\n",
    "from torch_geometric.typing import OptTensor, Adj\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Parameter as Param\n",
    "from torch.nn import Parameter\n",
    "from torch_scatter import scatter\n",
    "from torch_sparse import SparseTensor, matmul, masked_select_nnz\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "\n",
    "from torch_geometric.nn.inits import glorot, zeros\n",
    "\n",
    "\n",
    "@torch.jit._overload\n",
    "def masked_edge_index(edge_index, edge_mask):\n",
    "    # type: (Tensor, Tensor) -> Tensor\n",
    "    pass\n",
    "\n",
    "\n",
    "@torch.jit._overload\n",
    "def masked_edge_index(edge_index, edge_mask):\n",
    "    # type: (SparseTensor, Tensor) -> SparseTensor\n",
    "    pass\n",
    "\n",
    "\n",
    "def masked_edge_index(edge_index, edge_mask):\n",
    "    if isinstance(edge_index, Tensor):\n",
    "        return edge_index[:, edge_mask]\n",
    "    else:\n",
    "        return masked_select_nnz(edge_index, edge_mask, layout='coo')\n",
    "\n",
    "\n",
    "class RGCNConv(MessagePassing):\n",
    "    r\"\"\"The relational graph convolutional operator from the `\"Modeling\n",
    "    Relational Data with Graph Convolutional Networks\"\n",
    "    <https://arxiv.org/abs/1703.06103>`_ paper\n",
    "\n",
    "    .. math::\n",
    "        \\mathbf{x}^{\\prime}_i = \\mathbf{\\Theta}_{\\textrm{root}} \\cdot\n",
    "        \\mathbf{x}_i + \\sum_{r \\in \\mathcal{R}} \\sum_{j \\in \\mathcal{N}_r(i)}\n",
    "        \\frac{1}{|\\mathcal{N}_r(i)|} \\mathbf{\\Theta}_r \\cdot \\mathbf{x}_j,\n",
    "\n",
    "    where :math:`\\mathcal{R}` denotes the set of relations, *i.e.* edge types.\n",
    "    Edge type needs to be a one-dimensional :obj:`torch.long` tensor which\n",
    "    stores a relation identifier\n",
    "    :math:`\\in \\{ 0, \\ldots, |\\mathcal{R}| - 1\\}` for each edge.\n",
    "\n",
    "    .. note::\n",
    "        This implementation is as memory-efficient as possible by iterating\n",
    "        over each individual relation type.\n",
    "        Therefore, it may result in low GPU utilization in case the graph has a\n",
    "        large number of relations.\n",
    "        As an alternative approach, :class:`FastRGCNConv` does not iterate over\n",
    "        each individual type, but may consume a large amount of memory to\n",
    "        compensate.\n",
    "        We advise to check out both implementations to see which one fits your\n",
    "        needs.\n",
    "\n",
    "    Args:\n",
    "        in_channels (int or tuple): Size of each input sample. A tuple\n",
    "            corresponds to the sizes of source and target dimensionalities.\n",
    "            In case no input features are given, this argument should\n",
    "            correspond to the number of nodes in your graph.\n",
    "        out_channels (int): Size of each output sample.\n",
    "        num_relations (int): Number of relations.\n",
    "        num_bases (int, optional): If set to not :obj:`None`, this layer will\n",
    "            use the basis-decomposition regularization scheme where\n",
    "            :obj:`num_bases` denotes the number of bases to use.\n",
    "            (default: :obj:`None`)\n",
    "        num_blocks (int, optional): If set to not :obj:`None`, this layer will\n",
    "            use the block-diagonal-decomposition regularization scheme where\n",
    "            :obj:`num_blocks` denotes the number of blocks to use.\n",
    "            (default: :obj:`None`)\n",
    "        aggr (string, optional): The aggregation scheme to use\n",
    "            (:obj:`\"add\"`, :obj:`\"mean\"`, :obj:`\"max\"`).\n",
    "            (default: :obj:`\"mean\"`)\n",
    "        root_weight (bool, optional): If set to :obj:`False`, the layer will\n",
    "            not add transformed root node features to the output.\n",
    "            (default: :obj:`True`)\n",
    "        bias (bool, optional): If set to :obj:`False`, the layer will not learn\n",
    "            an additive bias. (default: :obj:`True`)\n",
    "        **kwargs (optional): Additional arguments of\n",
    "            :class:`torch_geometric.nn.conv.MessagePassing`.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: Union[int, Tuple[int, int]],\n",
    "        out_channels: int,\n",
    "        num_relations: int,\n",
    "        num_bases: Optional[int] = None,\n",
    "        num_blocks: Optional[int] = None,\n",
    "        aggr: str = 'mean',\n",
    "        root_weight: bool = True,\n",
    "        bias: bool = True,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(aggr=aggr, node_dim=0, **kwargs)\n",
    "\n",
    "        if num_bases is not None and num_blocks is not None:\n",
    "            raise ValueError('Can not apply both basis-decomposition and '\n",
    "                             'block-diagonal-decomposition at the same time.')\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.num_relations = num_relations\n",
    "        self.num_bases = num_bases\n",
    "        self.num_blocks = num_blocks\n",
    "\n",
    "        if isinstance(in_channels, int):\n",
    "            in_channels = (in_channels, in_channels)\n",
    "        self.in_channels_l = in_channels[0]\n",
    "\n",
    "        if num_bases is not None:\n",
    "            self.weight = Parameter(\n",
    "                torch.Tensor(num_bases, in_channels[0], out_channels))\n",
    "            self.comp = Parameter(torch.Tensor(num_relations, num_bases))\n",
    "\n",
    "        elif num_blocks is not None:\n",
    "            assert (in_channels[0] % num_blocks == 0\n",
    "                    and out_channels % num_blocks == 0)\n",
    "            self.weight = Parameter(\n",
    "                torch.Tensor(num_relations, num_blocks,\n",
    "                             in_channels[0] // num_blocks,\n",
    "                             out_channels // num_blocks))\n",
    "            self.register_parameter('comp', None)\n",
    "\n",
    "        else:\n",
    "            self.weight = Parameter(\n",
    "                torch.Tensor(num_relations, in_channels[0], out_channels))\n",
    "            self.register_parameter('comp', None)\n",
    "\n",
    "        if root_weight:\n",
    "            self.root = Param(torch.Tensor(in_channels[1], out_channels))\n",
    "        else:\n",
    "            self.register_parameter('root', None)\n",
    "\n",
    "        if bias:\n",
    "            self.bias = Param(torch.Tensor(out_channels))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        glorot(self.weight)\n",
    "        glorot(self.comp)\n",
    "        glorot(self.root)\n",
    "        zeros(self.bias)\n",
    "\n",
    "\n",
    "    def forward(self, x: Union[OptTensor, Tuple[OptTensor, Tensor]],\n",
    "                edge_index: Adj, edge_type: OptTensor = None):\n",
    "        r\"\"\"\n",
    "        Args:\n",
    "            x: The input node features. Can be either a :obj:`[num_nodes,\n",
    "                in_channels]` node feature matrix, or an optional\n",
    "                one-dimensional node index tensor (in which case input features\n",
    "                are treated as trainable node embeddings).\n",
    "                Furthermore, :obj:`x` can be of type :obj:`tuple` denoting\n",
    "                source and destination node features.\n",
    "            edge_type: The one-dimensional relation type/index for each edge in\n",
    "                :obj:`edge_index`.\n",
    "                Should be only :obj:`None` in case :obj:`edge_index` is of type\n",
    "                :class:`torch_sparse.tensor.SparseTensor`.\n",
    "                (default: :obj:`None`)\n",
    "        \"\"\"\n",
    "\n",
    "        # Convert input features to a pair of node features or node indices.\n",
    "        x_l: OptTensor = None\n",
    "        if isinstance(x, tuple):\n",
    "            x_l = x[0]\n",
    "        else:\n",
    "            x_l = x\n",
    "        if x_l is None:\n",
    "            x_l = torch.arange(self.in_channels_l, device=self.weight.device)\n",
    "\n",
    "        x_r: Tensor = x_l\n",
    "        if isinstance(x, tuple):\n",
    "            x_r = x[1]\n",
    "\n",
    "        size = (x_l.size(0), x_r.size(0))\n",
    "\n",
    "        if isinstance(edge_index, SparseTensor):\n",
    "            edge_type = edge_index.storage.value()\n",
    "        assert edge_type is not None\n",
    "\n",
    "        # propagate_type: (x: Tensor)\n",
    "        out = torch.zeros(x_r.size(0), self.out_channels, device=x_r.device)\n",
    "\n",
    "        weight = self.weight\n",
    "        if self.num_bases is not None:  # Basis-decomposition =================\n",
    "            weight = (self.comp @ weight.view(self.num_bases, -1)).view(\n",
    "                self.num_relations, self.in_channels_l, self.out_channels)\n",
    "\n",
    "        if self.num_blocks is not None:  # Block-diagonal-decomposition =====\n",
    "\n",
    "            if x_l.dtype == torch.long and self.num_blocks is not None:\n",
    "                raise ValueError('Block-diagonal decomposition not supported '\n",
    "                                 'for non-continuous input features.')\n",
    "\n",
    "            for i in range(self.num_relations):\n",
    "                tmp = masked_edge_index(edge_index, edge_type == i)\n",
    "                h = self.propagate(tmp, x=x_l, size=size)\n",
    "                h = h.view(-1, weight.size(1), weight.size(2))\n",
    "                h = torch.einsum('abc,bcd->abd', h, weight[i])\n",
    "                out += h.contiguous().view(-1, self.out_channels)\n",
    "\n",
    "        else:  # No regularization/Basis-decomposition ========================\n",
    "            for i in range(self.num_relations):\n",
    "                tmp = masked_edge_index(edge_index, edge_type == i)\n",
    "\n",
    "                if x_l.dtype == torch.long:\n",
    "                    out += self.propagate(tmp, x=weight[i, x_l], size=size)\n",
    "                else:\n",
    "                    h = self.propagate(tmp, x=x_l, size=size)\n",
    "                    out = out + (h @ weight[i])\n",
    "\n",
    "        root = self.root\n",
    "        if root is not None:\n",
    "            out += root[x_r] if x_r.dtype == torch.long else x_r @ root\n",
    "\n",
    "        if self.bias is not None:\n",
    "            out += self.bias\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "    def message(self, x_j: Tensor) -> Tensor:\n",
    "        return x_j\n",
    "\n",
    "    def message_and_aggregate(self, adj_t: SparseTensor, x: Tensor) -> Tensor:\n",
    "        adj_t = adj_t.set_value(None, layout=None)\n",
    "        return matmul(adj_t, x, reduce=self.aggr)\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return (f'{self.__class__.__name__}({self.in_channels}, '\n",
    "                f'{self.out_channels}, num_relations={self.num_relations})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hfsNpMLrEXLk"
   },
   "source": [
    "next edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2DaVTonr_XB8",
    "outputId": "9e5fa8f9-604e-4273-a34d-fad73ad9ab7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 1 1]\n",
      " [1 1 1 1]\n",
      " [1 1 0 0]\n",
      " [1 1 1 1]\n",
      " [0 1 0 1]\n",
      " [1 0 0 0]\n",
      " [1 1 1 0]\n",
      " [0 0 0 0]]\n",
      "[[ 0  8 16 24]\n",
      " [ 1  9 17 25]\n",
      " [ 2 10 18 26]\n",
      " [ 3 11 19 27]\n",
      " [ 4 12 20 28]\n",
      " [ 5 13 21 29]\n",
      " [ 6 14 22 30]\n",
      " [ 7 15 23 31]]\n",
      "[(8, 1, 1), (8, 17, 1), (8, 25, 1), (16, 1, 1), (16, 9, 1), (16, 25, 1), (24, 1, 1), (24, 9, 1), (24, 17, 1), (1, 10, 1), (9, 2, 1), (17, 2, 1), (17, 10, 1), (25, 2, 1), (25, 10, 1), (2, 11, 1), (2, 19, 1), (2, 27, 1), (10, 3, 1), (10, 19, 1), (10, 27, 1), (3, 12, 1), (3, 28, 1), (11, 28, 1), (19, 12, 1), (19, 28, 1), (27, 12, 1), (12, 5, 1), (28, 5, 1), (5, 14, 1), (5, 22, 1)]\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "a = np.random.randint(2, size=(4,8))\n",
    "a_t = a.transpose()\n",
    "print(a_t)\n",
    "inds = np.stack(np.where(a_t == 1)).transpose()\n",
    "ts_acts = np.any(a_t, axis=1)\n",
    "ts_inds = np.where(ts_acts)[0]\n",
    "\n",
    "labels = np.arange(32).reshape(4, 8).transpose()\n",
    "print(labels)\n",
    "\n",
    "next_edges = []\n",
    "for i in range(len(ts_inds)-1):\n",
    "    ind_s = ts_inds[i]\n",
    "    ind_e = ts_inds[i+1]\n",
    "    s = inds[inds[:,0] == ind_s]\n",
    "    e = inds[inds[:,0] == ind_e]\n",
    "    e_inds = [t for t in list(itertools.product(s, e)) if t[0][1] != t[1][1]]\n",
    "    edges = [(labels[tuple(e[0])],labels[tuple(e[1])], ind_e-ind_s) for e in e_inds]\n",
    "    next_edges.extend(edges)\n",
    "\n",
    "print(next_edges)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lJ5JQm1aEbmb"
   },
   "source": [
    "onset edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DISmsJB3EatR",
    "outputId": "fc864608-63a6-4ad0-84d9-1478001ce60e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 1 1]\n",
      " [1 1 1 1]\n",
      " [1 1 0 0]\n",
      " [1 1 1 1]\n",
      " [0 1 0 1]\n",
      " [1 0 0 0]\n",
      " [1 1 1 0]\n",
      " [0 0 0 0]]\n",
      "[[ 0  8 16 24]\n",
      " [ 1  9 17 25]\n",
      " [ 2 10 18 26]\n",
      " [ 3 11 19 27]\n",
      " [ 4 12 20 28]\n",
      " [ 5 13 21 29]\n",
      " [ 6 14 22 30]\n",
      " [ 7 15 23 31]]\n",
      "[(8, 16, 0), (8, 24, 0), (16, 24, 0), (16, 8, 0), (24, 8, 0), (24, 16, 0), (1, 9, 0), (1, 17, 0), (1, 25, 0), (9, 17, 0), (9, 25, 0), (17, 25, 0), (9, 1, 0), (17, 1, 0), (25, 1, 0), (17, 9, 0), (25, 9, 0), (25, 17, 0), (2, 10, 0), (10, 2, 0), (3, 11, 0), (3, 19, 0), (3, 27, 0), (11, 19, 0), (11, 27, 0), (19, 27, 0), (11, 3, 0), (19, 3, 0), (27, 3, 0), (19, 11, 0), (27, 11, 0), (27, 19, 0), (12, 28, 0), (28, 12, 0), (6, 14, 0), (6, 22, 0), (14, 22, 0), (14, 6, 0), (22, 6, 0), (22, 14, 0)]\n"
     ]
    }
   ],
   "source": [
    "onset_edges = []\n",
    "print(a_t)\n",
    "print(labels)\n",
    "\n",
    "for i in ts_inds:\n",
    "    ts_acts_inds = list(inds[inds[:,0] == i])\n",
    "    if len(ts_acts_inds) < 2:\n",
    "        continue\n",
    "    e_inds = list(itertools.combinations(ts_acts_inds, 2))\n",
    "    edges = [(labels[tuple(e[0])], labels[tuple(e[1])], 0) for e in e_inds]\n",
    "    inv_edges = [(e[1], e[0], *e[2:]) for e in edges]\n",
    "    onset_edges.extend(edges)\n",
    "    onset_edges.extend(inv_edges)\n",
    "\n",
    "print(onset_edges)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ujitZCKaa7nu"
   },
   "source": [
    "track edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NbVG1vdFa-7e",
    "outputId": "c042449b-eef2-4707-a524-5f66f3ec07c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 1]\n",
      " [1 0 0 1]\n",
      " [0 1 0 0]\n",
      " [0 0 0 0]\n",
      " [1 1 0 0]\n",
      " [0 0 1 1]\n",
      " [0 0 1 0]\n",
      " [0 0 1 1]]\n",
      "[[ 0  8 16 24]\n",
      " [ 1  9 17 25]\n",
      " [ 2 10 18 26]\n",
      " [ 3 11 19 27]\n",
      " [ 4 12 20 28]\n",
      " [ 5 13 21 29]\n",
      " [ 6 14 22 30]\n",
      " [ 7 15 23 31]]\n",
      "[(array([0, 0]), array([1, 0])), (array([1, 0]), array([4, 0]))]\n",
      "[(array([0, 1]), array([2, 1])), (array([2, 1]), array([4, 1]))]\n",
      "[(array([0, 2]), array([5, 2])), (array([5, 2]), array([6, 2])), (array([6, 2]), array([7, 2]))]\n",
      "[(array([0, 3]), array([1, 3])), (array([1, 3]), array([5, 3])), (array([5, 3]), array([7, 3]))]\n",
      "[(0, 1, 1), (1, 4, 3), (8, 10, 2), (10, 12, 2), (16, 21, 5), (21, 22, 1), (22, 23, 1), (24, 25, 1), (25, 29, 4), (29, 31, 2)]\n"
     ]
    }
   ],
   "source": [
    "print(a_t)\n",
    "print(labels)\n",
    "track_edges = []\n",
    "\n",
    "for track in range(a_t.shape[1]):\n",
    "    tr_inds = list(inds[inds[:,1] == track])\n",
    "    e_inds = [(tr_inds[i],\n",
    "               tr_inds[i+1]) for i in range(len(tr_inds)-1)]\n",
    "    print(e_inds)\n",
    "    edges = [(labels[tuple(e[0])], labels[tuple(e[1])], e[1][0]-e[0][0]) for e in e_inds]\n",
    "    track_edges.extend(edges)\n",
    "\n",
    "print(track_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8DzouJ5NqALB",
    "outputId": "20a76e82-6305-4154-d894-6d69a64435a1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 3)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "track_edges = np.array(track_edges)\n",
    "onset_edges = np.array(onset_edges)\n",
    "np.concatenate((track_edges, onset_edges)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ihIYkPWPzyGX"
   },
   "outputs": [],
   "source": [
    "pip install pypianoroll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ie0pU8NWAUNM"
   },
   "outputs": [],
   "source": [
    "import pypianoroll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QTbGBSrdAZGH"
   },
   "outputs": [],
   "source": [
    "multitrack = pypianoroll.read(\"tests_fur-elise.mid\")\n",
    "print(multitrack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3eVo_BKzAmz4"
   },
   "outputs": [],
   "source": [
    "multitrack.tracks[0].pianoroll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PPpWw-rLA7CI"
   },
   "outputs": [],
   "source": [
    "multitrack.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x-PYbS7FA-Gg"
   },
   "outputs": [],
   "source": [
    "multitrack.trim(0, 12 * multitrack.resolution)\n",
    "multitrack.binarize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "psxuoTsZBFXY"
   },
   "outputs": [],
   "source": [
    "multitrack.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ovyixmSvBG3w"
   },
   "outputs": [],
   "source": [
    "multitrack.tracks[0].pianoroll.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wHlKNufuBzLn"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOhjCOJb34P4bTid7qFDg58",
   "collapsed_sections": [],
   "include_colab_link": true,
   "mount_file_id": "1NeVldMsPVJd6pXbxZDmuiUP-QJBRhYtj",
   "name": "midi.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
